{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdwsLohTkjdK85Rhx7XMk2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ByeonJaeseong/DeepLearningProject/blob/main/Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "WAYnybdRZp7K",
        "outputId": "7d9270cf-f4ca-41ea-a1ca-9f6fe009faa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.27.1)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.3.5 kt-legacy-1.0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2c34a779239e>:11: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner.tuners import RandomSearch\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cd0a7771-5547-4fbd-986c-0b56646b6774\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cd0a7771-5547-4fbd-986c-0b56646b6774\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving answer_sample.csv to answer_sample.csv\n",
            "Saving data_c30.csv to data_c30.csv\n",
            "Saving data_c40.csv to data_c40.csv\n",
            "Saving data_c50.csv to data_c50.csv\n",
            "Saving data_c70.csv to data_c70.csv\n",
            "Saving data_c100.csv to data_c100.csv\n",
            "Saving data_columns.csv to data_columns.csv\n",
            "Saving data_s30.csv to data_s30.csv\n",
            "Saving data_s40.csv to data_s40.csv\n",
            "Saving data_s50.csv to data_s50.csv\n",
            "Saving data_s70.csv to data_s70.csv\n",
            "Saving data_s100.csv to data_s100.csv\n",
            "Saving lane_data_c.csv to lane_data_c.csv\n",
            "Saving lane_data_columns.csv to lane_data_columns.csv\n",
            "Saving lane_data_s.csv to lane_data_s.csv\n",
            "Saving 차량_및_요댐퍼.xlsx to 차량_및_요댐퍼.xlsx\n"
          ]
        }
      ],
      "source": [
        "!pip install -U keras-tuner\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list = ['s30', 's40', 's50', 's70', 's100', 'c30', 'c40', 'c50', 'c70', 'c100']\n",
        "count = 1\n",
        "for i in list :\n",
        "    # 데이터 불러오기\n",
        "    lane_data_c = pd.read_csv('lane_data_c.csv', encoding='utf-8')\n",
        "    lane_data_s = pd.read_csv('lane_data_s.csv', encoding='utf-8')\n",
        "    data = pd.read_csv('data_'+i+'.csv', encoding='utf-8')\n",
        "    # 데이터 결합\n",
        "    data_combined = pd.concat([lane_data_c, lane_data_s, data], axis=1)\n",
        "    data_combined = data_combined.loc[:, ~data_combined.columns.duplicated()]\n",
        "    data_combined = data_combined.drop_duplicates(subset='Distance', keep='first')  # 첫 번째 중복 행만 남기기\n",
        "    # 가중치 계산 함수 정의\n",
        "    def weighted_mape(y_true, y_pred, weights):\n",
        "        return np.sum(weights * np.abs((y_true - y_pred) / y_true)) / np.sum(weights) * 100\n",
        "\n",
        "    # 사용자 정의 Weighted MAPE 손실 함수\n",
        "    def weighted_mape_loss(weights):\n",
        "        def loss(y_true, y_pred):\n",
        "            return tf.reduce_sum(weights * tf.abs((y_true - y_pred) / y_true)) / tf.reduce_sum(weights) * 100\n",
        "        return loss\n",
        "\n",
        "    # 입력 변수와 탈선계수 분리\n",
        "    X_time_series = data_combined[['Distance']]\n",
        "    X_features = data_combined.drop(['YL_M1_B1_W1', 'YR_M1_B1_W1', 'YL_M1_B1_W2', 'YR_M1_B1_W2', 'Distance'], axis=1)\n",
        "    y = data_combined[['YL_M1_B1_W1', 'YR_M1_B1_W1', 'YL_M1_B1_W2', 'YR_M1_B1_W2']]\n",
        "\n",
        "\n",
        "    # 데이터 정규화\n",
        "    scaler = MinMaxScaler()\n",
        "    X_features_scaled = scaler.fit_transform(X_features)\n",
        "    X_time_series_scaled = scaler.fit_transform(X_time_series)\n",
        "\n",
        "    # 학습 데이터와 테스트 데이터 분할\n",
        "    X_features_train, X_features_test, X_time_series_train, X_time_series_test, y_train, y_test = train_test_split(X_features_scaled, X_time_series_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 사용자 정의 Weighted MAPE 손실 함수\n",
        "    def weighted_mape_loss(weights):\n",
        "        def loss(y_true, y_pred):\n",
        "            return tf.reduce_sum(weights * tf.abs((y_true - y_pred) / y_true)) / tf.reduce_sum(weights) * 100\n",
        "        return loss\n",
        "\n",
        "    # 가중치 계산\n",
        "    weights_train = np.abs(y_train)  # 훈련 데이터를 기반으로 가중치 계산\n",
        "\n",
        "    # 입력 정의\n",
        "    input_time_series = Input(shape=(X_time_series_train.shape[1], 1), name='input_time_series')\n",
        "    input_features = Input(shape=(X_features_train.shape[1],), name='input_features')\n",
        "\n",
        "    # 시계열 데이터 처리를 위한 LSTM 층\n",
        "    lstm_units = 64\n",
        "    lstm_output = LSTM(units=lstm_units, activation='relu', return_sequences=True)(input_time_series)\n",
        "    lstm_output = LSTM(units=lstm_units, activation='relu')(lstm_output)\n",
        "\n",
        "    # 특성 데이터 처리를 위한 밀집층\n",
        "    features_output = Dense(units=32, activation='relu')(input_features)\n",
        "\n",
        "    # LSTM 층과 밀집층을 합치기\n",
        "    concatenated = concatenate([lstm_output, features_output])\n",
        "\n",
        "    # 예측을 위한 밀집층 추가\n",
        "    output_layer = Dense(4)(concatenated)  # 4개의 탈선계수를 예측하므로 출력 뉴런 수는 4\n",
        "\n",
        "    # 모델 구성\n",
        "    model = Model(inputs=[input_time_series, input_features], outputs=output_layer)\n",
        "\n",
        "    # 모델 컴파일\n",
        "    model.compile(optimizer='adam', loss=weighted_mape_loss(weights_train))\n",
        "\n",
        "    # 하이퍼파라미터 튜닝을 위한 함수 정의\n",
        "    def build_model(hp):\n",
        "        lstm_units = hp.Int('lstm_units', min_value=32, max_value=128, step=32)\n",
        "        dense_units = hp.Int('dense_units', min_value=32, max_value=128, step=32)\n",
        "\n",
        "        input_time_series = Input(shape=(X_time_series_train.shape[1], 1), name='input_time_series')\n",
        "        input_features = Input(shape=(X_features_train.shape[1],), name='input_features')\n",
        "\n",
        "        lstm_output = LSTM(units=lstm_units, activation='relu', return_sequences=True)(input_time_series)\n",
        "        lstm_output = LSTM(units=lstm_units, activation='relu')(lstm_output)\n",
        "\n",
        "        features_output = Dense(units=dense_units, activation='relu')(input_features)\n",
        "\n",
        "        concatenated = concatenate([lstm_output, features_output])\n",
        "\n",
        "        output_layer = Dense(4)(concatenated)\n",
        "\n",
        "        tuned_model = Model(inputs=[input_time_series, input_features], outputs=output_layer)\n",
        "        tuned_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "        return tuned_model\n",
        "\n",
        "    # 하이퍼파라미터 튜닝\n",
        "    tuner = RandomSearch(build_model, objective='val_loss', max_trials=5, executions_per_trial=1, directory='tuner_results', project_name='model_tuning')\n",
        "    tuner.search([X_time_series_train, X_features_train], y_train, epochs=50, batch_size=32, validation_data=([X_time_series_test, X_features_test], y_test))\n",
        "\n",
        "    # 최적의 모델 선택\n",
        "    best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "    # 모델 훈련\n",
        "    best_model.fit([X_time_series_train, X_features_train], y_train, epochs=50, batch_size=32, validation_data=([X_time_series_test, X_features_test], y_test))\n",
        "\n",
        "    # 다음 1999개의 샘플 예측\n",
        "    next_samples = 1999\n",
        "    X_time_series_predict = X_time_series[-next_samples:]\n",
        "    X_features_predict = X_features[-next_samples:]\n",
        "\n",
        "    # 모델 예측\n",
        "    predictions = best_model.predict([X_time_series_predict, X_features_predict])\n",
        "\n",
        "    answer_sample = pd.read_csv('answer_sample.csv', header=None)\n",
        "    answer_sample.iloc[1:, count:count+4] = predictions  # 예측 결과 저장\n",
        "    answer_sample.to_csv('answer_sample.csv', index=False, header=False)  # 결과를 파일에 저장\n",
        "    count = count+4\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWhLbFbpZ6X6",
        "outputId": "71c948e2-0c64-4fc5-9ed5-49b4f91a6e73"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "300/300 [==============================] - 6s 10ms/step - loss: 1.6000e-04 - val_loss: 1.7359e-04\n",
            "Epoch 2/50\n",
            "300/300 [==============================] - 1s 5ms/step - loss: 1.6088e-04 - val_loss: 1.7763e-04\n",
            "Epoch 3/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.5918e-04 - val_loss: 1.6435e-04\n",
            "Epoch 4/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.5141e-04 - val_loss: 1.5108e-04\n",
            "Epoch 5/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.5425e-04 - val_loss: 1.6122e-04\n",
            "Epoch 6/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.5681e-04 - val_loss: 1.6170e-04\n",
            "Epoch 7/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.6021e-04 - val_loss: 1.8333e-04\n",
            "Epoch 8/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.5261e-04 - val_loss: 1.7609e-04\n",
            "Epoch 9/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.5377e-04 - val_loss: 1.4455e-04\n",
            "Epoch 10/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.4477e-04 - val_loss: 1.5928e-04\n",
            "Epoch 11/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.4461e-04 - val_loss: 1.5202e-04\n",
            "Epoch 12/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.4893e-04 - val_loss: 1.4554e-04\n",
            "Epoch 13/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.4761e-04 - val_loss: 1.3922e-04\n",
            "Epoch 14/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.4601e-04 - val_loss: 1.5002e-04\n",
            "Epoch 15/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.4636e-04 - val_loss: 1.5892e-04\n",
            "Epoch 16/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 1.4281e-04 - val_loss: 1.4257e-04\n",
            "Epoch 17/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.4592e-04 - val_loss: 1.6949e-04\n",
            "Epoch 18/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 1.4720e-04 - val_loss: 1.5614e-04\n",
            "Epoch 19/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.4120e-04 - val_loss: 1.6964e-04\n",
            "Epoch 20/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.4200e-04 - val_loss: 1.4450e-04\n",
            "Epoch 21/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.3292e-04 - val_loss: 1.3219e-04\n",
            "Epoch 22/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.3449e-04 - val_loss: 1.6449e-04\n",
            "Epoch 23/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 1.3893e-04 - val_loss: 1.3818e-04\n",
            "Epoch 24/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.3808e-04 - val_loss: 1.4238e-04\n",
            "Epoch 25/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.4237e-04 - val_loss: 1.3646e-04\n",
            "Epoch 26/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.3563e-04 - val_loss: 1.5580e-04\n",
            "Epoch 27/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.3622e-04 - val_loss: 1.4362e-04\n",
            "Epoch 28/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.3134e-04 - val_loss: 1.4379e-04\n",
            "Epoch 29/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.3427e-04 - val_loss: 1.4425e-04\n",
            "Epoch 30/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 1.3249e-04 - val_loss: 1.3907e-04\n",
            "Epoch 31/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.2934e-04 - val_loss: 1.5885e-04\n",
            "Epoch 32/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.2928e-04 - val_loss: 1.3031e-04\n",
            "Epoch 33/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.3162e-04 - val_loss: 1.4399e-04\n",
            "Epoch 34/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.2928e-04 - val_loss: 1.3140e-04\n",
            "Epoch 35/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.3267e-04 - val_loss: 1.2295e-04\n",
            "Epoch 36/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.3047e-04 - val_loss: 1.2503e-04\n",
            "Epoch 37/50\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 1.3206e-04 - val_loss: 1.3747e-04\n",
            "Epoch 38/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.2197e-04 - val_loss: 1.5206e-04\n",
            "Epoch 39/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.2527e-04 - val_loss: 1.2507e-04\n",
            "Epoch 40/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.2363e-04 - val_loss: 1.1720e-04\n",
            "Epoch 41/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.2319e-04 - val_loss: 1.5608e-04\n",
            "Epoch 42/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.2763e-04 - val_loss: 1.3248e-04\n",
            "Epoch 43/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.2008e-04 - val_loss: 1.4995e-04\n",
            "Epoch 44/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.2549e-04 - val_loss: 1.2750e-04\n",
            "Epoch 45/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.2213e-04 - val_loss: 1.3892e-04\n",
            "Epoch 46/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.2746e-04 - val_loss: 1.3665e-04\n",
            "Epoch 47/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.2426e-04 - val_loss: 1.2913e-04\n",
            "Epoch 48/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.2738e-04 - val_loss: 1.3628e-04\n",
            "Epoch 49/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.1752e-04 - val_loss: 1.3616e-04\n",
            "Epoch 50/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.2763e-04 - val_loss: 1.2680e-04\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n",
            "300/300 [==============================] - 4s 7ms/step - loss: 1.5536e-04 - val_loss: 1.2298e-04\n",
            "Epoch 2/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.1602e-04 - val_loss: 1.1733e-04\n",
            "Epoch 3/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 1.0848e-04 - val_loss: 1.1091e-04\n",
            "Epoch 4/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0770e-04 - val_loss: 1.2873e-04\n",
            "Epoch 5/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.0461e-04 - val_loss: 1.0046e-04\n",
            "Epoch 6/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0740e-04 - val_loss: 1.1107e-04\n",
            "Epoch 7/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0773e-04 - val_loss: 1.0323e-04\n",
            "Epoch 8/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0495e-04 - val_loss: 1.0330e-04\n",
            "Epoch 9/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.0421e-04 - val_loss: 1.0616e-04\n",
            "Epoch 10/50\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 1.0055e-04 - val_loss: 1.0607e-04\n",
            "Epoch 11/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.9870e-05 - val_loss: 9.7773e-05\n",
            "Epoch 12/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0066e-04 - val_loss: 1.2195e-04\n",
            "Epoch 13/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0438e-04 - val_loss: 1.1341e-04\n",
            "Epoch 14/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0030e-04 - val_loss: 1.0204e-04\n",
            "Epoch 15/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.8648e-05 - val_loss: 1.0855e-04\n",
            "Epoch 16/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 1.0009e-04 - val_loss: 1.0556e-04\n",
            "Epoch 17/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.9794e-05 - val_loss: 9.8958e-05\n",
            "Epoch 18/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0146e-04 - val_loss: 1.1736e-04\n",
            "Epoch 19/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.7041e-05 - val_loss: 9.4085e-05\n",
            "Epoch 20/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 9.6989e-05 - val_loss: 1.1529e-04\n",
            "Epoch 21/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.3546e-05 - val_loss: 1.0664e-04\n",
            "Epoch 22/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.7821e-05 - val_loss: 1.1005e-04\n",
            "Epoch 23/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.6761e-05 - val_loss: 9.8929e-05\n",
            "Epoch 24/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.2229e-05 - val_loss: 1.0206e-04\n",
            "Epoch 25/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.1791e-05 - val_loss: 9.4693e-05\n",
            "Epoch 26/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.0648e-05 - val_loss: 1.0131e-04\n",
            "Epoch 27/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.3771e-05 - val_loss: 9.5787e-05\n",
            "Epoch 28/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.2049e-05 - val_loss: 1.0750e-04\n",
            "Epoch 29/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 9.0577e-05 - val_loss: 1.1166e-04\n",
            "Epoch 30/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 9.1889e-05 - val_loss: 1.0856e-04\n",
            "Epoch 31/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.1208e-05 - val_loss: 9.4126e-05\n",
            "Epoch 32/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 9.2903e-05 - val_loss: 8.6156e-05\n",
            "Epoch 33/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.6802e-05 - val_loss: 9.9230e-05\n",
            "Epoch 34/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.9459e-05 - val_loss: 9.1568e-05\n",
            "Epoch 35/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.6857e-05 - val_loss: 9.2965e-05\n",
            "Epoch 36/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.6452e-05 - val_loss: 9.3052e-05\n",
            "Epoch 37/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 8.4397e-05 - val_loss: 9.3349e-05\n",
            "Epoch 38/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 8.7977e-05 - val_loss: 8.8298e-05\n",
            "Epoch 39/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.6925e-05 - val_loss: 9.3579e-05\n",
            "Epoch 40/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.3646e-05 - val_loss: 9.6802e-05\n",
            "Epoch 41/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.5894e-05 - val_loss: 1.0344e-04\n",
            "Epoch 42/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.5310e-05 - val_loss: 1.0113e-04\n",
            "Epoch 43/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.7627e-05 - val_loss: 9.3279e-05\n",
            "Epoch 44/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 8.6387e-05 - val_loss: 9.3145e-05\n",
            "Epoch 45/50\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 8.8083e-05 - val_loss: 9.8149e-05\n",
            "Epoch 46/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.6761e-05 - val_loss: 9.4915e-05\n",
            "Epoch 47/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.4519e-05 - val_loss: 9.3724e-05\n",
            "Epoch 48/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.2950e-05 - val_loss: 8.8418e-05\n",
            "Epoch 49/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.1683e-05 - val_loss: 9.1375e-05\n",
            "Epoch 50/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.3853e-05 - val_loss: 8.2120e-05\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n",
            "300/300 [==============================] - 5s 7ms/step - loss: 1.4850e-04 - val_loss: 1.1020e-04\n",
            "Epoch 2/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1228e-04 - val_loss: 1.1821e-04\n",
            "Epoch 3/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0557e-04 - val_loss: 1.0426e-04\n",
            "Epoch 4/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0303e-04 - val_loss: 1.5464e-04\n",
            "Epoch 5/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.0340e-04 - val_loss: 1.0099e-04\n",
            "Epoch 6/50\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 9.8911e-05 - val_loss: 9.8508e-05\n",
            "Epoch 7/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0117e-04 - val_loss: 1.0933e-04\n",
            "Epoch 8/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.9275e-05 - val_loss: 1.1920e-04\n",
            "Epoch 9/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.7533e-05 - val_loss: 1.1617e-04\n",
            "Epoch 10/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0064e-04 - val_loss: 9.2671e-05\n",
            "Epoch 11/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.6414e-05 - val_loss: 1.0144e-04\n",
            "Epoch 12/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.3727e-05 - val_loss: 8.8967e-05\n",
            "Epoch 13/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 9.7022e-05 - val_loss: 1.0070e-04\n",
            "Epoch 14/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 9.3263e-05 - val_loss: 1.1479e-04\n",
            "Epoch 15/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 9.5023e-05 - val_loss: 9.1247e-05\n",
            "Epoch 16/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.3729e-05 - val_loss: 8.9955e-05\n",
            "Epoch 17/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.1779e-05 - val_loss: 8.8140e-05\n",
            "Epoch 18/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.1420e-05 - val_loss: 1.2093e-04\n",
            "Epoch 19/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.1194e-05 - val_loss: 9.5382e-05\n",
            "Epoch 20/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 8.6369e-05 - val_loss: 9.5518e-05\n",
            "Epoch 21/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.5876e-05 - val_loss: 1.1058e-04\n",
            "Epoch 22/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.7587e-05 - val_loss: 9.6110e-05\n",
            "Epoch 23/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.5551e-05 - val_loss: 9.2463e-05\n",
            "Epoch 24/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.8826e-05 - val_loss: 1.2855e-04\n",
            "Epoch 25/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.9273e-05 - val_loss: 1.1177e-04\n",
            "Epoch 26/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 8.8718e-05 - val_loss: 8.5941e-05\n",
            "Epoch 27/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 8.6630e-05 - val_loss: 9.7885e-05\n",
            "Epoch 28/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.5239e-05 - val_loss: 9.1737e-05\n",
            "Epoch 29/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.4779e-05 - val_loss: 8.5575e-05\n",
            "Epoch 30/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.7621e-05 - val_loss: 9.9267e-05\n",
            "Epoch 31/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.3042e-05 - val_loss: 8.3544e-05\n",
            "Epoch 32/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.1843e-05 - val_loss: 8.0016e-05\n",
            "Epoch 33/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 8.2829e-05 - val_loss: 8.4584e-05\n",
            "Epoch 34/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 8.2317e-05 - val_loss: 8.0793e-05\n",
            "Epoch 35/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.2505e-05 - val_loss: 9.4694e-05\n",
            "Epoch 36/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.3207e-05 - val_loss: 9.6057e-05\n",
            "Epoch 37/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.1619e-05 - val_loss: 9.4644e-05\n",
            "Epoch 38/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.2336e-05 - val_loss: 8.7569e-05\n",
            "Epoch 39/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 7.8486e-05 - val_loss: 7.9526e-05\n",
            "Epoch 40/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 7.9788e-05 - val_loss: 8.4222e-05\n",
            "Epoch 41/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 7.9446e-05 - val_loss: 8.2450e-05\n",
            "Epoch 42/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 7.8737e-05 - val_loss: 8.9280e-05\n",
            "Epoch 43/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.1262e-05 - val_loss: 8.3663e-05\n",
            "Epoch 44/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 7.9741e-05 - val_loss: 8.2898e-05\n",
            "Epoch 45/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 7.9558e-05 - val_loss: 8.0085e-05\n",
            "Epoch 46/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 7.9254e-05 - val_loss: 9.1546e-05\n",
            "Epoch 47/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 7.7131e-05 - val_loss: 8.3813e-05\n",
            "Epoch 48/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 7.8140e-05 - val_loss: 9.4681e-05\n",
            "Epoch 49/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 7.8248e-05 - val_loss: 8.9611e-05\n",
            "Epoch 50/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 7.6404e-05 - val_loss: 1.0693e-04\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n",
            "300/300 [==============================] - 5s 9ms/step - loss: 1.5636e-04 - val_loss: 1.1208e-04\n",
            "Epoch 2/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.1468e-04 - val_loss: 1.2538e-04\n",
            "Epoch 3/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0783e-04 - val_loss: 9.9546e-05\n",
            "Epoch 4/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.0507e-04 - val_loss: 1.1705e-04\n",
            "Epoch 5/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0368e-04 - val_loss: 9.8395e-05\n",
            "Epoch 6/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 9.9497e-05 - val_loss: 9.9368e-05\n",
            "Epoch 7/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.0034e-04 - val_loss: 1.0103e-04\n",
            "Epoch 8/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.6380e-05 - val_loss: 9.6250e-05\n",
            "Epoch 9/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 1.0462e-04 - val_loss: 1.2021e-04\n",
            "Epoch 10/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 9.9855e-05 - val_loss: 1.0312e-04\n",
            "Epoch 11/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 9.6439e-05 - val_loss: 1.0188e-04\n",
            "Epoch 12/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 9.4138e-05 - val_loss: 9.2727e-05\n",
            "Epoch 13/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 9.4013e-05 - val_loss: 9.2364e-05\n",
            "Epoch 14/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 9.3510e-05 - val_loss: 9.4664e-05\n",
            "Epoch 15/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 9.5217e-05 - val_loss: 1.1127e-04\n",
            "Epoch 16/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 9.2693e-05 - val_loss: 9.1247e-05\n",
            "Epoch 17/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.1327e-05 - val_loss: 9.2227e-05\n",
            "Epoch 18/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.2132e-05 - val_loss: 1.2233e-04\n",
            "Epoch 19/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.4232e-05 - val_loss: 9.5929e-05\n",
            "Epoch 20/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.8888e-05 - val_loss: 8.5915e-05\n",
            "Epoch 21/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.6861e-05 - val_loss: 8.6376e-05\n",
            "Epoch 22/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.5030e-05 - val_loss: 1.0115e-04\n",
            "Epoch 23/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 8.9279e-05 - val_loss: 8.9160e-05\n",
            "Epoch 24/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 8.6971e-05 - val_loss: 9.4247e-05\n",
            "Epoch 25/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.4465e-05 - val_loss: 8.3993e-05\n",
            "Epoch 26/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.7428e-05 - val_loss: 8.5824e-05\n",
            "Epoch 27/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.3022e-05 - val_loss: 9.4195e-05\n",
            "Epoch 28/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.4792e-05 - val_loss: 8.7696e-05\n",
            "Epoch 29/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.6348e-05 - val_loss: 9.3441e-05\n",
            "Epoch 30/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.1297e-05 - val_loss: 8.5313e-05\n",
            "Epoch 31/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 8.3695e-05 - val_loss: 8.9099e-05\n",
            "Epoch 32/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.4566e-05 - val_loss: 1.0688e-04\n",
            "Epoch 33/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.4776e-05 - val_loss: 8.4956e-05\n",
            "Epoch 34/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.0150e-05 - val_loss: 8.1181e-05\n",
            "Epoch 35/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 7.7248e-05 - val_loss: 8.7709e-05\n",
            "Epoch 36/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.1445e-05 - val_loss: 8.0513e-05\n",
            "Epoch 37/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 8.1681e-05 - val_loss: 8.0963e-05\n",
            "Epoch 38/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 8.2986e-05 - val_loss: 8.5260e-05\n",
            "Epoch 39/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 7.9593e-05 - val_loss: 1.0168e-04\n",
            "Epoch 40/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 7.8637e-05 - val_loss: 8.9789e-05\n",
            "Epoch 41/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 7.8777e-05 - val_loss: 8.0088e-05\n",
            "Epoch 42/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 7.8859e-05 - val_loss: 9.0914e-05\n",
            "Epoch 43/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 7.7891e-05 - val_loss: 7.9226e-05\n",
            "Epoch 44/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 7.8718e-05 - val_loss: 8.1424e-05\n",
            "Epoch 45/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 7.6352e-05 - val_loss: 7.3996e-05\n",
            "Epoch 46/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 7.8876e-05 - val_loss: 1.1527e-04\n",
            "Epoch 47/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 7.6230e-05 - val_loss: 8.3863e-05\n",
            "Epoch 48/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 7.4623e-05 - val_loss: 8.1352e-05\n",
            "Epoch 49/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 7.6004e-05 - val_loss: 7.5781e-05\n",
            "Epoch 50/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 7.3539e-05 - val_loss: 8.9185e-05\n",
            "63/63 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "300/300 [==============================] - 5s 8ms/step - loss: 1.4793e-04 - val_loss: 1.0829e-04\n",
            "Epoch 2/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1274e-04 - val_loss: 1.2076e-04\n",
            "Epoch 3/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.1001e-04 - val_loss: 1.3291e-04\n",
            "Epoch 4/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 1.0431e-04 - val_loss: 9.8981e-05\n",
            "Epoch 5/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0126e-04 - val_loss: 1.1413e-04\n",
            "Epoch 6/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.9468e-05 - val_loss: 1.0371e-04\n",
            "Epoch 7/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0073e-04 - val_loss: 1.0115e-04\n",
            "Epoch 8/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.8541e-05 - val_loss: 9.3537e-05\n",
            "Epoch 9/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.6306e-05 - val_loss: 9.4216e-05\n",
            "Epoch 10/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.4931e-05 - val_loss: 9.2112e-05\n",
            "Epoch 11/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 9.6933e-05 - val_loss: 9.6589e-05\n",
            "Epoch 12/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.5550e-05 - val_loss: 1.0412e-04\n",
            "Epoch 13/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.2119e-05 - val_loss: 1.1290e-04\n",
            "Epoch 14/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.2166e-05 - val_loss: 1.1354e-04\n",
            "Epoch 15/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.2349e-05 - val_loss: 8.7929e-05\n",
            "Epoch 16/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.2355e-05 - val_loss: 8.6356e-05\n",
            "Epoch 17/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 8.7653e-05 - val_loss: 9.0159e-05\n",
            "Epoch 18/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 9.0558e-05 - val_loss: 9.6268e-05\n",
            "Epoch 19/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.0433e-05 - val_loss: 9.4071e-05\n",
            "Epoch 20/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.9841e-05 - val_loss: 8.5113e-05\n",
            "Epoch 21/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.7896e-05 - val_loss: 8.6358e-05\n",
            "Epoch 22/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 8.7167e-05 - val_loss: 8.5757e-05\n",
            "Epoch 23/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 8.4173e-05 - val_loss: 9.9754e-05\n",
            "Epoch 24/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 8.7512e-05 - val_loss: 8.8241e-05\n",
            "Epoch 25/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 8.5507e-05 - val_loss: 9.4121e-05\n",
            "Epoch 26/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 8.4195e-05 - val_loss: 9.8463e-05\n",
            "Epoch 27/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 8.7551e-05 - val_loss: 1.0164e-04\n",
            "Epoch 28/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.2040e-05 - val_loss: 8.1350e-05\n",
            "Epoch 29/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 8.3370e-05 - val_loss: 8.0642e-05\n",
            "Epoch 30/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 8.0109e-05 - val_loss: 8.9807e-05\n",
            "Epoch 31/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 8.3307e-05 - val_loss: 9.2470e-05\n",
            "Epoch 32/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.4080e-05 - val_loss: 8.6919e-05\n",
            "Epoch 33/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.2444e-05 - val_loss: 8.7868e-05\n",
            "Epoch 34/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 7.9627e-05 - val_loss: 9.0468e-05\n",
            "Epoch 35/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.1740e-05 - val_loss: 8.1024e-05\n",
            "Epoch 36/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 8.0090e-05 - val_loss: 9.2134e-05\n",
            "Epoch 37/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 7.9872e-05 - val_loss: 9.6087e-05\n",
            "Epoch 38/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 7.8459e-05 - val_loss: 7.7473e-05\n",
            "Epoch 39/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.0380e-05 - val_loss: 7.8193e-05\n",
            "Epoch 40/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 7.7626e-05 - val_loss: 7.9119e-05\n",
            "Epoch 41/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 7.6905e-05 - val_loss: 9.4529e-05\n",
            "Epoch 42/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 7.7473e-05 - val_loss: 8.2277e-05\n",
            "Epoch 43/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 7.6998e-05 - val_loss: 8.8037e-05\n",
            "Epoch 44/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 7.6677e-05 - val_loss: 8.1706e-05\n",
            "Epoch 45/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 7.4061e-05 - val_loss: 8.2564e-05\n",
            "Epoch 46/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 7.6822e-05 - val_loss: 8.1754e-05\n",
            "Epoch 47/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 7.7635e-05 - val_loss: 7.8984e-05\n",
            "Epoch 48/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 7.7024e-05 - val_loss: 8.1438e-05\n",
            "Epoch 49/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 7.6876e-05 - val_loss: 8.5155e-05\n",
            "Epoch 50/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 7.5941e-05 - val_loss: 7.9717e-05\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n",
            "300/300 [==============================] - 6s 10ms/step - loss: 3.6648e-04 - val_loss: 2.8314e-04\n",
            "Epoch 2/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 2.9512e-04 - val_loss: 2.3864e-04\n",
            "Epoch 3/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 2.7492e-04 - val_loss: 2.4438e-04\n",
            "Epoch 4/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 2.4858e-04 - val_loss: 2.2501e-04\n",
            "Epoch 5/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 2.4775e-04 - val_loss: 2.5037e-04\n",
            "Epoch 6/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 2.3430e-04 - val_loss: 2.1553e-04\n",
            "Epoch 7/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 2.3165e-04 - val_loss: 3.3436e-04\n",
            "Epoch 8/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 2.3135e-04 - val_loss: 2.0199e-04\n",
            "Epoch 9/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 2.2111e-04 - val_loss: 2.2281e-04\n",
            "Epoch 10/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 2.2285e-04 - val_loss: 1.9929e-04\n",
            "Epoch 11/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 2.1496e-04 - val_loss: 2.1114e-04\n",
            "Epoch 12/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 2.2465e-04 - val_loss: 2.8621e-04\n",
            "Epoch 13/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 2.1326e-04 - val_loss: 2.0789e-04\n",
            "Epoch 14/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 2.0247e-04 - val_loss: 1.8910e-04\n",
            "Epoch 15/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 2.0747e-04 - val_loss: 2.2279e-04\n",
            "Epoch 16/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.9468e-04 - val_loss: 1.9773e-04\n",
            "Epoch 17/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.9668e-04 - val_loss: 1.9847e-04\n",
            "Epoch 18/50\n",
            "300/300 [==============================] - 2s 5ms/step - loss: 1.9069e-04 - val_loss: 1.9899e-04\n",
            "Epoch 19/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.9716e-04 - val_loss: 1.9012e-04\n",
            "Epoch 20/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.9589e-04 - val_loss: 1.8899e-04\n",
            "Epoch 21/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 1.9544e-04 - val_loss: 2.0228e-04\n",
            "Epoch 22/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.9046e-04 - val_loss: 2.4379e-04\n",
            "Epoch 23/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.8684e-04 - val_loss: 1.7332e-04\n",
            "Epoch 24/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.8999e-04 - val_loss: 1.9104e-04\n",
            "Epoch 25/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.8436e-04 - val_loss: 1.9741e-04\n",
            "Epoch 26/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.8825e-04 - val_loss: 1.8682e-04\n",
            "Epoch 27/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.8279e-04 - val_loss: 2.0992e-04\n",
            "Epoch 28/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 1.7646e-04 - val_loss: 2.8831e-04\n",
            "Epoch 29/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.7934e-04 - val_loss: 1.7692e-04\n",
            "Epoch 30/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.7472e-04 - val_loss: 2.3208e-04\n",
            "Epoch 31/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.8038e-04 - val_loss: 2.4471e-04\n",
            "Epoch 32/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.7724e-04 - val_loss: 1.7690e-04\n",
            "Epoch 33/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.7203e-04 - val_loss: 1.8020e-04\n",
            "Epoch 34/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 1.7532e-04 - val_loss: 1.7553e-04\n",
            "Epoch 35/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 1.8034e-04 - val_loss: 1.9893e-04\n",
            "Epoch 36/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.7410e-04 - val_loss: 1.8490e-04\n",
            "Epoch 37/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.7011e-04 - val_loss: 1.8799e-04\n",
            "Epoch 38/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.6831e-04 - val_loss: 1.9979e-04\n",
            "Epoch 39/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.6434e-04 - val_loss: 1.6646e-04\n",
            "Epoch 40/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.6673e-04 - val_loss: 1.6644e-04\n",
            "Epoch 41/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 1.6065e-04 - val_loss: 1.6682e-04\n",
            "Epoch 42/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.6522e-04 - val_loss: 1.9508e-04\n",
            "Epoch 43/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.7035e-04 - val_loss: 1.6324e-04\n",
            "Epoch 44/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.7590e-04 - val_loss: 1.7069e-04\n",
            "Epoch 45/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.6230e-04 - val_loss: 1.7373e-04\n",
            "Epoch 46/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.7091e-04 - val_loss: 1.7053e-04\n",
            "Epoch 47/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.6990e-04 - val_loss: 1.6393e-04\n",
            "Epoch 48/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 1.6270e-04 - val_loss: 1.7474e-04\n",
            "Epoch 49/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.5913e-04 - val_loss: 1.8226e-04\n",
            "Epoch 50/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.6306e-04 - val_loss: 1.7669e-04\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n",
            "300/300 [==============================] - 5s 8ms/step - loss: 2.2832e-04 - val_loss: 1.4092e-04\n",
            "Epoch 2/50\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 1.4524e-04 - val_loss: 1.2185e-04\n",
            "Epoch 3/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.3555e-04 - val_loss: 1.2509e-04\n",
            "Epoch 4/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.3067e-04 - val_loss: 1.3091e-04\n",
            "Epoch 5/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.2485e-04 - val_loss: 1.5216e-04\n",
            "Epoch 6/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.2596e-04 - val_loss: 1.3948e-04\n",
            "Epoch 7/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.2242e-04 - val_loss: 1.1868e-04\n",
            "Epoch 8/50\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 1.2191e-04 - val_loss: 1.5950e-04\n",
            "Epoch 9/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.2836e-04 - val_loss: 1.2725e-04\n",
            "Epoch 10/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.2218e-04 - val_loss: 1.1579e-04\n",
            "Epoch 11/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.2168e-04 - val_loss: 1.4136e-04\n",
            "Epoch 12/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1790e-04 - val_loss: 1.0924e-04\n",
            "Epoch 13/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1408e-04 - val_loss: 1.1384e-04\n",
            "Epoch 14/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1786e-04 - val_loss: 1.2267e-04\n",
            "Epoch 15/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 1.1399e-04 - val_loss: 1.0855e-04\n",
            "Epoch 16/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1645e-04 - val_loss: 1.1339e-04\n",
            "Epoch 17/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1401e-04 - val_loss: 1.1309e-04\n",
            "Epoch 18/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0964e-04 - val_loss: 1.0938e-04\n",
            "Epoch 19/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1097e-04 - val_loss: 1.1131e-04\n",
            "Epoch 20/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1141e-04 - val_loss: 1.0925e-04\n",
            "Epoch 21/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.1217e-04 - val_loss: 1.1640e-04\n",
            "Epoch 22/50\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 1.0637e-04 - val_loss: 1.1258e-04\n",
            "Epoch 23/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0814e-04 - val_loss: 1.0169e-04\n",
            "Epoch 24/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0714e-04 - val_loss: 1.0564e-04\n",
            "Epoch 25/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0511e-04 - val_loss: 1.0675e-04\n",
            "Epoch 26/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0450e-04 - val_loss: 9.8432e-05\n",
            "Epoch 27/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0468e-04 - val_loss: 1.3070e-04\n",
            "Epoch 28/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 1.0778e-04 - val_loss: 1.1664e-04\n",
            "Epoch 29/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.0795e-04 - val_loss: 1.0557e-04\n",
            "Epoch 30/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0891e-04 - val_loss: 9.7935e-05\n",
            "Epoch 31/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.0632e-04 - val_loss: 1.0004e-04\n",
            "Epoch 32/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0435e-04 - val_loss: 1.2927e-04\n",
            "Epoch 33/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0359e-04 - val_loss: 1.1973e-04\n",
            "Epoch 34/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0477e-04 - val_loss: 1.0633e-04\n",
            "Epoch 35/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 1.0636e-04 - val_loss: 1.0238e-04\n",
            "Epoch 36/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0094e-04 - val_loss: 1.1797e-04\n",
            "Epoch 37/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0365e-04 - val_loss: 1.1933e-04\n",
            "Epoch 38/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0485e-04 - val_loss: 1.0086e-04\n",
            "Epoch 39/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.9694e-05 - val_loss: 1.0274e-04\n",
            "Epoch 40/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0030e-04 - val_loss: 1.0305e-04\n",
            "Epoch 41/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.0018e-04 - val_loss: 1.2445e-04\n",
            "Epoch 42/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 1.0261e-04 - val_loss: 1.0147e-04\n",
            "Epoch 43/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0148e-04 - val_loss: 9.7757e-05\n",
            "Epoch 44/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.8232e-05 - val_loss: 1.1217e-04\n",
            "Epoch 45/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0303e-04 - val_loss: 1.0387e-04\n",
            "Epoch 46/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.9840e-05 - val_loss: 1.0178e-04\n",
            "Epoch 47/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.8834e-05 - val_loss: 1.0421e-04\n",
            "Epoch 48/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 9.8408e-05 - val_loss: 9.7595e-05\n",
            "Epoch 49/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 9.7931e-05 - val_loss: 1.0254e-04\n",
            "Epoch 50/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0018e-04 - val_loss: 1.0699e-04\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n",
            "300/300 [==============================] - 5s 7ms/step - loss: 2.3912e-04 - val_loss: 1.2863e-04\n",
            "Epoch 2/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.2513e-04 - val_loss: 1.2447e-04\n",
            "Epoch 3/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.2295e-04 - val_loss: 1.1477e-04\n",
            "Epoch 4/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.1821e-04 - val_loss: 1.1642e-04\n",
            "Epoch 5/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 1.1614e-04 - val_loss: 1.0794e-04\n",
            "Epoch 6/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 1.1693e-04 - val_loss: 1.2084e-04\n",
            "Epoch 7/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.1147e-04 - val_loss: 1.1323e-04\n",
            "Epoch 8/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1049e-04 - val_loss: 1.0909e-04\n",
            "Epoch 9/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1131e-04 - val_loss: 1.0998e-04\n",
            "Epoch 10/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0799e-04 - val_loss: 1.1309e-04\n",
            "Epoch 11/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0922e-04 - val_loss: 1.0075e-04\n",
            "Epoch 12/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 1.0737e-04 - val_loss: 1.0789e-04\n",
            "Epoch 13/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.0641e-04 - val_loss: 1.1391e-04\n",
            "Epoch 14/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.0748e-04 - val_loss: 1.2294e-04\n",
            "Epoch 15/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.0627e-04 - val_loss: 9.9015e-05\n",
            "Epoch 16/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0531e-04 - val_loss: 1.1045e-04\n",
            "Epoch 17/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0452e-04 - val_loss: 1.9363e-04\n",
            "Epoch 18/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.0645e-04 - val_loss: 1.0061e-04\n",
            "Epoch 19/50\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 9.9570e-05 - val_loss: 1.0035e-04\n",
            "Epoch 20/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0136e-04 - val_loss: 1.0472e-04\n",
            "Epoch 21/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.0026e-04 - val_loss: 1.0166e-04\n",
            "Epoch 22/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0013e-04 - val_loss: 1.0641e-04\n",
            "Epoch 23/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.5951e-05 - val_loss: 9.8596e-05\n",
            "Epoch 24/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0265e-04 - val_loss: 1.0792e-04\n",
            "Epoch 25/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 9.6928e-05 - val_loss: 9.8543e-05\n",
            "Epoch 26/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 9.6449e-05 - val_loss: 9.5946e-05\n",
            "Epoch 27/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.7343e-05 - val_loss: 8.8313e-05\n",
            "Epoch 28/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.5787e-05 - val_loss: 1.0645e-04\n",
            "Epoch 29/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.6554e-05 - val_loss: 1.0249e-04\n",
            "Epoch 30/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.5375e-05 - val_loss: 1.0279e-04\n",
            "Epoch 31/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.9518e-05 - val_loss: 1.0729e-04\n",
            "Epoch 32/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 9.7118e-05 - val_loss: 9.5569e-05\n",
            "Epoch 33/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 9.5930e-05 - val_loss: 8.8961e-05\n",
            "Epoch 34/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.3292e-05 - val_loss: 1.0467e-04\n",
            "Epoch 35/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.3373e-05 - val_loss: 1.0076e-04\n",
            "Epoch 36/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.3849e-05 - val_loss: 9.5875e-05\n",
            "Epoch 37/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.2143e-05 - val_loss: 9.8520e-05\n",
            "Epoch 38/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.2177e-05 - val_loss: 9.3642e-05\n",
            "Epoch 39/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 8.9541e-05 - val_loss: 8.4922e-05\n",
            "Epoch 40/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.3516e-05 - val_loss: 1.0286e-04\n",
            "Epoch 41/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.0777e-05 - val_loss: 8.6733e-05\n",
            "Epoch 42/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.5774e-05 - val_loss: 1.0007e-04\n",
            "Epoch 43/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.0147e-05 - val_loss: 9.2124e-05\n",
            "Epoch 44/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.0453e-05 - val_loss: 1.0380e-04\n",
            "Epoch 45/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.0268e-05 - val_loss: 8.6014e-05\n",
            "Epoch 46/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 8.9288e-05 - val_loss: 9.0423e-05\n",
            "Epoch 47/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.8089e-05 - val_loss: 8.5282e-05\n",
            "Epoch 48/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.8962e-05 - val_loss: 1.0578e-04\n",
            "Epoch 49/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.9625e-05 - val_loss: 8.5970e-05\n",
            "Epoch 50/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.6975e-05 - val_loss: 9.5752e-05\n",
            "63/63 [==============================] - 1s 3ms/step\n",
            "Epoch 1/50\n",
            "300/300 [==============================] - 5s 7ms/step - loss: 2.2618e-04 - val_loss: 1.3209e-04\n",
            "Epoch 2/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 1.2559e-04 - val_loss: 1.2238e-04\n",
            "Epoch 3/50\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 1.2015e-04 - val_loss: 1.0862e-04\n",
            "Epoch 4/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1189e-04 - val_loss: 1.0830e-04\n",
            "Epoch 5/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1263e-04 - val_loss: 1.2611e-04\n",
            "Epoch 6/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1276e-04 - val_loss: 1.0849e-04\n",
            "Epoch 7/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1234e-04 - val_loss: 1.1166e-04\n",
            "Epoch 8/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0575e-04 - val_loss: 1.0124e-04\n",
            "Epoch 9/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 1.0719e-04 - val_loss: 9.8545e-05\n",
            "Epoch 10/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.0585e-04 - val_loss: 1.5515e-04\n",
            "Epoch 11/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1207e-04 - val_loss: 1.0492e-04\n",
            "Epoch 12/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0962e-04 - val_loss: 1.0512e-04\n",
            "Epoch 13/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.0810e-04 - val_loss: 1.1005e-04\n",
            "Epoch 14/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0435e-04 - val_loss: 1.0119e-04\n",
            "Epoch 15/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.9530e-05 - val_loss: 1.0502e-04\n",
            "Epoch 16/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 1.0126e-04 - val_loss: 9.6062e-05\n",
            "Epoch 17/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0301e-04 - val_loss: 1.0383e-04\n",
            "Epoch 18/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.0052e-04 - val_loss: 9.2299e-05\n",
            "Epoch 19/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.7294e-05 - val_loss: 1.0119e-04\n",
            "Epoch 20/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0140e-04 - val_loss: 9.6047e-05\n",
            "Epoch 21/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.8534e-05 - val_loss: 1.2440e-04\n",
            "Epoch 22/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 9.9973e-05 - val_loss: 1.0082e-04\n",
            "Epoch 23/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 9.7071e-05 - val_loss: 9.6832e-05\n",
            "Epoch 24/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.8966e-05 - val_loss: 9.1357e-05\n",
            "Epoch 25/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.5941e-05 - val_loss: 9.7273e-05\n",
            "Epoch 26/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.3731e-05 - val_loss: 8.6068e-05\n",
            "Epoch 27/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.7468e-05 - val_loss: 8.5485e-05\n",
            "Epoch 28/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.6144e-05 - val_loss: 8.6619e-05\n",
            "Epoch 29/50\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 9.6374e-05 - val_loss: 1.1327e-04\n",
            "Epoch 30/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 9.2970e-05 - val_loss: 9.2429e-05\n",
            "Epoch 31/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.2123e-05 - val_loss: 9.8432e-05\n",
            "Epoch 32/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.8495e-05 - val_loss: 8.4340e-05\n",
            "Epoch 33/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.1689e-05 - val_loss: 1.2728e-04\n",
            "Epoch 34/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.1620e-05 - val_loss: 9.0161e-05\n",
            "Epoch 35/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.0391e-05 - val_loss: 1.0302e-04\n",
            "Epoch 36/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 9.0683e-05 - val_loss: 8.2540e-05\n",
            "Epoch 37/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.9254e-05 - val_loss: 9.1806e-05\n",
            "Epoch 38/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.8586e-05 - val_loss: 9.7640e-05\n",
            "Epoch 39/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.8711e-05 - val_loss: 8.4990e-05\n",
            "Epoch 40/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.9272e-05 - val_loss: 9.0805e-05\n",
            "Epoch 41/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.8103e-05 - val_loss: 9.9067e-05\n",
            "Epoch 42/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 8.6612e-05 - val_loss: 9.0715e-05\n",
            "Epoch 43/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 9.2253e-05 - val_loss: 8.3412e-05\n",
            "Epoch 44/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 8.6290e-05 - val_loss: 1.0277e-04\n",
            "Epoch 45/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.9778e-05 - val_loss: 9.9778e-05\n",
            "Epoch 46/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 8.7310e-05 - val_loss: 9.0999e-05\n",
            "Epoch 47/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.4901e-05 - val_loss: 8.8307e-05\n",
            "Epoch 48/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.6793e-05 - val_loss: 9.4833e-05\n",
            "Epoch 49/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 8.4340e-05 - val_loss: 8.3708e-05\n",
            "Epoch 50/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 8.5839e-05 - val_loss: 9.0015e-05\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n",
            "300/300 [==============================] - 6s 11ms/step - loss: 2.4247e-04 - val_loss: 1.3458e-04\n",
            "Epoch 2/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.2844e-04 - val_loss: 1.4786e-04\n",
            "Epoch 3/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1916e-04 - val_loss: 1.1387e-04\n",
            "Epoch 4/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1631e-04 - val_loss: 1.0341e-04\n",
            "Epoch 5/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1415e-04 - val_loss: 1.1188e-04\n",
            "Epoch 6/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.1064e-04 - val_loss: 1.0674e-04\n",
            "Epoch 7/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 1.1265e-04 - val_loss: 1.0261e-04\n",
            "Epoch 8/50\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 1.1064e-04 - val_loss: 9.9391e-05\n",
            "Epoch 9/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0894e-04 - val_loss: 9.7449e-05\n",
            "Epoch 10/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0788e-04 - val_loss: 1.0820e-04\n",
            "Epoch 11/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0874e-04 - val_loss: 9.9185e-05\n",
            "Epoch 12/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0562e-04 - val_loss: 1.0354e-04\n",
            "Epoch 13/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0893e-04 - val_loss: 1.0024e-04\n",
            "Epoch 14/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 1.0347e-04 - val_loss: 1.0579e-04\n",
            "Epoch 15/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.0681e-04 - val_loss: 1.0382e-04\n",
            "Epoch 16/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.8962e-05 - val_loss: 9.5258e-05\n",
            "Epoch 17/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 1.0183e-04 - val_loss: 1.0267e-04\n",
            "Epoch 18/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0439e-04 - val_loss: 9.3903e-05\n",
            "Epoch 19/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 1.0365e-04 - val_loss: 9.5473e-05\n",
            "Epoch 20/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.9485e-05 - val_loss: 9.5830e-05\n",
            "Epoch 21/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 9.7172e-05 - val_loss: 1.0792e-04\n",
            "Epoch 22/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.7596e-05 - val_loss: 9.4787e-05\n",
            "Epoch 23/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.7950e-05 - val_loss: 1.1475e-04\n",
            "Epoch 24/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.5651e-05 - val_loss: 1.0279e-04\n",
            "Epoch 25/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.9157e-05 - val_loss: 9.8879e-05\n",
            "Epoch 26/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.5811e-05 - val_loss: 9.0699e-05\n",
            "Epoch 27/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 9.6113e-05 - val_loss: 9.7926e-05\n",
            "Epoch 28/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 9.4268e-05 - val_loss: 1.1206e-04\n",
            "Epoch 29/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.4094e-05 - val_loss: 8.7386e-05\n",
            "Epoch 30/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.5729e-05 - val_loss: 9.6285e-05\n",
            "Epoch 31/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.9902e-05 - val_loss: 9.0442e-05\n",
            "Epoch 32/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.1005e-05 - val_loss: 9.0615e-05\n",
            "Epoch 33/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.1606e-05 - val_loss: 9.3700e-05\n",
            "Epoch 34/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 9.1821e-05 - val_loss: 9.3240e-05\n",
            "Epoch 35/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 9.1232e-05 - val_loss: 9.6786e-05\n",
            "Epoch 36/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.9489e-05 - val_loss: 8.9441e-05\n",
            "Epoch 37/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.6217e-05 - val_loss: 8.7372e-05\n",
            "Epoch 38/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.1226e-05 - val_loss: 1.1924e-04\n",
            "Epoch 39/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 9.1371e-05 - val_loss: 8.8938e-05\n",
            "Epoch 40/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.9392e-05 - val_loss: 9.4874e-05\n",
            "Epoch 41/50\n",
            "300/300 [==============================] - 3s 8ms/step - loss: 8.9443e-05 - val_loss: 1.2216e-04\n",
            "Epoch 42/50\n",
            "300/300 [==============================] - 2s 7ms/step - loss: 9.0795e-05 - val_loss: 8.9031e-05\n",
            "Epoch 43/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.8481e-05 - val_loss: 9.9396e-05\n",
            "Epoch 44/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.7777e-05 - val_loss: 9.3176e-05\n",
            "Epoch 45/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.5376e-05 - val_loss: 8.3429e-05\n",
            "Epoch 46/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.6082e-05 - val_loss: 9.2112e-05\n",
            "Epoch 47/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.4952e-05 - val_loss: 9.6327e-05\n",
            "Epoch 48/50\n",
            "300/300 [==============================] - 3s 9ms/step - loss: 8.7411e-05 - val_loss: 9.7799e-05\n",
            "Epoch 49/50\n",
            "300/300 [==============================] - 2s 8ms/step - loss: 8.8087e-05 - val_loss: 8.3915e-05\n",
            "Epoch 50/50\n",
            "300/300 [==============================] - 2s 6ms/step - loss: 8.9135e-05 - val_loss: 8.6023e-05\n",
            "63/63 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "answer_sample = pd.read_csv('answer_sample.csv', header=None)\n",
        "answer_sample.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "uT31GG13v0Dz",
        "outputId": "e9c768a0-f70f-411c-9c78-7a7043e381a1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0                    1                    2                   3   \\\n",
              "0  Distance      YL_M1_B1_W1_s30      YR_M1_B1_W1_s30     YL_M1_B1_W2_s30   \n",
              "1   2500.25  -3.0934884548187256  -1.4886139631271362   20.01789093017578   \n",
              "2    2500.5  -2.2509000301361084    -1.34923255443573  19.740528106689453   \n",
              "3   2500.75   1.4095127582550049   1.2128592729568481  19.660186767578125   \n",
              "4    2501.0   2.6432268619537354   2.2171010971069336  19.893169403076172   \n",
              "\n",
              "                    4                    5                    6   \\\n",
              "0      YR_M1_B1_W2_s30      YL_M1_B1_W1_s40      YR_M1_B1_W1_s40   \n",
              "1   -34.83118438720703  -0.3079476058483124   -5.391927242279053   \n",
              "2    -34.8693962097168   0.4328317940235138   -4.951985836029053   \n",
              "3  -34.815792083740234    3.013756275177002    -3.26092267036438   \n",
              "4   -35.54393005371094       4.662353515625  -2.4610416889190674   \n",
              "\n",
              "                   7                   8                   9   ...  \\\n",
              "0     YL_M1_B1_W2_s40     YR_M1_B1_W2_s40     YL_M1_B1_W1_s50  ...   \n",
              "1  3.5623786449432373  -7.828848361968994   5.366372585296631  ...   \n",
              "2   4.133959770202637  -8.332554817199707   6.211326599121094  ...   \n",
              "3   4.375100135803223  -9.513163566589355    9.22378158569336  ...   \n",
              "4   4.614716529846191  -10.21658992767334  11.517169952392578  ...   \n",
              "\n",
              "                    31                   32                   33  \\\n",
              "0      YL_M1_B1_W2_c50      YR_M1_B1_W2_c50      YL_M1_B1_W1_c70   \n",
              "1   -3.894071340560913  -36.648765563964844  -58.144840240478516   \n",
              "2  -3.6030831336975098  -36.858070373535156   -57.30297088623047   \n",
              "3   -2.607984781265259  -37.675514221191406   -54.00553894042969   \n",
              "4   -1.684582233428955  -38.659664154052734  -52.000579833984375   \n",
              "\n",
              "                    34                   35                   36  \\\n",
              "0      YR_M1_B1_W1_c70      YL_M1_B1_W2_c70      YR_M1_B1_W2_c70   \n",
              "1  -52.452613830566406   -25.34734344482422  -45.123416900634766   \n",
              "2   -50.87465286254883  -24.833837509155273   -45.28736114501953   \n",
              "3   -47.01079559326172  -23.564468383789062    -46.1656608581543   \n",
              "4   -45.38255310058594   -22.53877830505371   -47.32369613647461   \n",
              "\n",
              "                   37                   38                  39  \\\n",
              "0    YL_M1_B1_W1_c100     YR_M1_B1_W1_c100    YL_M1_B1_W2_c100   \n",
              "1   10.21291732788086   -20.53331184387207  12.387517929077148   \n",
              "2  11.046222686767578  -19.129724502563477  12.802045822143555   \n",
              "3   14.39602279663086  -15.092873573303223  14.033159255981445   \n",
              "4   16.39366340637207  -13.429675102233887  14.918346405029297   \n",
              "\n",
              "                    40  \n",
              "0     YR_M1_B1_W2_c100  \n",
              "1    -29.0419979095459  \n",
              "2   -29.59121322631836  \n",
              "3  -30.982730865478516  \n",
              "4  -32.055450439453125  \n",
              "\n",
              "[5 rows x 41 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-ca97db90-259b-48fc-8b70-0e3ad5ab2a06\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Distance</td>\n",
              "      <td>YL_M1_B1_W1_s30</td>\n",
              "      <td>YR_M1_B1_W1_s30</td>\n",
              "      <td>YL_M1_B1_W2_s30</td>\n",
              "      <td>YR_M1_B1_W2_s30</td>\n",
              "      <td>YL_M1_B1_W1_s40</td>\n",
              "      <td>YR_M1_B1_W1_s40</td>\n",
              "      <td>YL_M1_B1_W2_s40</td>\n",
              "      <td>YR_M1_B1_W2_s40</td>\n",
              "      <td>YL_M1_B1_W1_s50</td>\n",
              "      <td>...</td>\n",
              "      <td>YL_M1_B1_W2_c50</td>\n",
              "      <td>YR_M1_B1_W2_c50</td>\n",
              "      <td>YL_M1_B1_W1_c70</td>\n",
              "      <td>YR_M1_B1_W1_c70</td>\n",
              "      <td>YL_M1_B1_W2_c70</td>\n",
              "      <td>YR_M1_B1_W2_c70</td>\n",
              "      <td>YL_M1_B1_W1_c100</td>\n",
              "      <td>YR_M1_B1_W1_c100</td>\n",
              "      <td>YL_M1_B1_W2_c100</td>\n",
              "      <td>YR_M1_B1_W2_c100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2500.25</td>\n",
              "      <td>-3.0934884548187256</td>\n",
              "      <td>-1.4886139631271362</td>\n",
              "      <td>20.01789093017578</td>\n",
              "      <td>-34.83118438720703</td>\n",
              "      <td>-0.3079476058483124</td>\n",
              "      <td>-5.391927242279053</td>\n",
              "      <td>3.5623786449432373</td>\n",
              "      <td>-7.828848361968994</td>\n",
              "      <td>5.366372585296631</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.894071340560913</td>\n",
              "      <td>-36.648765563964844</td>\n",
              "      <td>-58.144840240478516</td>\n",
              "      <td>-52.452613830566406</td>\n",
              "      <td>-25.34734344482422</td>\n",
              "      <td>-45.123416900634766</td>\n",
              "      <td>10.21291732788086</td>\n",
              "      <td>-20.53331184387207</td>\n",
              "      <td>12.387517929077148</td>\n",
              "      <td>-29.0419979095459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2500.5</td>\n",
              "      <td>-2.2509000301361084</td>\n",
              "      <td>-1.34923255443573</td>\n",
              "      <td>19.740528106689453</td>\n",
              "      <td>-34.8693962097168</td>\n",
              "      <td>0.4328317940235138</td>\n",
              "      <td>-4.951985836029053</td>\n",
              "      <td>4.133959770202637</td>\n",
              "      <td>-8.332554817199707</td>\n",
              "      <td>6.211326599121094</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.6030831336975098</td>\n",
              "      <td>-36.858070373535156</td>\n",
              "      <td>-57.30297088623047</td>\n",
              "      <td>-50.87465286254883</td>\n",
              "      <td>-24.833837509155273</td>\n",
              "      <td>-45.28736114501953</td>\n",
              "      <td>11.046222686767578</td>\n",
              "      <td>-19.129724502563477</td>\n",
              "      <td>12.802045822143555</td>\n",
              "      <td>-29.59121322631836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2500.75</td>\n",
              "      <td>1.4095127582550049</td>\n",
              "      <td>1.2128592729568481</td>\n",
              "      <td>19.660186767578125</td>\n",
              "      <td>-34.815792083740234</td>\n",
              "      <td>3.013756275177002</td>\n",
              "      <td>-3.26092267036438</td>\n",
              "      <td>4.375100135803223</td>\n",
              "      <td>-9.513163566589355</td>\n",
              "      <td>9.22378158569336</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.607984781265259</td>\n",
              "      <td>-37.675514221191406</td>\n",
              "      <td>-54.00553894042969</td>\n",
              "      <td>-47.01079559326172</td>\n",
              "      <td>-23.564468383789062</td>\n",
              "      <td>-46.1656608581543</td>\n",
              "      <td>14.39602279663086</td>\n",
              "      <td>-15.092873573303223</td>\n",
              "      <td>14.033159255981445</td>\n",
              "      <td>-30.982730865478516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2501.0</td>\n",
              "      <td>2.6432268619537354</td>\n",
              "      <td>2.2171010971069336</td>\n",
              "      <td>19.893169403076172</td>\n",
              "      <td>-35.54393005371094</td>\n",
              "      <td>4.662353515625</td>\n",
              "      <td>-2.4610416889190674</td>\n",
              "      <td>4.614716529846191</td>\n",
              "      <td>-10.21658992767334</td>\n",
              "      <td>11.517169952392578</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.684582233428955</td>\n",
              "      <td>-38.659664154052734</td>\n",
              "      <td>-52.000579833984375</td>\n",
              "      <td>-45.38255310058594</td>\n",
              "      <td>-22.53877830505371</td>\n",
              "      <td>-47.32369613647461</td>\n",
              "      <td>16.39366340637207</td>\n",
              "      <td>-13.429675102233887</td>\n",
              "      <td>14.918346405029297</td>\n",
              "      <td>-32.055450439453125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 41 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca97db90-259b-48fc-8b70-0e3ad5ab2a06')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-aeeeae16-cc52-4adb-b0f2-0d0570812279\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aeeeae16-cc52-4adb-b0f2-0d0570812279')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-aeeeae16-cc52-4adb-b0f2-0d0570812279 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ca97db90-259b-48fc-8b70-0e3ad5ab2a06 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ca97db90-259b-48fc-8b70-0e3ad5ab2a06');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}