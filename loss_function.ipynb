{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPXsTRZ8RvxC2xULIO82GsQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ByeonJaeseong/DeepLearningProject/blob/main/loss_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "2jMccpbFTnKQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import  fetch_openml\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "def sum_squares_error(y, t):\n",
        "    return 0.5 * np,sum((y-t)**2)\n",
        "\n",
        "\n",
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "\n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(t*np.log(y+1e-7))/batch_size \n",
        "\n",
        "def numerical_diff(f,x):\n",
        "    h = 1e-4\n",
        "    return(f(x+h)-f(x-h))/(2*h)\n",
        "\n",
        "def function_1(x):\n",
        "    return 0.01*x**2+0.1*x\n",
        "\n",
        "def function_2(x):\n",
        "    return x[0]**2 + x[1]**2\n",
        "\n",
        "def numerical_gradient(f,x):\n",
        "    h = 1e-4\n",
        "    grad = np.zeros_like(x)\n",
        "    \n",
        "    for idx in range(x.size):\n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = tmp_val +h\n",
        "        fxh1 = f(x)\n",
        "\n",
        "        x[idx] = tmp_val-h\n",
        "        fxh2 = f(x)\n",
        "\n",
        "        grad[idx] = (fxh1-fxh2) / (2*h)\n",
        "        x[idx] = tmp_val\n",
        "\n",
        "    return grad\n",
        "\n",
        "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
        "    x = init_x\n",
        "\n",
        "    for i in range(step_num):\n",
        "        grad = numerical_gradient(f,x)\n",
        "        x-= lr*grad\n",
        "    return x\n",
        "\n",
        "def softmax(a):\n",
        "    c = np.max(a)\n",
        "    exp_a = np.exp(a-c)\n",
        "    sum_exp_a = np.sum(exp_a)\n",
        "    y = exp_a / sum_exp_a\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "class simpleNet:\n",
        "    def __init__(self):\n",
        "        self.W = np.random.randn(2, 3)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return np.dot(x, self.W)\n",
        "\n",
        "    def loss(self, x, t):\n",
        "        z = self.predict(x)\n",
        "        y = softmax(z)\n",
        "        loss = cross_entropy_error(y, t)\n",
        "\n",
        "        return loss      "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "X, y = mnist[\"data\"], mnist[\"target\"]\n",
        "x_train, x_test, t_train, t_test = X[:60000], X[60000:], y[:60000], y[60000:]\n"
      ],
      "metadata": {
        "id": "ptOZBPJsXYiW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(t_train.shape)\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 10\n",
        "batch_mask = np.random.choice(train_size, batch_size)\n",
        "x_batch = x_train[batch_mask]\n",
        "t_batch = t_train[batch_mask]\n",
        "np.random.choice(60000,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7RmDHWmXSZX",
        "outputId": "2b2aca60-691d-425f-ec8b-3fa4eef20157"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(60000,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([29231, 28086,  2844, 51285, 43598, 10720, 17483, 28754, 59390,\n",
              "       14631])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(numerical_gradient(function_2, np.array([3.0, 4.0])))\n",
        "print(numerical_gradient(function_2, np.array([0.0, 2.0])))\n",
        "print(numerical_gradient(function_2, np.array([3.0, 0.0])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekfSh0mMM8Di",
        "outputId": "023135e4-5eea-4d4e-95de-7f334a229f85"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6. 8.]\n",
            "[0. 4.]\n",
            "[6. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gradient_descent(function_2, init_x=np.array([-3.0, 4.0]), lr=0.1, step_num=100))\n",
        "print(gradient_descent(function_2, init_x=np.array([-3.0, 4.0]), lr=10, step_num=100)) #발산\n",
        "print(gradient_descent(function_2, init_x=np.array([-3.0, 4.0]), lr=1e-10, step_num=100)) #수렴못함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-MD35KlOKwC",
        "outputId": "a4a17bfa-c700-4525-b55a-aa01d97a4d96"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-6.11110793e-10  8.14814391e-10]\n",
            "[-2.58983747e+13 -1.29524862e+12]\n",
            "[-2.99999994  3.99999992]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = simpleNet()\n",
        "print(net.W)\n",
        "x = np.array([0.6, 0.9])\n",
        "p = net.predict(x)\n",
        "print(p)\n",
        "\n",
        "np.argmax(p)\n",
        "\n",
        "t = np.array([0,0,1])\n",
        "\n",
        "print()\n",
        "softmax(net.predict(x))\n",
        "\n",
        "net.loss(x, t)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzXGxAerQnSg",
        "outputId": "1ffaf253-cff3-4ff7-9ad7-ff41d2aedd4a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.31738361  0.41058017  0.96290367]\n",
            " [-1.98094259 -0.62120651  1.00153851]]\n",
            "[-0.99241817 -0.31273776  1.47912686]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2240257695289369"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    }
  ]
}