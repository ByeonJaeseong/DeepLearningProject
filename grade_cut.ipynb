{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "14okYe7l-5w312k9O6JasyqbRqUJM_lMm",
      "authorship_tag": "ABX9TyMxPyYzvuuV4153LM5eaSM8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ByeonJaeseong/DeepLearningProject/blob/main/grade_cut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g3sdZg5c5u6x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "1a762e4e-fc64-4e5a-a507-50891d6c7c9e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9d666593-4907-4525-9723-464f4dcae89b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9d666593-4907-4525-9723-464f4dcae89b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving grade_cut.cell to grade_cut.cell\n",
            "Saving grade_cut_modi.cell to grade_cut_modi.cell\n",
            "Saving percentage_of_correct_answers.cell to percentage_of_correct_answers.cell\n",
            "Saving percentage_of_correct_answers_modi.cell to percentage_of_correct_answers_modi.cell\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 업로드\n",
        "df_data = pd.read_excel('percentage_of_correct_answers_modi.cell', index_col=0)\n",
        "df_data.head()\n",
        "df_data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "1rNoOkrR6ALP",
        "outputId": "fba8caca-e17f-48df-ae07-ea33537c8456"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0           1           2           3           4           5   \\\n",
              "count  291.000000  291.000000  291.000000  291.000000  291.000000  291.000000   \n",
              "mean    91.701031   94.343643   90.453608   88.941581   91.017182   86.257732   \n",
              "std      4.023633   44.084231    4.640944    5.302572   47.212393    7.369946   \n",
              "min     71.000000   77.000000   66.000000   66.000000   58.000000   56.000000   \n",
              "25%     90.000000   90.000000   88.000000   87.000000   86.000000   84.000000   \n",
              "50%     92.000000   93.000000   92.000000   90.000000   89.000000   88.000000   \n",
              "75%     95.000000   94.500000   94.000000   92.000000   92.000000   91.000000   \n",
              "max     98.000000  841.000000   98.000000   97.000000  888.000000   97.000000   \n",
              "\n",
              "               6           7           8           9   ...         20  \\\n",
              "count  291.000000  291.000000  291.000000  291.000000  ...  291.00000   \n",
              "mean    84.962199   82.965636   84.632302   80.271478  ...   43.00000   \n",
              "std      8.006158    8.630271   46.971512    9.282084  ...   12.87687   \n",
              "min     33.000000   38.000000   54.000000   50.000000  ...   12.00000   \n",
              "25%     82.000000   79.000000   78.000000   77.000000  ...   34.00000   \n",
              "50%     87.000000   85.000000   84.000000   82.000000  ...   42.00000   \n",
              "75%     90.500000   89.000000   88.000000   87.000000  ...   51.00000   \n",
              "max     96.000000   96.000000  870.000000   96.000000  ...   84.00000   \n",
              "\n",
              "               21          22          23          24          25          26  \\\n",
              "count  291.000000  291.000000  291.000000  291.000000  291.000000  291.000000   \n",
              "mean    86.199313   81.195876   74.845361   69.333333   56.068729   45.793814   \n",
              "std      6.220223   10.723136   12.499109   13.544393   17.522855   18.726860   \n",
              "min     58.000000   32.000000   29.000000   22.000000    8.000000    3.000000   \n",
              "25%     83.000000   77.000000   68.500000   60.500000   45.000000   32.000000   \n",
              "50%     88.000000   84.000000   78.000000   71.000000   59.000000   46.000000   \n",
              "75%     91.000000   89.000000   84.000000   80.000000   69.000000   61.000000   \n",
              "max     96.000000   95.000000   94.000000   92.000000   89.000000   87.000000   \n",
              "\n",
              "               27          28          29  \n",
              "count  291.000000  291.000000  291.000000  \n",
              "mean    40.134021   25.408935   14.151203  \n",
              "std     16.768379   15.211196   12.725666  \n",
              "min      7.000000    4.000000    0.000000  \n",
              "25%     27.000000   14.000000    6.000000  \n",
              "50%     39.000000   22.000000   10.000000  \n",
              "75%     51.500000   34.000000   18.000000  \n",
              "max     82.000000   79.000000  100.000000  \n",
              "\n",
              "[8 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7713d26-e83b-435a-b876-85a1a411231a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>291.00000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "      <td>291.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>91.701031</td>\n",
              "      <td>94.343643</td>\n",
              "      <td>90.453608</td>\n",
              "      <td>88.941581</td>\n",
              "      <td>91.017182</td>\n",
              "      <td>86.257732</td>\n",
              "      <td>84.962199</td>\n",
              "      <td>82.965636</td>\n",
              "      <td>84.632302</td>\n",
              "      <td>80.271478</td>\n",
              "      <td>...</td>\n",
              "      <td>43.00000</td>\n",
              "      <td>86.199313</td>\n",
              "      <td>81.195876</td>\n",
              "      <td>74.845361</td>\n",
              "      <td>69.333333</td>\n",
              "      <td>56.068729</td>\n",
              "      <td>45.793814</td>\n",
              "      <td>40.134021</td>\n",
              "      <td>25.408935</td>\n",
              "      <td>14.151203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.023633</td>\n",
              "      <td>44.084231</td>\n",
              "      <td>4.640944</td>\n",
              "      <td>5.302572</td>\n",
              "      <td>47.212393</td>\n",
              "      <td>7.369946</td>\n",
              "      <td>8.006158</td>\n",
              "      <td>8.630271</td>\n",
              "      <td>46.971512</td>\n",
              "      <td>9.282084</td>\n",
              "      <td>...</td>\n",
              "      <td>12.87687</td>\n",
              "      <td>6.220223</td>\n",
              "      <td>10.723136</td>\n",
              "      <td>12.499109</td>\n",
              "      <td>13.544393</td>\n",
              "      <td>17.522855</td>\n",
              "      <td>18.726860</td>\n",
              "      <td>16.768379</td>\n",
              "      <td>15.211196</td>\n",
              "      <td>12.725666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>71.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>12.00000</td>\n",
              "      <td>58.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>90.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>86.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>34.00000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>68.500000</td>\n",
              "      <td>60.500000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>92.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>42.00000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>95.000000</td>\n",
              "      <td>94.500000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>90.500000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>51.00000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>51.500000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>18.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>98.000000</td>\n",
              "      <td>841.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>888.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>870.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>84.00000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7713d26-e83b-435a-b876-85a1a411231a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7713d26-e83b-435a-b876-85a1a411231a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7713d26-e83b-435a-b876-85a1a411231a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 타겟 데이터 업로드\n",
        "df_target = pd.read_excel('grade_cut_modi.cell', index_col=0)\n",
        "df_target.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "FeAREfRr66Ut",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f01940d3-e33f-49e8-c7b3-70e38e476191"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0    1    2    3    4   5   6   7   8\n",
              "0  151  138  128  118  103  89  81  79  75\n",
              "1  158  138  128  118  103  89  81  79  75\n",
              "2  157  138  128  118  103  89  81  79  75\n",
              "3  145  133  126  119  107  91  80  76  72\n",
              "4  145  133  126  119  107  91  80  76  72"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ae94a06-26e7-4055-a0be-06248174edab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>151</td>\n",
              "      <td>138</td>\n",
              "      <td>128</td>\n",
              "      <td>118</td>\n",
              "      <td>103</td>\n",
              "      <td>89</td>\n",
              "      <td>81</td>\n",
              "      <td>79</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>158</td>\n",
              "      <td>138</td>\n",
              "      <td>128</td>\n",
              "      <td>118</td>\n",
              "      <td>103</td>\n",
              "      <td>89</td>\n",
              "      <td>81</td>\n",
              "      <td>79</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>157</td>\n",
              "      <td>138</td>\n",
              "      <td>128</td>\n",
              "      <td>118</td>\n",
              "      <td>103</td>\n",
              "      <td>89</td>\n",
              "      <td>81</td>\n",
              "      <td>79</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>145</td>\n",
              "      <td>133</td>\n",
              "      <td>126</td>\n",
              "      <td>119</td>\n",
              "      <td>107</td>\n",
              "      <td>91</td>\n",
              "      <td>80</td>\n",
              "      <td>76</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>145</td>\n",
              "      <td>133</td>\n",
              "      <td>126</td>\n",
              "      <td>119</td>\n",
              "      <td>107</td>\n",
              "      <td>91</td>\n",
              "      <td>80</td>\n",
              "      <td>76</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ae94a06-26e7-4055-a0be-06248174edab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ae94a06-26e7-4055-a0be-06248174edab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ae94a06-26e7-4055-a0be-06248174edab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_main = pd.concat([df_data, df_target], axis=1) # concatenate # data 합치기\n",
        "df_main.head()"
      ],
      "metadata": {
        "id": "TekOsqEG7GCJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "c32ad72a-4443-41df-c073-f498dd5985e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0   1   2   3   4   5   6   7   8   9   ...  29   0    1    2    3    4   \\\n",
              "0  85  90  78  87  70  64  91  64  73  89  ...   1  151  138  128  118  103   \n",
              "1  95  96  93  96  87  79  94  84  88  82  ...   7  158  138  128  118  103   \n",
              "2  89  91  84  88  78  74  89  75  80  80  ...   6  157  138  128  118  103   \n",
              "3  82  80  79  85  80  60  82  80  60  77  ...   5  145  133  126  119  107   \n",
              "4  95  95  95  89  95  81  78  95  84  87  ...  10  145  133  126  119  107   \n",
              "\n",
              "   5   6   7   8   \n",
              "0  89  81  79  75  \n",
              "1  89  81  79  75  \n",
              "2  89  81  79  75  \n",
              "3  91  80  76  72  \n",
              "4  91  80  76  72  \n",
              "\n",
              "[5 rows x 39 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b9f35c5-6afd-4229-9110-44a946e79a37\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>29</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>85</td>\n",
              "      <td>90</td>\n",
              "      <td>78</td>\n",
              "      <td>87</td>\n",
              "      <td>70</td>\n",
              "      <td>64</td>\n",
              "      <td>91</td>\n",
              "      <td>64</td>\n",
              "      <td>73</td>\n",
              "      <td>89</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>151</td>\n",
              "      <td>138</td>\n",
              "      <td>128</td>\n",
              "      <td>118</td>\n",
              "      <td>103</td>\n",
              "      <td>89</td>\n",
              "      <td>81</td>\n",
              "      <td>79</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>95</td>\n",
              "      <td>96</td>\n",
              "      <td>93</td>\n",
              "      <td>96</td>\n",
              "      <td>87</td>\n",
              "      <td>79</td>\n",
              "      <td>94</td>\n",
              "      <td>84</td>\n",
              "      <td>88</td>\n",
              "      <td>82</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>158</td>\n",
              "      <td>138</td>\n",
              "      <td>128</td>\n",
              "      <td>118</td>\n",
              "      <td>103</td>\n",
              "      <td>89</td>\n",
              "      <td>81</td>\n",
              "      <td>79</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>89</td>\n",
              "      <td>91</td>\n",
              "      <td>84</td>\n",
              "      <td>88</td>\n",
              "      <td>78</td>\n",
              "      <td>74</td>\n",
              "      <td>89</td>\n",
              "      <td>75</td>\n",
              "      <td>80</td>\n",
              "      <td>80</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>157</td>\n",
              "      <td>138</td>\n",
              "      <td>128</td>\n",
              "      <td>118</td>\n",
              "      <td>103</td>\n",
              "      <td>89</td>\n",
              "      <td>81</td>\n",
              "      <td>79</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>82</td>\n",
              "      <td>80</td>\n",
              "      <td>79</td>\n",
              "      <td>85</td>\n",
              "      <td>80</td>\n",
              "      <td>60</td>\n",
              "      <td>82</td>\n",
              "      <td>80</td>\n",
              "      <td>60</td>\n",
              "      <td>77</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>145</td>\n",
              "      <td>133</td>\n",
              "      <td>126</td>\n",
              "      <td>119</td>\n",
              "      <td>107</td>\n",
              "      <td>91</td>\n",
              "      <td>80</td>\n",
              "      <td>76</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "      <td>89</td>\n",
              "      <td>95</td>\n",
              "      <td>81</td>\n",
              "      <td>78</td>\n",
              "      <td>95</td>\n",
              "      <td>84</td>\n",
              "      <td>87</td>\n",
              "      <td>...</td>\n",
              "      <td>10</td>\n",
              "      <td>145</td>\n",
              "      <td>133</td>\n",
              "      <td>126</td>\n",
              "      <td>119</td>\n",
              "      <td>107</td>\n",
              "      <td>91</td>\n",
              "      <td>80</td>\n",
              "      <td>76</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 39 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b9f35c5-6afd-4229-9110-44a946e79a37')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b9f35c5-6afd-4229-9110-44a946e79a37 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b9f35c5-6afd-4229-9110-44a946e79a37');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "percentage_data = np.array(df_data)\n",
        "grade_cut = np.array(df_target)\n",
        "pd.DataFrame(percentage_data)\n",
        "data_X = percentage_data[:]\n",
        "data_Y = grade_cut[:]\n",
        "print(data_X[0].shape)\n",
        "print(data_X)\n",
        "print(data_Y.shape)\n",
        "print(data_Y)\n"
      ],
      "metadata": {
        "id": "tpGQCQLXdPzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd18faa8-250d-42e9-ae86-4f9cd3b16133"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30,)\n",
            "[[85 90 78 ... 38 16  1]\n",
            " [95 96 93 ... 31  8  7]\n",
            " [89 91 84 ... 33 15  6]\n",
            " ...\n",
            " [85 86 85 ... 42 63  7]\n",
            " [89 90 90 ... 74 50 33]\n",
            " [87 82 85 ... 40 26 48]]\n",
            "(291, 9)\n",
            "[[151 138 128 ...  81  79  75]\n",
            " [158 138 128 ...  81  79  75]\n",
            " [157 138 128 ...  81  79  75]\n",
            " ...\n",
            " [155 141 129 ...  83  78  74]\n",
            " [141 138 130 ...  82  76  73]\n",
            " [156 141 127 ...  83  78  72]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zhbqUsoqh6YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "\n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(percentage_data, grade_cut, test_size=0.2, random_state=42)\n",
        "X_valid=x_train[:59]\n",
        "Y_valid=y_train[:59]\n",
        "X_train=x_train[59:]\n",
        "Y_train=y_train[59:]\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n"
      ],
      "metadata": {
        "id": "Gez7D-9Zivtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00370c6-6479-4cd2-ab80-f831cde81bd3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(232, 30)\n",
            "(59, 30)\n",
            "(232, 9)\n",
            "(59, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HuberLoss(keras.losses.Loss):\n",
        "    def __init__(self, threshold=1.0, **kwargs):\n",
        "        self.threshold = threshold\n",
        "        super().__init__(**kwargs)\n",
        "    def call(self, y_true, y_pred):\n",
        "##        tf.cast(y_pred|y_true, tf.float32|tf.float32)\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) < self.threshold\n",
        "        squared_loss = tf.square(error)/2\n",
        "        linear_loss = self.threshold*tf.abs(error) - self.threshold**2/2\n",
        "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return{**base_config, \"threshold\":self.threshold}    "
      ],
      "metadata": {
        "id": "VplIeL9Ex0KU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "initializer = tf.keras.initializers.Identity()\n",
        "\n",
        "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[30,], Huberloss=7):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.InputLayer(input_shape = input_shape))\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(keras.layers.Dense(n_neurons, activation=\"selu\"))\n",
        "    model.add(keras.layers.Dense(9, kernel_initializer=initializer))\n",
        "    optimizer = keras.optimizers.Nadam(learning_rate=learning_rate)\n",
        "    model.compile(loss=HuberLoss(Huberloss), optimizer=optimizer)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "n3-VD5lQrYsG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JsqJTsqvYUG",
        "outputId": "f02e3ae3-adb9-4d54-ee35-a42a9f47d676"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-651c14c6d32f>:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3bBHn6fpvjAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "initializer = tf.keras.initializers.Identity()\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_vaild = scaler.transform(X_valid)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "param_distribs = {\n",
        "    \"n_hidden\":np.arange(0, 5),\n",
        "    \"n_neurons\":np.arange(1,100),\n",
        "    \"learning_rate\":reciprocal(3e-5,3e-2),\n",
        "    \"Huberloss\":np.arange(1,15)\n",
        "}\n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=500, cv=3)\n",
        "rnd_search_cv.fit(X_train, Y_train, epochs=700, validation_data=(X_valid, Y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=20)])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# model = keras.models.Sequential([keras.layers.InputLayer(input_shape = [30,]),\n",
        "# keras.layers.Dropout(rate=0.3),                               \n",
        "# keras.layers.Dense(80, activation = \"selu\"),\n",
        "# keras.layers.BatchNormalization(),\n",
        "# keras.layers.Dropout(rate=0.3),\n",
        "# keras.layers.Dense(5, activation = \"selu\"),\n",
        "# ##keras.layers.Dense(2, activation = \"selu\"),\n",
        "# keras.layers.Dense(9, kernel_initializer=initializer)\n",
        "# ])\n",
        "# model.compile(loss=HuberLoss(10), optimizer = keras.optimizers.Nadam(learning_rate=0.0005), metrics=['accuracy'])\n",
        "\n",
        "# history = model.fit(X_train, Y_train, epochs = 700, validation_data = (X_valid, Y_valid))\n",
        "# mse_test = model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "id": "0r_yPLqIs9z6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b201891c-28aa-409b-e5b0-5857e35ab1e0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1291.9022 - val_loss: 415.6151\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1291.6033 - val_loss: 469.4746\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1291.3138 - val_loss: 526.9614\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1291.0479 - val_loss: 585.3876\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1290.7460 - val_loss: 630.7484\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1290.4755 - val_loss: 687.8549\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1290.1558 - val_loss: 739.2261\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1289.8777 - val_loss: 784.6235\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1289.6332 - val_loss: 841.5523\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1289.3044 - val_loss: 857.4297\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1289.0339 - val_loss: 875.0097\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1289.5612\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 121ms/step - loss: 1293.6825 - val_loss: 236.4769\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1293.4530 - val_loss: 222.0466\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1293.2076 - val_loss: 215.0721\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1292.9462 - val_loss: 216.2276\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1292.7006 - val_loss: 230.3592\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1292.3992 - val_loss: 250.4777\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1292.1261 - val_loss: 274.0157\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1291.8560 - val_loss: 302.5406\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1291.5261 - val_loss: 324.6219\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1291.2616 - val_loss: 355.1659\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1290.9695 - val_loss: 389.8328\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1290.6676 - val_loss: 412.4828\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1290.3683 - val_loss: 435.1594\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1290.0865 - val_loss: 474.0104\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1289.7897 - val_loss: 532.5563\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1289.5038 - val_loss: 618.6447\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1289.1835 - val_loss: 696.9061\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1288.8745 - val_loss: 765.5486\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1288.5725 - val_loss: 826.9686\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1288.2865 - val_loss: 894.5224\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1287.9652 - val_loss: 924.0622\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1287.6860 - val_loss: 982.5392\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1287.3585 - val_loss: 1035.2130\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1294.8596\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 66ms/step - loss: 1294.0753 - val_loss: 324.5552\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1293.7649 - val_loss: 384.4216\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1293.4779 - val_loss: 456.9501\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1293.1604 - val_loss: 545.3204\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1292.8605 - val_loss: 653.7259\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1292.4695 - val_loss: 757.2592\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1292.1208 - val_loss: 866.7623\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1291.7344 - val_loss: 961.3560\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1291.3942 - val_loss: 1070.5853\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1291.0056 - val_loss: 1171.0222\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1290.6575 - val_loss: 1257.4298\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1290.2815 - val_loss: 1360.8243\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1289.9116 - val_loss: 1467.0372\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1289.5508 - val_loss: 1569.5278\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1289.1637 - val_loss: 1687.5902\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1288.7974 - val_loss: 1804.3472\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1288.4016 - val_loss: 1922.7529\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1288.0701 - val_loss: 2053.9541\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1287.6417 - val_loss: 2161.4844\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1287.2683 - val_loss: 2264.2686\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1286.9178 - val_loss: 2375.6150\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1297.3922\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 80ms/step - loss: 1102.1661 - val_loss: 1762.3228\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 856.6746 - val_loss: 69364.8594\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 445.1922 - val_loss: 51172.8398\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 336.8847 - val_loss: 24915.5430\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 227.4663 - val_loss: 30084.7520\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 118.7372 - val_loss: 14325.4453\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 110.5056 - val_loss: 6831.8823\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 50.5275 - val_loss: 4147.5327\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 30.0093 - val_loss: 3341.8540\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 28.7238 - val_loss: 3946.4370\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 24.6112 - val_loss: 3563.1292\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 15.2927 - val_loss: 3064.8613\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 12.5975 - val_loss: 4022.4167\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 13.9433 - val_loss: 3056.3633\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 9.9335 - val_loss: 3475.7361\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 12.5675 - val_loss: 3774.5725\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 8.4748 - val_loss: 3869.9746\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 10.0872 - val_loss: 3391.5752\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 7.6375 - val_loss: 3714.8293\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 6.7796 - val_loss: 3894.3865\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 8.0530 - val_loss: 3939.1584\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 95.3864\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 3s 102ms/step - loss: 1097.6754 - val_loss: 2665.1965\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 858.1942 - val_loss: 54200.9023\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 419.3557 - val_loss: 39065.2070\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 295.1845 - val_loss: 14723.0146\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 175.3093 - val_loss: 10674.5449\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 150.9151 - val_loss: 3070.4189\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 93.6618 - val_loss: 3401.0674\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 61.8249 - val_loss: 1729.1306\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 28.6091 - val_loss: 1961.5654\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 26.4856 - val_loss: 2887.1162\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 16.9952 - val_loss: 3568.3931\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 10.9897 - val_loss: 2929.2803\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 12.9053 - val_loss: 2627.5706\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 9.1705 - val_loss: 3127.7483\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 8.2180 - val_loss: 2401.1494\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 8.0065 - val_loss: 2313.4756\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 7.2183 - val_loss: 2344.1321\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 7.1930 - val_loss: 2207.9988\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 6.8350 - val_loss: 2522.7400\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 6.8708 - val_loss: 2419.5911\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 7.6055 - val_loss: 2647.9243\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 6.2129 - val_loss: 2597.5259\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 6.9698 - val_loss: 2915.9487\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 6.4113 - val_loss: 2509.1089\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 7.1810 - val_loss: 2783.5439\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 5.8284 - val_loss: 2923.6514\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 6.3210 - val_loss: 2910.5181\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 6.2991 - val_loss: 2781.3347\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 59.8820\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 69ms/step - loss: 1095.5227 - val_loss: 808.8526\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 804.6835 - val_loss: 35458.4961\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 404.1053 - val_loss: 84738.0312\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 281.1438 - val_loss: 67381.4141\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 195.9443 - val_loss: 63427.2969\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 141.6269 - val_loss: 28337.0684\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 75.8752 - val_loss: 21067.0254\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 57.3743 - val_loss: 7492.3149\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 33.0186 - val_loss: 3207.1499\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 26.0162 - val_loss: 2415.1082\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 17.9855 - val_loss: 2792.6692\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 11.4710 - val_loss: 3018.2498\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 12.5312 - val_loss: 2239.7637\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 8.4023 - val_loss: 2290.0024\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 8.5081 - val_loss: 2673.2024\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 8.2339 - val_loss: 2487.9663\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 8.4770 - val_loss: 2868.3591\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 7.8894 - val_loss: 3520.3809\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 9.0925 - val_loss: 3042.8396\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 6.6425 - val_loss: 3138.7644\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 6.0697 - val_loss: 3149.2947\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 55.7820\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 3s 73ms/step - loss: 314.2196 - val_loss: 237.4564\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 313.5274 - val_loss: 110.9628\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 311.9456 - val_loss: 595.7592\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 307.9293 - val_loss: 1884.2161\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 300.4084 - val_loss: 3932.6304\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 288.4247 - val_loss: 6822.2573\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 269.9461 - val_loss: 11040.1084\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 247.1588 - val_loss: 15955.4004\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 223.2557 - val_loss: 19509.4473\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 198.4597 - val_loss: 21386.1523\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 175.7980 - val_loss: 21354.5645\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 154.0819 - val_loss: 21685.4395\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 131.9885 - val_loss: 23071.6484\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 115.3901 - val_loss: 20607.9570\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 98.3002 - val_loss: 18449.1309\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 86.3629 - val_loss: 16972.3145\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 77.9499 - val_loss: 16636.3184\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 69.0165 - val_loss: 14197.8379\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 60.8409 - val_loss: 12924.7842\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 53.7904 - val_loss: 10781.2754\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 46.5467 - val_loss: 9731.2041\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 39.9163 - val_loss: 7949.0264\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 59.2919\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 114ms/step - loss: 313.5532 - val_loss: 256.2975\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 312.7787 - val_loss: 211.0699\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 310.8762 - val_loss: 193.9622\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 307.5244 - val_loss: 603.1799\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 301.3273 - val_loss: 1488.9683\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 291.9328 - val_loss: 2924.9895\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 278.0092 - val_loss: 5227.9766\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 259.3375 - val_loss: 8380.8584\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 235.1420 - val_loss: 12266.7051\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 210.1535 - val_loss: 15273.2158\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 184.8965 - val_loss: 15232.1094\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 159.9973 - val_loss: 14501.0977\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 136.0187 - val_loss: 15564.0137\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 115.1306 - val_loss: 14666.4580\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 96.5674 - val_loss: 12920.3750\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 81.6890 - val_loss: 13928.2734\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 70.6602 - val_loss: 9922.9258\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 59.7213 - val_loss: 9378.5166\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 50.4589 - val_loss: 7456.5049\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 42.4662 - val_loss: 4807.5244\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 35.4583 - val_loss: 4365.6821\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 29.9004 - val_loss: 4641.2827\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 25.8669 - val_loss: 813.7561\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 38.5723\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 88ms/step - loss: 313.5731 - val_loss: 342.3336\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 312.7271 - val_loss: 500.8949\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 310.6682 - val_loss: 810.6444\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 306.5248 - val_loss: 1331.8702\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 299.9130 - val_loss: 1676.5283\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 289.0609 - val_loss: 1896.3459\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 273.9290 - val_loss: 2305.3928\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 254.6285 - val_loss: 2513.9067\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 231.9773 - val_loss: 1499.5975\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 209.6533 - val_loss: 591.0226\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 186.5296 - val_loss: 1179.2479\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 165.1832 - val_loss: 1932.9232\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 143.5211 - val_loss: 2959.4219\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 123.7913 - val_loss: 4240.3008\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 104.6907 - val_loss: 5698.2285\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 87.9767 - val_loss: 7272.0825\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 71.8814 - val_loss: 8778.0986\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 58.7991 - val_loss: 10051.8730\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 47.2484 - val_loss: 10967.8008\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 41.0021 - val_loss: 11264.6484\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 34.1311 - val_loss: 10928.2842\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 94.4330\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 71ms/step - loss: 718.8341 - val_loss: 141.0624\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 718.2666 - val_loss: 155.9101\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 717.5757 - val_loss: 187.3082\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 716.8534 - val_loss: 269.9364\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 716.1154 - val_loss: 405.6043\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 715.3820 - val_loss: 533.0186\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 714.6820 - val_loss: 625.4377\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 713.8412 - val_loss: 796.5743\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 713.0565 - val_loss: 962.2946\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 712.1909 - val_loss: 1078.1776\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 711.4412 - val_loss: 1171.4000\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 710.6155 - val_loss: 1338.1403\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 709.8624 - val_loss: 1506.3438\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 709.0373 - val_loss: 1615.1761\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 708.1918 - val_loss: 1680.1155\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 707.4421 - val_loss: 1759.1057\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 706.5942 - val_loss: 1865.2317\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 705.8115 - val_loss: 2044.5699\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 705.0769 - val_loss: 2209.4214\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 704.2408 - val_loss: 2301.3135\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 703.3658 - val_loss: 2358.9282\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 711.3311\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 99ms/step - loss: 717.6288 - val_loss: 140.6716\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 716.9017 - val_loss: 190.0598\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 716.2441 - val_loss: 339.2936\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 715.4511 - val_loss: 524.8063\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 714.7380 - val_loss: 742.4271\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 713.9290 - val_loss: 958.0608\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 713.0316 - val_loss: 1135.6040\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 712.2037 - val_loss: 1299.9431\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 711.3860 - val_loss: 1428.3422\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 710.4485 - val_loss: 1522.9459\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 709.6226 - val_loss: 1687.3954\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 708.7781 - val_loss: 1825.9547\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 708.0143 - val_loss: 1986.6926\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 707.0613 - val_loss: 2043.4380\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 706.2122 - val_loss: 2104.7412\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 705.4046 - val_loss: 2231.0178\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 704.5276 - val_loss: 2349.1931\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 703.7199 - val_loss: 2479.4724\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 702.9175 - val_loss: 2675.9932\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 702.0565 - val_loss: 2815.9746\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 701.1624 - val_loss: 2966.0330\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 715.7278\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 81ms/step - loss: 717.7155 - val_loss: 373.8017\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 716.8001 - val_loss: 675.1545\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 715.9488 - val_loss: 986.2289\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 715.0409 - val_loss: 1331.9042\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 713.9949 - val_loss: 1654.0969\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 713.0181 - val_loss: 1993.3337\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 711.9918 - val_loss: 2318.7161\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 710.9293 - val_loss: 2665.4243\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 709.7641 - val_loss: 2982.5081\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 708.7772 - val_loss: 3355.2119\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 707.6142 - val_loss: 3683.2991\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 706.5510 - val_loss: 4016.7061\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 705.5148 - val_loss: 4436.0991\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 704.4571 - val_loss: 4814.1826\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 703.3026 - val_loss: 5110.7544\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 702.2526 - val_loss: 5413.6660\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 701.2005 - val_loss: 5692.2764\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 700.1142 - val_loss: 5994.1611\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 699.0437 - val_loss: 6345.9727\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 697.9767 - val_loss: 6733.7046\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 696.8854 - val_loss: 7086.8477\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 725.0596\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 72ms/step - loss: 1388.3898 - val_loss: 976.4704\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1378.5614 - val_loss: 1531.5288\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1338.1086 - val_loss: 11170.7119\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1190.8903 - val_loss: 46526.3906\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 879.2640 - val_loss: 98427.9141\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 668.7527 - val_loss: 92091.0156\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 559.5605 - val_loss: 77096.8984\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 492.8151 - val_loss: 63661.1836\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 415.9087 - val_loss: 49822.4922\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 357.1820 - val_loss: 31933.1016\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 314.0023 - val_loss: 19087.4336\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 257.7576 - val_loss: 11835.2432\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 211.1812 - val_loss: 5475.4546\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 174.2309 - val_loss: 2918.5085\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 143.0713 - val_loss: 3468.2949\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 109.9450 - val_loss: 3560.2976\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 79.3929 - val_loss: 3909.9656\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 53.6237 - val_loss: 4575.7046\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 45.9896 - val_loss: 4941.4619\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 36.0107 - val_loss: 4623.3838\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 31.5763 - val_loss: 8669.8076\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 144.5106\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 78ms/step - loss: 1386.9076 - val_loss: 1240.1459\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1382.5485 - val_loss: 890.7023\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1369.6707 - val_loss: 1218.5532\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1320.5055 - val_loss: 9717.4180\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1171.6371 - val_loss: 36503.9336\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 918.4235 - val_loss: 55339.7891\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 718.1184 - val_loss: 58328.7109\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 522.5055 - val_loss: 26193.9531\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 332.8399 - val_loss: 7003.8301\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 246.2665 - val_loss: 20533.1992\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 182.0672 - val_loss: 17391.4824\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 126.6026 - val_loss: 15054.9131\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 92.3646 - val_loss: 19133.5352\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 66.5350 - val_loss: 6497.4067\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 41.6089 - val_loss: 9580.6172\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 25.6429 - val_loss: 7403.7871\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 17.4683 - val_loss: 3425.0576\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 15.1482 - val_loss: 3940.0149\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 12.1200 - val_loss: 5501.0713\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 10.3085 - val_loss: 6128.1909\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 9.9820 - val_loss: 6665.7354\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 8.0297 - val_loss: 6032.4663\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 25.3774\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 3s 109ms/step - loss: 1386.4365 - val_loss: 878.1058\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1379.3661 - val_loss: 888.9874\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1355.3370 - val_loss: 1872.1743\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1271.5264 - val_loss: 6268.3589\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1031.8943 - val_loss: 19536.9277\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 780.0199 - val_loss: 45508.6133\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 582.7753 - val_loss: 83564.2344\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 387.6099 - val_loss: 118577.5781\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 323.5816 - val_loss: 119594.7109\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 252.7381 - val_loss: 100062.0781\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 187.1883 - val_loss: 79806.7188\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 139.2164 - val_loss: 66369.6641\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 112.0379 - val_loss: 53828.7031\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 82.8567 - val_loss: 42565.0664\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 64.4952 - val_loss: 33725.2148\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 49.2518 - val_loss: 21051.1406\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 35.4581 - val_loss: 16327.9482\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 25.9120 - val_loss: 8250.8398\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 25.2375 - val_loss: 9375.3926\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 17.5354 - val_loss: 7695.0483\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 15.3463 - val_loss: 8050.5195\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 64.7164\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 76ms/step - loss: 618.8547 - val_loss: 554.5140\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 617.7932 - val_loss: 546.3954\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 616.1542 - val_loss: 525.5869\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 613.0115 - val_loss: 470.9589\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 607.7588 - val_loss: 383.9803\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 597.4048 - val_loss: 259.8979\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 578.9995 - val_loss: 854.4323\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 545.9058 - val_loss: 2880.6133\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 493.6953 - val_loss: 6878.9409\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 422.1064 - val_loss: 12447.0850\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 376.7726 - val_loss: 14282.7051\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 338.0450 - val_loss: 9350.6123\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 289.2717 - val_loss: 3976.8655\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 231.3898 - val_loss: 1999.0951\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 182.3264 - val_loss: 930.0421\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 139.3333 - val_loss: 970.7284\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 116.2630 - val_loss: 1024.0752\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 95.9306 - val_loss: 1285.2565\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 82.6130 - val_loss: 1308.1825\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 69.7393 - val_loss: 640.3261\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 60.1138 - val_loss: 836.9233\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 49.6441 - val_loss: 1273.9717\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 40.3625 - val_loss: 1617.5259\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 33.6589 - val_loss: 1924.1017\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 25.8706 - val_loss: 2055.6292\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 20.4539 - val_loss: 2347.5869\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 40.9875\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 71ms/step - loss: 617.8220 - val_loss: 600.3485\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 616.7198 - val_loss: 584.2047\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 614.7923 - val_loss: 548.7548\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 611.6694 - val_loss: 467.7151\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 605.9837 - val_loss: 292.5773\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 596.6558 - val_loss: 282.6429\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 579.9094 - val_loss: 988.2518\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 553.2867 - val_loss: 2559.8066\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 510.2833 - val_loss: 5513.4258\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 444.7698 - val_loss: 10678.8037\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 383.5286 - val_loss: 14923.3955\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 340.8411 - val_loss: 13118.5127\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 292.8657 - val_loss: 6917.4893\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 236.6920 - val_loss: 2552.7283\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 176.5207 - val_loss: 1955.4667\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 130.8314 - val_loss: 2310.5842\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 108.7209 - val_loss: 3337.2166\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 97.5264 - val_loss: 2259.2771\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 84.8492 - val_loss: 2381.4468\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 72.6513 - val_loss: 1995.0104\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 62.2243 - val_loss: 1882.8878\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 53.3077 - val_loss: 1776.5897\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 46.5105 - val_loss: 1602.6603\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 41.8436 - val_loss: 1591.9031\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 36.7810 - val_loss: 1574.7307\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 31.8643 - val_loss: 1541.3273\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 65.0831\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 74ms/step - loss: 618.2274 - val_loss: 563.3411\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 617.3673 - val_loss: 531.8456\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 615.8632 - val_loss: 481.8571\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 613.1144 - val_loss: 432.7715\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 607.8997 - val_loss: 403.6897\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 597.7979 - val_loss: 544.9710\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 579.4017 - val_loss: 1692.8107\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 545.9355 - val_loss: 4518.9272\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 489.7411 - val_loss: 9825.8477\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 396.6393 - val_loss: 18859.2676\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 307.1423 - val_loss: 28934.7891\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 259.7149 - val_loss: 32462.6523\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 239.8069 - val_loss: 29058.2969\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 215.6476 - val_loss: 23960.2168\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 187.2201 - val_loss: 18086.8457\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 163.4324 - val_loss: 14373.9707\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 140.2281 - val_loss: 9132.4043\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 115.3227 - val_loss: 3123.8977\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 93.5156 - val_loss: 1242.3517\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 71.0460 - val_loss: 2723.2114\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 56.1819 - val_loss: 3638.2722\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 46.0790 - val_loss: 4119.3008\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 39.9061 - val_loss: 4344.6743\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 34.4545 - val_loss: 3377.0293\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 28.3584 - val_loss: 3515.4741\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 74.2188\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 3s 83ms/step - loss: 718.7932 - val_loss: 550.3499\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 718.7632 - val_loss: 547.2542\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 718.7307 - val_loss: 543.9523\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 718.6949 - val_loss: 540.3919\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 718.6553 - val_loss: 537.1371\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 718.6142 - val_loss: 534.2812\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 718.5702 - val_loss: 531.8393\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 718.5247 - val_loss: 529.4732\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 718.4747 - val_loss: 527.3646\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 718.4275 - val_loss: 525.0992\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 718.3773 - val_loss: 523.2623\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 718.3184 - val_loss: 521.8337\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 718.2711 - val_loss: 520.4065\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 718.2067 - val_loss: 519.5538\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 718.1503 - val_loss: 518.3702\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 718.0887 - val_loss: 517.4272\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 718.0327 - val_loss: 516.4864\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 717.9601 - val_loss: 516.1932\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 717.8968 - val_loss: 515.5433\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 717.8270 - val_loss: 515.0000\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 717.7496 - val_loss: 514.6860\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 717.6736 - val_loss: 514.5045\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 717.5925 - val_loss: 514.6264\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 717.5070 - val_loss: 515.1182\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 717.4232 - val_loss: 515.7264\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 717.3317 - val_loss: 516.5058\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 717.2362 - val_loss: 517.4990\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 717.1346 - val_loss: 518.7466\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 717.0325 - val_loss: 520.1291\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 716.9214 - val_loss: 521.6864\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 716.8017 - val_loss: 523.4542\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 716.6859 - val_loss: 525.3792\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 716.5534 - val_loss: 527.1843\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 716.4249 - val_loss: 529.0649\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 716.2943 - val_loss: 530.9604\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 716.1379 - val_loss: 533.0121\n",
            "Epoch 37/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 715.9921 - val_loss: 535.7256\n",
            "Epoch 38/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 715.8443 - val_loss: 539.5372\n",
            "Epoch 39/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 715.6777 - val_loss: 545.0489\n",
            "Epoch 40/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 715.5119 - val_loss: 552.5214\n",
            "Epoch 41/700\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 715.3262 - val_loss: 561.1824\n",
            "Epoch 42/700\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 715.1530 - val_loss: 571.3420\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 714.8836\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 104ms/step - loss: 717.3262 - val_loss: 383.0086\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 717.2966 - val_loss: 380.3704\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 717.2645 - val_loss: 377.9359\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 717.2286 - val_loss: 375.1931\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 717.1880 - val_loss: 372.3989\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 717.1489 - val_loss: 369.4502\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 717.1030 - val_loss: 366.5938\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 717.0541 - val_loss: 364.0250\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 717.0052 - val_loss: 360.9641\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 716.9555 - val_loss: 357.2103\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 716.8998 - val_loss: 353.6047\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 716.8423 - val_loss: 349.7731\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 716.7831 - val_loss: 345.7761\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 716.7241 - val_loss: 341.7475\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 716.6563 - val_loss: 338.0718\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 716.5901 - val_loss: 334.8424\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 716.5267 - val_loss: 331.7938\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 716.4481 - val_loss: 329.0763\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 716.3780 - val_loss: 326.5011\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 716.2945 - val_loss: 324.5403\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 716.2172 - val_loss: 323.1628\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 716.1327 - val_loss: 323.3499\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 716.0328 - val_loss: 325.7363\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 715.9476 - val_loss: 330.8440\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 715.8477 - val_loss: 338.4500\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 715.7325 - val_loss: 347.7307\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 715.6292 - val_loss: 359.9235\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 715.5327 - val_loss: 374.5742\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 715.3985 - val_loss: 389.5784\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 715.2897 - val_loss: 407.6398\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 715.1660 - val_loss: 428.0773\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 715.0239 - val_loss: 448.9015\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 714.8992 - val_loss: 472.6620\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 714.7543 - val_loss: 497.3606\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 714.6137 - val_loss: 524.1537\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 714.4601 - val_loss: 552.6913\n",
            "Epoch 37/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 714.3143 - val_loss: 584.4337\n",
            "Epoch 38/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 714.1469 - val_loss: 618.7304\n",
            "Epoch 39/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 713.9755 - val_loss: 657.2500\n",
            "Epoch 40/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 713.8262 - val_loss: 703.5769\n",
            "Epoch 41/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 713.6281 - val_loss: 749.0524\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 718.1041\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 77ms/step - loss: 717.7570 - val_loss: 622.0971\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 717.7278 - val_loss: 624.8345\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 717.6984 - val_loss: 627.4030\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 717.6653 - val_loss: 629.9342\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 717.6279 - val_loss: 633.0295\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 717.5898 - val_loss: 636.1505\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 717.5491 - val_loss: 639.4507\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 717.5059 - val_loss: 643.2247\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 717.4627 - val_loss: 647.0261\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 717.4173 - val_loss: 650.6884\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 717.3661 - val_loss: 654.4575\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 717.3183 - val_loss: 658.9030\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 717.2708 - val_loss: 663.1439\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 717.2122 - val_loss: 666.9073\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 717.1558 - val_loss: 670.8580\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 717.1018 - val_loss: 674.9272\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 717.0383 - val_loss: 678.4373\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 716.9804 - val_loss: 682.4177\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 716.9191 - val_loss: 686.7679\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 716.8480 - val_loss: 691.3820\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 716.7769 - val_loss: 696.3098\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 719.0437\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 104ms/step - loss: 1011.8610 - val_loss: 743.5787\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1006.8766 - val_loss: 940.4984\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 988.7346 - val_loss: 5417.6479\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 923.5102 - val_loss: 20399.7402\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 760.5709 - val_loss: 50936.7695\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 614.5150 - val_loss: 64604.7539\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 503.5558 - val_loss: 59464.7969\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 406.4857 - val_loss: 49817.0391\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 354.5907 - val_loss: 39732.6094\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 311.6682 - val_loss: 29735.3574\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 271.4796 - val_loss: 20592.6992\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 240.5600 - val_loss: 11474.3926\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 209.7114 - val_loss: 5546.2402\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 182.9034 - val_loss: 2481.5476\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 156.3632 - val_loss: 1115.3503\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 136.7403 - val_loss: 621.8281\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 118.2360 - val_loss: 752.8658\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 103.3802 - val_loss: 754.0800\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 89.1111 - val_loss: 1211.9017\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 77.5488 - val_loss: 2414.0564\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 67.0413 - val_loss: 2165.8733\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 57.1910 - val_loss: 2250.7402\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 47.3058 - val_loss: 2716.2925\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 38.7310 - val_loss: 2839.5798\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 30.7204 - val_loss: 3599.4761\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 24.1862 - val_loss: 3450.0486\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 19.6896 - val_loss: 4252.1543\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 17.7222 - val_loss: 4485.0723\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 14.5280 - val_loss: 5030.2144\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 12.6734 - val_loss: 5039.9297\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 11.3524 - val_loss: 5014.7192\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 10.6482 - val_loss: 5249.6748\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 9.7197 - val_loss: 5128.7310\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 8.8149 - val_loss: 5332.2290\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 8.1744 - val_loss: 4954.9941\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 7.6980 - val_loss: 4857.6128\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 42.7489\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 72ms/step - loss: 1009.6368 - val_loss: 519.0654\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1004.1584 - val_loss: 1622.0790\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 981.8453 - val_loss: 9767.8604\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 909.6494 - val_loss: 30541.1465\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 765.9698 - val_loss: 64269.7461\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 655.2492 - val_loss: 79774.7969\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 592.7372 - val_loss: 69916.8906\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 515.9915 - val_loss: 58328.8711\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 439.1154 - val_loss: 50495.1953\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 372.6097 - val_loss: 44513.3086\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 314.5251 - val_loss: 34171.9570\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 265.0050 - val_loss: 23985.6973\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 224.3517 - val_loss: 16243.2012\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 194.9361 - val_loss: 10019.0830\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 171.3090 - val_loss: 8640.7949\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 151.9824 - val_loss: 6075.0688\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 130.7548 - val_loss: 6816.2300\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 109.7357 - val_loss: 7769.5146\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 93.5850 - val_loss: 9203.5078\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 80.9864 - val_loss: 9549.8174\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 67.7698 - val_loss: 9751.0957\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 158.6684\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 75ms/step - loss: 1009.9135 - val_loss: 904.9948\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1004.1276 - val_loss: 1204.4415\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 984.0600 - val_loss: 1098.3870\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 922.5190 - val_loss: 1409.2917\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 802.2736 - val_loss: 5585.0288\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 670.3084 - val_loss: 12594.9072\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 574.5083 - val_loss: 28268.4082\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 438.7266 - val_loss: 51169.1641\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 313.3941 - val_loss: 77669.2344\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 235.1883 - val_loss: 96018.5781\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 192.4748 - val_loss: 95825.4688\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 159.2220 - val_loss: 85878.0156\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 131.5019 - val_loss: 71608.8125\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 106.9496 - val_loss: 56844.2891\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 87.3302 - val_loss: 42400.5039\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 70.4857 - val_loss: 34363.3477\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 55.9747 - val_loss: 24760.0449\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 42.1921 - val_loss: 12180.9082\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 30.3119 - val_loss: 7153.6494\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 23.8090 - val_loss: 6498.3174\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 20.4502 - val_loss: 6706.2466\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 114.3790\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 71ms/step - loss: 210.3788 - val_loss: 50.3981\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 210.3056 - val_loss: 46.3569\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 210.2534 - val_loss: 44.9183\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 210.1806 - val_loss: 43.6049\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 210.1099 - val_loss: 44.0604\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 210.0356 - val_loss: 46.7583\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 209.9750 - val_loss: 55.7159\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 209.8752 - val_loss: 63.4512\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 209.8045 - val_loss: 74.4892\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 209.7272 - val_loss: 81.6296\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 209.6450 - val_loss: 95.0319\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 209.5690 - val_loss: 107.9788\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 209.4944 - val_loss: 127.4552\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 209.4127 - val_loss: 143.1968\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 209.3359 - val_loss: 157.6266\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 209.2543 - val_loss: 167.6122\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 209.1729 - val_loss: 185.6531\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 209.0941 - val_loss: 203.1774\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 209.0141 - val_loss: 216.6158\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 208.9327 - val_loss: 234.3393\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 208.8539 - val_loss: 252.6818\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 208.7776 - val_loss: 270.7971\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 208.6967 - val_loss: 283.7346\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 208.6127 - val_loss: 300.6040\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 209.1414\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 92ms/step - loss: 210.0340 - val_loss: 44.1373\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 209.9568 - val_loss: 42.8079\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 209.8966 - val_loss: 43.7433\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 209.8204 - val_loss: 50.0174\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 209.7440 - val_loss: 60.6170\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 209.6683 - val_loss: 74.1823\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 209.5851 - val_loss: 87.9798\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 209.5041 - val_loss: 102.5505\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 209.4156 - val_loss: 119.9070\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 209.3345 - val_loss: 139.3703\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 209.2503 - val_loss: 161.7695\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 209.1641 - val_loss: 179.8623\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 209.0835 - val_loss: 203.1955\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 208.9922 - val_loss: 221.4381\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 208.9094 - val_loss: 238.7100\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 208.8260 - val_loss: 258.5364\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 208.7428 - val_loss: 280.6312\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 208.6573 - val_loss: 302.6537\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 208.5767 - val_loss: 317.9735\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 208.4923 - val_loss: 331.8868\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 208.4050 - val_loss: 350.9528\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 208.3245 - val_loss: 375.0926\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 210.0934\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 78ms/step - loss: 210.0928 - val_loss: 59.8379\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 210.0069 - val_loss: 80.7706\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 209.9250 - val_loss: 109.4696\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 209.8470 - val_loss: 144.3784\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 209.7400 - val_loss: 174.1974\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 209.6409 - val_loss: 206.3350\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 209.5496 - val_loss: 237.4530\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 209.4529 - val_loss: 266.8787\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 209.3399 - val_loss: 295.0023\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 209.2520 - val_loss: 325.8781\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 209.1432 - val_loss: 354.4076\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 209.0381 - val_loss: 382.2860\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 208.9497 - val_loss: 410.5209\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 208.8387 - val_loss: 432.0336\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 208.7444 - val_loss: 458.1476\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 208.6403 - val_loss: 481.0165\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 208.5358 - val_loss: 504.1028\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 208.4325 - val_loss: 526.3981\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 208.3363 - val_loss: 551.8541\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 208.2390 - val_loss: 582.3033\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 208.1270 - val_loss: 607.5705\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 210.7309\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 73ms/step - loss: 1372.0527 - val_loss: 17349.5527\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 926.0594 - val_loss: 43034.4531\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 503.3339 - val_loss: 40817.8828\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 370.3901 - val_loss: 19695.7598\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 278.1965 - val_loss: 8829.5996\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 180.6136 - val_loss: 2424.0200\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 123.0894 - val_loss: 7119.7275\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 68.9855 - val_loss: 2267.0781\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 97.2881 - val_loss: 7481.1558\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 28.3109 - val_loss: 2192.4495\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 22.6390 - val_loss: 878.9005\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 22.6690 - val_loss: 767.6005\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 15.1116 - val_loss: 768.8882\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 11.7261 - val_loss: 808.4263\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 11.5611 - val_loss: 477.7451\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 9.2332 - val_loss: 628.3881\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 8.2010 - val_loss: 391.9620\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 7.6604 - val_loss: 484.5087\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 7.1385 - val_loss: 390.8954\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 7.2190 - val_loss: 387.1343\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 7.0935 - val_loss: 722.8275\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 7.0406 - val_loss: 1204.0479\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 6.4966 - val_loss: 1592.7721\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 6.0804 - val_loss: 1925.9238\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 5.7566 - val_loss: 1989.2894\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 5.7205 - val_loss: 1965.2463\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 6.0072 - val_loss: 2144.6143\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 5.5832 - val_loss: 2009.5752\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 5.2753 - val_loss: 2226.8665\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 5.5779 - val_loss: 2085.2288\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 5.3188 - val_loss: 2267.1367\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 4.9380 - val_loss: 2258.8599\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 5.0757 - val_loss: 2208.5974\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 5.7486 - val_loss: 2095.1917\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 5.2294 - val_loss: 2074.8088\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.9069 - val_loss: 2040.3433\n",
            "Epoch 37/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 4.9640 - val_loss: 2075.7991\n",
            "Epoch 38/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 4.7356 - val_loss: 2004.8300\n",
            "Epoch 39/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 4.7019 - val_loss: 1997.3478\n",
            "Epoch 40/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 6.4297 - val_loss: 1705.5500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 160.4925\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 102ms/step - loss: 1374.7871 - val_loss: 7652.8608\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 919.2676 - val_loss: 43255.1602\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 481.1045 - val_loss: 59667.5039\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 366.1699 - val_loss: 38404.7812\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 270.1779 - val_loss: 8387.0713\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 152.2621 - val_loss: 9997.5703\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 138.3247 - val_loss: 12247.1992\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 73.8193 - val_loss: 12387.5723\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 52.7121 - val_loss: 8631.9756\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 19.9252 - val_loss: 10806.8994\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 16.7324 - val_loss: 7525.7827\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 9.9357 - val_loss: 9325.3789\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 9.5825 - val_loss: 7451.2036\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 10.1077 - val_loss: 6272.9702\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 7.7193 - val_loss: 6278.2607\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 6.8258 - val_loss: 4957.6099\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 8.4220 - val_loss: 4910.8687\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 7.4627 - val_loss: 5352.6504\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 7.4886 - val_loss: 5964.6582\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 6.0105 - val_loss: 6483.0210\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 6.0924 - val_loss: 6611.4248\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 11.3765 - val_loss: 8585.2510\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 7.5527 - val_loss: 8798.2197\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 6.2671 - val_loss: 8698.8711\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 5.4091 - val_loss: 7177.6792\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 5.7734 - val_loss: 7837.9482\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 5.0150 - val_loss: 6429.4087\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 6.1906 - val_loss: 6635.2393\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 5.1848 - val_loss: 6167.4775\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 5.8792 - val_loss: 8282.3652\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 5.2168 - val_loss: 7490.8950\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 3.9791 - val_loss: 6511.9058\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 4.9627 - val_loss: 7281.0864\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 4.3220 - val_loss: 6640.1777\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 5.4595 - val_loss: 10899.4834\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 6.5034 - val_loss: 8214.3594\n",
            "Epoch 37/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 5.3921 - val_loss: 8610.4443\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 130.2814\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 3s 70ms/step - loss: 1381.7864 - val_loss: 5457.5181\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1054.1520 - val_loss: 109196.2031\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 506.5768 - val_loss: 70883.2188\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 275.8294 - val_loss: 59978.8555\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 224.6732 - val_loss: 54775.0000\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 120.8293 - val_loss: 28116.7637\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 50.2200 - val_loss: 12777.6484\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 46.1379 - val_loss: 8383.6777\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 47.6924 - val_loss: 8488.5840\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 18.6517 - val_loss: 4973.3745\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 11.2038 - val_loss: 4474.5298\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 9.4155 - val_loss: 3174.2012\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 9.1204 - val_loss: 5574.7202\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 9.0169 - val_loss: 6193.9355\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 7.0797 - val_loss: 4738.9790\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 6.5223 - val_loss: 3705.8325\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 5.9556 - val_loss: 2855.9778\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 6.1645 - val_loss: 3118.0144\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 6.0922 - val_loss: 4145.8462\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 6.3731 - val_loss: 2458.1399\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 5.4123 - val_loss: 3011.1287\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 5.2798 - val_loss: 3491.2930\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 5.1371 - val_loss: 3262.8528\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 5.0967 - val_loss: 3337.4009\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 5.0429 - val_loss: 2858.3289\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 5.3015 - val_loss: 3432.9314\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 4.8338 - val_loss: 2992.0125\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 4.7634 - val_loss: 2738.9285\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 4.9394 - val_loss: 2840.0571\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 4.6161 - val_loss: 3289.5176\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 4.8085 - val_loss: 2513.2219\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 4.7257 - val_loss: 3238.2363\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 4.6872 - val_loss: 3229.1770\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 4.4554 - val_loss: 2702.3081\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 4.3787 - val_loss: 2753.2820\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 4.1471 - val_loss: 2824.4185\n",
            "Epoch 37/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 4.2763 - val_loss: 3520.6589\n",
            "Epoch 38/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 4.1217 - val_loss: 2605.2427\n",
            "Epoch 39/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 4.2133 - val_loss: 2579.2251\n",
            "Epoch 40/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 4.2409 - val_loss: 2718.0449\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 68.2295\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 64ms/step - loss: 915.5137 - val_loss: 594.6067\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 915.2415 - val_loss: 564.9656\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 914.8822 - val_loss: 525.8087\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 914.4110 - val_loss: 490.3596\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 913.7975 - val_loss: 468.9522\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 913.0611 - val_loss: 468.3395\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 912.0264 - val_loss: 481.5865\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 910.8845 - val_loss: 499.4400\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 909.3939 - val_loss: 558.2978\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 907.5789 - val_loss: 703.3889\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 905.4715 - val_loss: 976.0057\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 903.1071 - val_loss: 1363.7833\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 900.1440 - val_loss: 1843.1682\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 896.8521 - val_loss: 2415.6926\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 892.8444 - val_loss: 3055.6409\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 888.5200 - val_loss: 3782.3982\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 883.3083 - val_loss: 4604.2227\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 878.4653 - val_loss: 5561.1895\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 872.3203 - val_loss: 6576.6738\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 865.6123 - val_loss: 7673.3716\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 858.5729 - val_loss: 8867.4219\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 850.6091 - val_loss: 10156.2070\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 842.2784 - val_loss: 11626.5928\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 832.9606 - val_loss: 13197.9551\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 822.8397 - val_loss: 14921.4834\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 812.1011 - val_loss: 16838.2910\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 859.7586\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 4s 103ms/step - loss: 914.0771 - val_loss: 735.1973\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 913.8063 - val_loss: 720.8028\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 913.5424 - val_loss: 695.7389\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 913.1492 - val_loss: 670.7175\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 912.6793 - val_loss: 639.6542\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 912.0481 - val_loss: 597.0867\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 911.2733 - val_loss: 543.8809\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 910.3484 - val_loss: 489.0878\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 909.1098 - val_loss: 445.7177\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 907.5958 - val_loss: 405.7163\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 905.9220 - val_loss: 454.8549\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 903.7831 - val_loss: 647.9962\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 901.2338 - val_loss: 980.7067\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 898.1916 - val_loss: 1415.9548\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 895.0247 - val_loss: 1919.8895\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 891.0303 - val_loss: 2488.6938\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 887.0789 - val_loss: 3163.8162\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 882.0868 - val_loss: 3892.9531\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 876.9129 - val_loss: 4703.5884\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 870.9111 - val_loss: 5590.7939\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 864.8363 - val_loss: 6583.2285\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 857.6851 - val_loss: 7607.1523\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 850.2057 - val_loss: 8766.0596\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 842.0200 - val_loss: 10005.5908\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 833.5434 - val_loss: 11477.3906\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 823.9969 - val_loss: 12994.6680\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 814.3594 - val_loss: 14716.1504\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 803.4277 - val_loss: 16477.7246\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 792.2707 - val_loss: 18427.4277\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 780.4332 - val_loss: 20496.4688\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 834.0966\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 89ms/step - loss: 914.3669 - val_loss: 749.5058\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 914.0765 - val_loss: 809.5510\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 913.7258 - val_loss: 875.5358\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 913.2993 - val_loss: 948.0464\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 912.7113 - val_loss: 1033.3564\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 911.9734 - val_loss: 1142.7767\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 911.0508 - val_loss: 1278.6743\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 909.9427 - val_loss: 1433.2815\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 908.5421 - val_loss: 1603.1096\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 906.9117 - val_loss: 1819.4579\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 904.9133 - val_loss: 2055.3362\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 902.7116 - val_loss: 2344.9438\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 900.0313 - val_loss: 2590.7432\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 897.0318 - val_loss: 2890.3462\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 893.7061 - val_loss: 3169.6575\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 889.8366 - val_loss: 3391.6199\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 885.7183 - val_loss: 3676.6340\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 881.2676 - val_loss: 4022.1194\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 876.2139 - val_loss: 4238.5728\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 871.0535 - val_loss: 4564.4746\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 864.9267 - val_loss: 4769.6001\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 908.6974\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 3s 87ms/step - loss: 105.6968 - val_loss: 100.8420\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 105.6903 - val_loss: 100.7194\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 105.6832 - val_loss: 100.5873\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 105.6754 - val_loss: 100.4247\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 105.6668 - val_loss: 100.2171\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 105.6583 - val_loss: 100.0238\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 105.6487 - val_loss: 99.8262\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 105.6403 - val_loss: 99.5862\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 105.6296 - val_loss: 99.3435\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 105.6195 - val_loss: 99.0805\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 105.6093 - val_loss: 98.7770\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 105.5986 - val_loss: 98.4509\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 105.5878 - val_loss: 98.0990\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 105.5760 - val_loss: 97.7425\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 105.5634 - val_loss: 97.3697\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 105.5512 - val_loss: 96.9406\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 105.5386 - val_loss: 96.4759\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 105.5246 - val_loss: 95.9984\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 105.5111 - val_loss: 95.4834\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 105.4964 - val_loss: 94.9577\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 105.4807 - val_loss: 94.4193\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 105.4646 - val_loss: 93.7929\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 105.4496 - val_loss: 93.0187\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 105.4307 - val_loss: 92.2963\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 105.4128 - val_loss: 91.5117\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 105.3936 - val_loss: 90.7010\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 105.3743 - val_loss: 89.7744\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 105.3526 - val_loss: 88.9127\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 105.3314 - val_loss: 87.9094\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 105.3073 - val_loss: 86.8777\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 105.2832 - val_loss: 85.7731\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 105.2578 - val_loss: 84.5498\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 105.2315 - val_loss: 83.2794\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 105.2027 - val_loss: 81.8683\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 105.1750 - val_loss: 80.3098\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 105.1419 - val_loss: 78.8017\n",
            "Epoch 37/700\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 105.1079 - val_loss: 77.3457\n",
            "Epoch 38/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 105.0739 - val_loss: 75.8112\n",
            "Epoch 39/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 105.0388 - val_loss: 74.3051\n",
            "Epoch 40/700\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 105.0006 - val_loss: 72.7600\n",
            "Epoch 41/700\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 104.9597 - val_loss: 71.1567\n",
            "Epoch 42/700\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 104.9187 - val_loss: 69.4835\n",
            "Epoch 43/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 104.8712 - val_loss: 67.8468\n",
            "Epoch 44/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 104.8243 - val_loss: 66.1050\n",
            "Epoch 45/700\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 104.7757 - val_loss: 64.2805\n",
            "Epoch 46/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 104.7234 - val_loss: 62.4028\n",
            "Epoch 47/700\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 104.6668 - val_loss: 60.5754\n",
            "Epoch 48/700\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 104.6077 - val_loss: 58.7846\n",
            "Epoch 49/700\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 104.5455 - val_loss: 57.0484\n",
            "Epoch 50/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 104.4791 - val_loss: 55.5325\n",
            "Epoch 51/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 104.4100 - val_loss: 54.2442\n",
            "Epoch 52/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 104.3372 - val_loss: 53.1988\n",
            "Epoch 53/700\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 104.2631 - val_loss: 52.3873\n",
            "Epoch 54/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 104.1783 - val_loss: 51.7653\n",
            "Epoch 55/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 104.0929 - val_loss: 51.4758\n",
            "Epoch 56/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 104.0020 - val_loss: 51.5751\n",
            "Epoch 57/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 103.9088 - val_loss: 52.2543\n",
            "Epoch 58/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 103.8081 - val_loss: 53.4262\n",
            "Epoch 59/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 103.7026 - val_loss: 54.9920\n",
            "Epoch 60/700\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 103.5892 - val_loss: 56.9013\n",
            "Epoch 61/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 103.4709 - val_loss: 59.0105\n",
            "Epoch 62/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 103.3472 - val_loss: 61.5167\n",
            "Epoch 63/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 103.2186 - val_loss: 64.7350\n",
            "Epoch 64/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 103.0791 - val_loss: 69.0294\n",
            "Epoch 65/700\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 102.9346 - val_loss: 74.4616\n",
            "Epoch 66/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 102.7828 - val_loss: 81.3446\n",
            "Epoch 67/700\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 102.6221 - val_loss: 89.9199\n",
            "Epoch 68/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 102.4523 - val_loss: 100.0179\n",
            "Epoch 69/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 102.2670 - val_loss: 111.5089\n",
            "Epoch 70/700\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 102.0894 - val_loss: 124.9108\n",
            "Epoch 71/700\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 101.8806 - val_loss: 139.0056\n",
            "Epoch 72/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 101.6806 - val_loss: 154.7070\n",
            "Epoch 73/700\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 101.4705 - val_loss: 171.6099\n",
            "Epoch 74/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 101.2385 - val_loss: 189.1114\n",
            "Epoch 75/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 101.0063 - val_loss: 207.2029\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 102.7951\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 3s 77ms/step - loss: 105.4985 - val_loss: 91.6968\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 105.4923 - val_loss: 91.5245\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 105.4848 - val_loss: 91.3485\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 105.4766 - val_loss: 91.1525\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 105.4679 - val_loss: 90.8890\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 105.4583 - val_loss: 90.6008\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 105.4486 - val_loss: 90.2647\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 105.4385 - val_loss: 89.9242\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 105.4275 - val_loss: 89.5793\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 105.4163 - val_loss: 89.2571\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 105.4063 - val_loss: 88.9072\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 105.3945 - val_loss: 88.6025\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 105.3829 - val_loss: 88.3105\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 105.3709 - val_loss: 87.9908\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 105.3584 - val_loss: 87.6193\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 105.3460 - val_loss: 87.2074\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 105.3324 - val_loss: 86.7860\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 105.3198 - val_loss: 86.3313\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 105.3044 - val_loss: 85.9440\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 105.2902 - val_loss: 85.5494\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 105.2744 - val_loss: 85.1501\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 105.2591 - val_loss: 84.6674\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 105.2424 - val_loss: 84.2142\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 105.2255 - val_loss: 83.7290\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 105.2074 - val_loss: 83.2025\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 105.1897 - val_loss: 82.6317\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 105.1702 - val_loss: 82.0248\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 105.1487 - val_loss: 81.3989\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 105.1280 - val_loss: 80.7361\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 105.1055 - val_loss: 80.0424\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 105.0811 - val_loss: 79.3361\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 105.0565 - val_loss: 78.6217\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 105.0315 - val_loss: 77.9028\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 105.0041 - val_loss: 77.2271\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 104.9756 - val_loss: 76.5235\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 104.9466 - val_loss: 75.8225\n",
            "Epoch 37/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 104.9168 - val_loss: 75.1254\n",
            "Epoch 38/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 104.8829 - val_loss: 74.4635\n",
            "Epoch 39/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 104.8498 - val_loss: 73.8011\n",
            "Epoch 40/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 104.8132 - val_loss: 73.2110\n",
            "Epoch 41/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 104.7771 - val_loss: 72.6290\n",
            "Epoch 42/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 104.7388 - val_loss: 72.1021\n",
            "Epoch 43/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 104.6957 - val_loss: 71.6792\n",
            "Epoch 44/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 104.6532 - val_loss: 71.2761\n",
            "Epoch 45/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 104.6083 - val_loss: 70.8931\n",
            "Epoch 46/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 104.5605 - val_loss: 70.4829\n",
            "Epoch 47/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 104.5122 - val_loss: 70.0161\n",
            "Epoch 48/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 104.4581 - val_loss: 69.4977\n",
            "Epoch 49/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 104.4041 - val_loss: 68.9384\n",
            "Epoch 50/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 104.3444 - val_loss: 68.3881\n",
            "Epoch 51/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 104.2846 - val_loss: 67.8478\n",
            "Epoch 52/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 104.2181 - val_loss: 67.4375\n",
            "Epoch 53/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 104.1536 - val_loss: 67.0872\n",
            "Epoch 54/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 104.0802 - val_loss: 66.8323\n",
            "Epoch 55/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 104.0131 - val_loss: 66.5373\n",
            "Epoch 56/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 103.9350 - val_loss: 66.2695\n",
            "Epoch 57/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 103.8522 - val_loss: 66.1017\n",
            "Epoch 58/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 103.7709 - val_loss: 66.0462\n",
            "Epoch 59/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 103.6791 - val_loss: 66.1445\n",
            "Epoch 60/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 103.5881 - val_loss: 66.4623\n",
            "Epoch 61/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 103.4950 - val_loss: 66.9411\n",
            "Epoch 62/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 103.3854 - val_loss: 67.5307\n",
            "Epoch 63/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 103.2754 - val_loss: 68.2022\n",
            "Epoch 64/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 103.1658 - val_loss: 68.9901\n",
            "Epoch 65/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 103.0454 - val_loss: 69.8472\n",
            "Epoch 66/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 102.9190 - val_loss: 70.9218\n",
            "Epoch 67/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 102.7760 - val_loss: 72.4461\n",
            "Epoch 68/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 102.6382 - val_loss: 74.7235\n",
            "Epoch 69/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 102.4938 - val_loss: 77.9716\n",
            "Epoch 70/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 102.3417 - val_loss: 81.7723\n",
            "Epoch 71/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 102.1736 - val_loss: 86.2092\n",
            "Epoch 72/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 102.0092 - val_loss: 91.9064\n",
            "Epoch 73/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 101.8255 - val_loss: 98.6647\n",
            "Epoch 74/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 101.6350 - val_loss: 106.5727\n",
            "Epoch 75/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 101.4417 - val_loss: 116.6105\n",
            "Epoch 76/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 101.2379 - val_loss: 128.3431\n",
            "Epoch 77/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 101.0128 - val_loss: 141.0041\n",
            "Epoch 78/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 100.7881 - val_loss: 154.8909\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 102.4682\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 3s 121ms/step - loss: 105.5151 - val_loss: 95.6838\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 105.5074 - val_loss: 95.8374\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 105.4989 - val_loss: 96.0251\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 105.4897 - val_loss: 96.2271\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 105.4786 - val_loss: 96.4326\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 105.4680 - val_loss: 96.6649\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 105.4563 - val_loss: 96.9071\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 105.4443 - val_loss: 97.1599\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 105.4318 - val_loss: 97.4138\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 105.4183 - val_loss: 97.6691\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 105.4050 - val_loss: 97.9418\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 105.3908 - val_loss: 98.2233\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 105.3755 - val_loss: 98.4963\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 105.3603 - val_loss: 98.7851\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 105.3444 - val_loss: 99.1075\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 105.3278 - val_loss: 99.4425\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 105.3111 - val_loss: 99.7984\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 105.2926 - val_loss: 100.1279\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 105.2753 - val_loss: 100.5077\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 105.2534 - val_loss: 100.8774\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 105.2340 - val_loss: 101.2724\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 105.5592\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 62ms/step - loss: 619.1796 - val_loss: 130.4852\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 618.7381 - val_loss: 162.8388\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 618.2019 - val_loss: 214.0230\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 617.6970 - val_loss: 288.4724\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 617.1974 - val_loss: 382.4846\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 616.6792 - val_loss: 488.9648\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 616.1340 - val_loss: 608.0140\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 615.5620 - val_loss: 695.2109\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 615.0386 - val_loss: 821.3198\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 614.4208 - val_loss: 883.8190\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 613.8431 - val_loss: 978.8505\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 613.2388 - val_loss: 1090.7008\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 612.6687 - val_loss: 1197.1973\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 612.0850 - val_loss: 1338.6975\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 611.5276 - val_loss: 1439.0496\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 610.9006 - val_loss: 1561.7405\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 610.3610 - val_loss: 1714.7045\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 609.7351 - val_loss: 1819.6144\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 609.1705 - val_loss: 1938.2386\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 608.5889 - val_loss: 2079.2468\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 607.9830 - val_loss: 2208.0332\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 613.4467\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 72ms/step - loss: 618.1534 - val_loss: 127.8813\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 617.6118 - val_loss: 183.5335\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 617.0901 - val_loss: 280.8638\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 616.5948 - val_loss: 395.7071\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 616.0499 - val_loss: 482.8360\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 615.4620 - val_loss: 611.3166\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 614.8676 - val_loss: 765.8337\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 614.2576 - val_loss: 898.5237\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 613.7352 - val_loss: 1026.4344\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 613.0798 - val_loss: 1122.8262\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 612.4467 - val_loss: 1209.3940\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 611.8414 - val_loss: 1310.7339\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 611.2631 - val_loss: 1428.3358\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 610.6556 - val_loss: 1510.7371\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 610.0710 - val_loss: 1602.0760\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 609.4093 - val_loss: 1688.1522\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 608.8004 - val_loss: 1780.6438\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 608.2742 - val_loss: 1906.8845\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 607.5840 - val_loss: 2012.4677\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 606.9604 - val_loss: 2128.2537\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 606.3961 - val_loss: 2263.1323\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 616.7534\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 60ms/step - loss: 618.1636 - val_loss: 341.3392\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 617.5369 - val_loss: 534.2413\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 617.0099 - val_loss: 702.6267\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 616.3922 - val_loss: 894.9628\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 615.6260 - val_loss: 1052.2264\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 614.9358 - val_loss: 1277.1517\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 614.3535 - val_loss: 1520.0009\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 613.5154 - val_loss: 1738.8674\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 612.7418 - val_loss: 1942.9041\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 612.0271 - val_loss: 2143.8306\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 611.2830 - val_loss: 2361.5479\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 610.5366 - val_loss: 2569.5940\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 609.7762 - val_loss: 2785.7119\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 609.0864 - val_loss: 3014.5955\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 608.2897 - val_loss: 3212.5801\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 607.5322 - val_loss: 3435.5281\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 606.7994 - val_loss: 3693.9353\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 606.0804 - val_loss: 3944.2490\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 605.2767 - val_loss: 4178.2109\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 604.5638 - val_loss: 4421.0840\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 603.7517 - val_loss: 4643.6748\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 622.4449\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 3s 99ms/step - loss: 619.3843 - val_loss: 564.0196\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 619.3503 - val_loss: 561.8843\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 619.3150 - val_loss: 559.2742\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 619.2747 - val_loss: 556.5321\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 619.2338 - val_loss: 553.6409\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 619.1894 - val_loss: 550.6069\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 619.1441 - val_loss: 547.2610\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 619.0974 - val_loss: 543.9101\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 619.0510 - val_loss: 540.3471\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 619.0029 - val_loss: 536.9764\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 618.9581 - val_loss: 533.4589\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 618.9062 - val_loss: 530.1401\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 618.8578 - val_loss: 526.4811\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 618.8074 - val_loss: 522.6429\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 618.7570 - val_loss: 518.5211\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 618.7023 - val_loss: 514.2428\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 618.6515 - val_loss: 509.2058\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 618.5956 - val_loss: 503.7710\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 618.5395 - val_loss: 497.7180\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 618.4815 - val_loss: 491.1741\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 618.4219 - val_loss: 484.0434\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 618.3588 - val_loss: 476.4984\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 618.2949 - val_loss: 467.9503\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 618.2309 - val_loss: 458.4632\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 618.1604 - val_loss: 448.8323\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 618.0930 - val_loss: 438.4278\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 618.0145 - val_loss: 428.3111\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 617.9374 - val_loss: 417.5999\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 617.8625 - val_loss: 406.1333\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 617.7784 - val_loss: 394.5154\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 617.6912 - val_loss: 382.7382\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 617.6066 - val_loss: 370.7311\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 617.5166 - val_loss: 358.4052\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 617.4153 - val_loss: 346.5661\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 617.3143 - val_loss: 334.8474\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 617.2101 - val_loss: 323.5000\n",
            "Epoch 37/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 617.0968 - val_loss: 313.4734\n",
            "Epoch 38/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 616.9838 - val_loss: 304.4801\n",
            "Epoch 39/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 616.8610 - val_loss: 296.8776\n",
            "Epoch 40/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 616.7388 - val_loss: 290.1082\n",
            "Epoch 41/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 616.6062 - val_loss: 284.6664\n",
            "Epoch 42/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 616.4690 - val_loss: 280.2645\n",
            "Epoch 43/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 616.3262 - val_loss: 276.9207\n",
            "Epoch 44/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 616.1801 - val_loss: 274.7074\n",
            "Epoch 45/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 616.0238 - val_loss: 274.1355\n",
            "Epoch 46/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 615.8540 - val_loss: 275.3721\n",
            "Epoch 47/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 615.6877 - val_loss: 278.4543\n",
            "Epoch 48/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 615.5072 - val_loss: 283.5186\n",
            "Epoch 49/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 615.3190 - val_loss: 290.4248\n",
            "Epoch 50/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 615.1138 - val_loss: 298.9681\n",
            "Epoch 51/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 614.9126 - val_loss: 308.9670\n",
            "Epoch 52/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 614.6987 - val_loss: 320.3703\n",
            "Epoch 53/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 614.4637 - val_loss: 332.8753\n",
            "Epoch 54/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 614.2241 - val_loss: 346.9878\n",
            "Epoch 55/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 613.9779 - val_loss: 363.6744\n",
            "Epoch 56/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 613.7100 - val_loss: 382.2768\n",
            "Epoch 57/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 613.4291 - val_loss: 402.9860\n",
            "Epoch 58/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 613.1362 - val_loss: 426.0580\n",
            "Epoch 59/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 612.8293 - val_loss: 451.7741\n",
            "Epoch 60/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 612.5134 - val_loss: 479.7374\n",
            "Epoch 61/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 612.1837 - val_loss: 510.4983\n",
            "Epoch 62/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 611.8312 - val_loss: 543.1824\n",
            "Epoch 63/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 611.4578 - val_loss: 576.7155\n",
            "Epoch 64/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 611.0690 - val_loss: 612.5358\n",
            "Epoch 65/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 610.6808 - val_loss: 650.3576\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 612.1360\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 111ms/step - loss: 618.1802 - val_loss: 496.9884\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 618.1446 - val_loss: 495.3688\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 618.1037 - val_loss: 493.3388\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 618.0569 - val_loss: 490.9237\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 618.0085 - val_loss: 488.0820\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 617.9542 - val_loss: 484.9396\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 617.8999 - val_loss: 481.4634\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 617.8448 - val_loss: 478.0832\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 617.7838 - val_loss: 474.4503\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 617.7261 - val_loss: 470.5051\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 617.6635 - val_loss: 466.5985\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 617.5984 - val_loss: 462.2911\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 617.5391 - val_loss: 457.3802\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 617.4659 - val_loss: 452.8031\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 617.3972 - val_loss: 448.0806\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 617.3293 - val_loss: 443.1945\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 617.2520 - val_loss: 438.5831\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 617.1760 - val_loss: 433.7310\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 617.0936 - val_loss: 429.0511\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 617.0142 - val_loss: 424.6147\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 616.9244 - val_loss: 420.9043\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 616.8334 - val_loss: 417.8044\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 616.7454 - val_loss: 415.0517\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 616.6508 - val_loss: 412.5106\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 616.5465 - val_loss: 410.0115\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 616.4485 - val_loss: 407.1207\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 616.3408 - val_loss: 403.9762\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 616.2262 - val_loss: 400.6995\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 616.1081 - val_loss: 397.2818\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 615.9821 - val_loss: 394.0151\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 615.8607 - val_loss: 390.8958\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 615.7249 - val_loss: 388.5656\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 615.5828 - val_loss: 387.4231\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 615.4387 - val_loss: 387.5396\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 615.2879 - val_loss: 388.8937\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 615.1358 - val_loss: 391.9605\n",
            "Epoch 37/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 614.9765 - val_loss: 397.2245\n",
            "Epoch 38/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 614.7944 - val_loss: 404.7889\n",
            "Epoch 39/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 614.6191 - val_loss: 416.1258\n",
            "Epoch 40/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 614.4363 - val_loss: 430.6660\n",
            "Epoch 41/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 614.2498 - val_loss: 446.9305\n",
            "Epoch 42/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 614.0566 - val_loss: 464.2737\n",
            "Epoch 43/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 613.8411 - val_loss: 482.1623\n",
            "Epoch 44/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 613.6333 - val_loss: 501.1550\n",
            "Epoch 45/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 613.4081 - val_loss: 520.9023\n",
            "Epoch 46/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 613.1696 - val_loss: 541.1570\n",
            "Epoch 47/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 612.9320 - val_loss: 562.0369\n",
            "Epoch 48/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 612.6686 - val_loss: 582.8977\n",
            "Epoch 49/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 612.4060 - val_loss: 604.5020\n",
            "Epoch 50/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 612.1234 - val_loss: 626.7480\n",
            "Epoch 51/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 611.8289 - val_loss: 650.0813\n",
            "Epoch 52/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 611.5300 - val_loss: 675.4774\n",
            "Epoch 53/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 611.2181 - val_loss: 703.7171\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 613.1798\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 75ms/step - loss: 618.5625 - val_loss: 565.4950\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 618.5372 - val_loss: 565.5378\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 618.5079 - val_loss: 565.5735\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 618.4774 - val_loss: 565.5314\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 618.4432 - val_loss: 565.4709\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 618.4089 - val_loss: 565.3528\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 618.3754 - val_loss: 565.2452\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 618.3399 - val_loss: 565.0987\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 618.3040 - val_loss: 564.9941\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 618.2686 - val_loss: 564.9223\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 618.2328 - val_loss: 564.8686\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 618.1974 - val_loss: 564.7163\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 618.1625 - val_loss: 564.6174\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 618.1275 - val_loss: 564.3469\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 618.0912 - val_loss: 564.1759\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 618.0551 - val_loss: 563.9803\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 618.0195 - val_loss: 563.7515\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 617.9837 - val_loss: 563.4156\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 617.9479 - val_loss: 562.8058\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 617.9096 - val_loss: 562.2573\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 617.8720 - val_loss: 561.7148\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 617.8331 - val_loss: 561.1423\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 617.7947 - val_loss: 560.4766\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 617.7557 - val_loss: 559.6583\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 617.7175 - val_loss: 558.8350\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 617.6754 - val_loss: 557.9905\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 617.6340 - val_loss: 557.0155\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 617.5906 - val_loss: 555.9667\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 617.5467 - val_loss: 554.7446\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 617.5031 - val_loss: 553.4196\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 617.4578 - val_loss: 552.0769\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 617.4086 - val_loss: 550.8698\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 617.3596 - val_loss: 549.3999\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 617.3101 - val_loss: 547.7604\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 617.2586 - val_loss: 545.6163\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 617.2033 - val_loss: 543.7267\n",
            "Epoch 37/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 617.1495 - val_loss: 541.6028\n",
            "Epoch 38/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 617.0919 - val_loss: 539.3773\n",
            "Epoch 39/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 617.0305 - val_loss: 537.2510\n",
            "Epoch 40/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 616.9712 - val_loss: 534.8934\n",
            "Epoch 41/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 616.9061 - val_loss: 532.1643\n",
            "Epoch 42/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 616.8389 - val_loss: 528.9485\n",
            "Epoch 43/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 616.7680 - val_loss: 525.4662\n",
            "Epoch 44/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 616.6945 - val_loss: 521.7935\n",
            "Epoch 45/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 616.6183 - val_loss: 517.9466\n",
            "Epoch 46/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 616.5411 - val_loss: 513.6182\n",
            "Epoch 47/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 616.4550 - val_loss: 509.4235\n",
            "Epoch 48/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 616.3687 - val_loss: 504.7156\n",
            "Epoch 49/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 616.2793 - val_loss: 499.6782\n",
            "Epoch 50/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 616.1802 - val_loss: 494.5740\n",
            "Epoch 51/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 616.0792 - val_loss: 489.3351\n",
            "Epoch 52/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 615.9744 - val_loss: 484.1132\n",
            "Epoch 53/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 615.8660 - val_loss: 479.0083\n",
            "Epoch 54/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 615.7499 - val_loss: 473.8331\n",
            "Epoch 55/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 615.6296 - val_loss: 468.9497\n",
            "Epoch 56/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 615.5028 - val_loss: 464.1626\n",
            "Epoch 57/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 615.3731 - val_loss: 459.4459\n",
            "Epoch 58/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 615.2310 - val_loss: 454.7379\n",
            "Epoch 59/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 615.0906 - val_loss: 449.6956\n",
            "Epoch 60/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 614.9347 - val_loss: 444.6617\n",
            "Epoch 61/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 614.7744 - val_loss: 439.3235\n",
            "Epoch 62/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 614.6070 - val_loss: 433.5593\n",
            "Epoch 63/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 614.4349 - val_loss: 427.7587\n",
            "Epoch 64/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 614.2470 - val_loss: 422.3477\n",
            "Epoch 65/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 614.0582 - val_loss: 417.3585\n",
            "Epoch 66/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 613.8544 - val_loss: 413.3797\n",
            "Epoch 67/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 613.6358 - val_loss: 411.1056\n",
            "Epoch 68/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 613.4164 - val_loss: 410.8542\n",
            "Epoch 69/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 613.1796 - val_loss: 412.1813\n",
            "Epoch 70/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 612.9288 - val_loss: 414.3224\n",
            "Epoch 71/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 612.6765 - val_loss: 417.0991\n",
            "Epoch 72/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 612.4107 - val_loss: 420.5439\n",
            "Epoch 73/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 612.1135 - val_loss: 424.8102\n",
            "Epoch 74/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 611.8270 - val_loss: 430.2000\n",
            "Epoch 75/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 611.5039 - val_loss: 436.9239\n",
            "Epoch 76/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 611.1908 - val_loss: 446.1683\n",
            "Epoch 77/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 610.8495 - val_loss: 458.5565\n",
            "Epoch 78/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 610.4906 - val_loss: 473.7713\n",
            "Epoch 79/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 610.1327 - val_loss: 492.5403\n",
            "Epoch 80/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 609.7401 - val_loss: 513.6694\n",
            "Epoch 81/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 609.3418 - val_loss: 538.7575\n",
            "Epoch 82/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 608.9337 - val_loss: 568.9578\n",
            "Epoch 83/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 608.4831 - val_loss: 602.2465\n",
            "Epoch 84/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 608.0342 - val_loss: 640.1250\n",
            "Epoch 85/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 607.5538 - val_loss: 681.8889\n",
            "Epoch 86/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 607.0532 - val_loss: 727.3317\n",
            "Epoch 87/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 606.5302 - val_loss: 779.1743\n",
            "Epoch 88/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 605.9984 - val_loss: 839.2603\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 602.0902\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 74ms/step - loss: 1202.1008 - val_loss: 879.9849\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1202.0546 - val_loss: 875.4478\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1202.0033 - val_loss: 870.4833\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1201.9431 - val_loss: 865.7299\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1201.8833 - val_loss: 861.1917\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1201.8157 - val_loss: 856.2336\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1201.7479 - val_loss: 851.2585\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1201.6780 - val_loss: 846.2513\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1201.6045 - val_loss: 841.4547\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1201.5261 - val_loss: 836.5262\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1201.4464 - val_loss: 830.8663\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1201.3622 - val_loss: 824.7689\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1201.2805 - val_loss: 818.0100\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1201.1901 - val_loss: 811.4342\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1201.0983 - val_loss: 804.0659\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1201.0043 - val_loss: 796.2534\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1200.9064 - val_loss: 788.2128\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1200.8081 - val_loss: 779.7019\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1200.6975 - val_loss: 771.3639\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1200.5940 - val_loss: 761.9329\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1200.4762 - val_loss: 753.0010\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1200.3704 - val_loss: 743.0676\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1200.2461 - val_loss: 733.1885\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1200.1234 - val_loss: 723.1347\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1199.9919 - val_loss: 713.8373\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1199.8668 - val_loss: 703.0181\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1199.7257 - val_loss: 691.8406\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1199.5862 - val_loss: 680.9832\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1199.4346 - val_loss: 671.3352\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1199.2791 - val_loss: 662.2321\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1199.1274 - val_loss: 653.7567\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1198.9608 - val_loss: 646.9205\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1198.7828 - val_loss: 642.2009\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1198.6176 - val_loss: 638.2964\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1198.4440 - val_loss: 636.5903\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1198.2377 - val_loss: 637.3380\n",
            "Epoch 37/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1198.0421 - val_loss: 639.3167\n",
            "Epoch 38/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1197.8439 - val_loss: 642.3955\n",
            "Epoch 39/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1197.6415 - val_loss: 646.7518\n",
            "Epoch 40/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1197.4346 - val_loss: 652.2344\n",
            "Epoch 41/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1197.1974 - val_loss: 659.1437\n",
            "Epoch 42/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1197.0055 - val_loss: 669.1021\n",
            "Epoch 43/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1196.7463 - val_loss: 681.1229\n",
            "Epoch 44/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1196.5189 - val_loss: 696.5552\n",
            "Epoch 45/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1196.2800 - val_loss: 714.8630\n",
            "Epoch 46/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1196.0325 - val_loss: 735.8553\n",
            "Epoch 47/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1195.7830 - val_loss: 761.5689\n",
            "Epoch 48/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1195.5144 - val_loss: 791.7456\n",
            "Epoch 49/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1195.2582 - val_loss: 829.3023\n",
            "Epoch 50/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1194.9722 - val_loss: 868.8611\n",
            "Epoch 51/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1194.6912 - val_loss: 913.7230\n",
            "Epoch 52/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1194.3905 - val_loss: 961.8010\n",
            "Epoch 53/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1194.1041 - val_loss: 1015.2880\n",
            "Epoch 54/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1193.7904 - val_loss: 1072.1047\n",
            "Epoch 55/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1193.4606 - val_loss: 1132.1692\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1194.4130\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 3s 530ms/step - loss: 1199.8877 - val_loss: 891.6240\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1199.8414 - val_loss: 890.2462\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1199.7875 - val_loss: 888.6899\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1199.7324 - val_loss: 887.0005\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1199.6674 - val_loss: 885.5136\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1199.6022 - val_loss: 883.7477\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1199.5342 - val_loss: 881.4682\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1199.4601 - val_loss: 878.9536\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1199.3926 - val_loss: 876.3842\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1199.3120 - val_loss: 873.6003\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1199.2372 - val_loss: 870.5658\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1199.1534 - val_loss: 867.3897\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1199.0635 - val_loss: 863.8055\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1198.9836 - val_loss: 859.1737\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1198.8929 - val_loss: 854.0671\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1198.7952 - val_loss: 849.1614\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1198.7057 - val_loss: 843.1904\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1198.6089 - val_loss: 837.2970\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1198.5104 - val_loss: 831.2911\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1198.4003 - val_loss: 825.6645\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1198.2871 - val_loss: 819.7001\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1198.1848 - val_loss: 812.1558\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1198.0671 - val_loss: 804.7227\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1197.9408 - val_loss: 797.9565\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1197.8159 - val_loss: 790.7673\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1197.6864 - val_loss: 783.5560\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1197.5621 - val_loss: 776.1766\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1197.4152 - val_loss: 769.3441\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1197.2655 - val_loss: 762.8328\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1197.1250 - val_loss: 755.9644\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1196.9740 - val_loss: 749.7153\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1196.8123 - val_loss: 744.0454\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1196.6478 - val_loss: 738.7294\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1196.4834 - val_loss: 734.0855\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1196.3105 - val_loss: 729.9993\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1196.1335 - val_loss: 726.8312\n",
            "Epoch 37/700\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1195.9426 - val_loss: 724.4794\n",
            "Epoch 38/700\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1195.7544 - val_loss: 723.3389\n",
            "Epoch 39/700\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1195.5543 - val_loss: 724.2164\n",
            "Epoch 40/700\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1195.3605 - val_loss: 727.4974\n",
            "Epoch 41/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1195.1428 - val_loss: 733.8571\n",
            "Epoch 42/700\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1194.9258 - val_loss: 743.3497\n",
            "Epoch 43/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1194.7031 - val_loss: 756.4123\n",
            "Epoch 44/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1194.4734 - val_loss: 772.8974\n",
            "Epoch 45/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1194.2295 - val_loss: 791.9731\n",
            "Epoch 46/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1193.9734 - val_loss: 813.9107\n",
            "Epoch 47/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1193.7233 - val_loss: 840.6468\n",
            "Epoch 48/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1193.4570 - val_loss: 872.2620\n",
            "Epoch 49/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1193.1979 - val_loss: 909.7706\n",
            "Epoch 50/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1192.8944 - val_loss: 949.6143\n",
            "Epoch 51/700\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1192.6091 - val_loss: 994.7422\n",
            "Epoch 52/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1192.3309 - val_loss: 1049.2552\n",
            "Epoch 53/700\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1192.0029 - val_loss: 1105.8318\n",
            "Epoch 54/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1191.7028 - val_loss: 1169.4783\n",
            "Epoch 55/700\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 1191.3676 - val_loss: 1237.2334\n",
            "Epoch 56/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1191.0261 - val_loss: 1307.6708\n",
            "Epoch 57/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1190.6810 - val_loss: 1382.0159\n",
            "Epoch 58/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1190.3429 - val_loss: 1465.1454\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1197.5403\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 86ms/step - loss: 1200.2552 - val_loss: 970.7451\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1200.2087 - val_loss: 970.1448\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1200.1620 - val_loss: 969.7788\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1200.1110 - val_loss: 969.5981\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1200.0535 - val_loss: 968.4248\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1199.9911 - val_loss: 967.5110\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1199.9298 - val_loss: 966.9844\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1199.8622 - val_loss: 966.1390\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1199.7896 - val_loss: 964.6330\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1199.7177 - val_loss: 964.0747\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1199.6448 - val_loss: 963.2282\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1199.5640 - val_loss: 962.2721\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1199.4865 - val_loss: 961.1065\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1199.3989 - val_loss: 959.1343\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1199.3164 - val_loss: 957.2085\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1199.2255 - val_loss: 955.5556\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1199.1349 - val_loss: 955.0687\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1199.0411 - val_loss: 954.7307\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1198.9368 - val_loss: 953.0058\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1198.8356 - val_loss: 950.9779\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1198.7365 - val_loss: 949.9019\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1198.6194 - val_loss: 948.0508\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1198.5060 - val_loss: 946.1875\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1198.3918 - val_loss: 944.4093\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1198.2699 - val_loss: 942.5809\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1198.1388 - val_loss: 940.5473\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1198.0068 - val_loss: 938.7476\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1197.8735 - val_loss: 937.5094\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1197.7256 - val_loss: 934.7350\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1197.5789 - val_loss: 932.1323\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1197.4312 - val_loss: 929.8813\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1197.2729 - val_loss: 927.5000\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1197.1045 - val_loss: 924.3312\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1196.9384 - val_loss: 921.3265\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1196.7727 - val_loss: 919.8185\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1196.5822 - val_loss: 916.7499\n",
            "Epoch 37/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1196.3940 - val_loss: 913.2577\n",
            "Epoch 38/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1196.2029 - val_loss: 909.4457\n",
            "Epoch 39/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1196.0024 - val_loss: 905.1255\n",
            "Epoch 40/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1195.7971 - val_loss: 900.9216\n",
            "Epoch 41/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1195.5792 - val_loss: 896.2697\n",
            "Epoch 42/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1195.3738 - val_loss: 892.2183\n",
            "Epoch 43/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1195.1431 - val_loss: 886.6656\n",
            "Epoch 44/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1194.9235 - val_loss: 882.3010\n",
            "Epoch 45/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1194.6726 - val_loss: 876.2495\n",
            "Epoch 46/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1194.4368 - val_loss: 870.9554\n",
            "Epoch 47/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1194.1975 - val_loss: 865.4249\n",
            "Epoch 48/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1193.9192 - val_loss: 859.4843\n",
            "Epoch 49/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1193.6678 - val_loss: 854.3008\n",
            "Epoch 50/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1193.3846 - val_loss: 848.7684\n",
            "Epoch 51/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1193.0975 - val_loss: 841.5914\n",
            "Epoch 52/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1192.8094 - val_loss: 835.6303\n",
            "Epoch 53/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1192.5068 - val_loss: 830.1131\n",
            "Epoch 54/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1192.1915 - val_loss: 824.9539\n",
            "Epoch 55/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1191.8707 - val_loss: 819.3242\n",
            "Epoch 56/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1191.5574 - val_loss: 814.6107\n",
            "Epoch 57/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1191.2283 - val_loss: 807.9436\n",
            "Epoch 58/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1190.8726 - val_loss: 798.8194\n",
            "Epoch 59/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1190.5374 - val_loss: 789.1663\n",
            "Epoch 60/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1190.1962 - val_loss: 780.5079\n",
            "Epoch 61/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1189.8409 - val_loss: 771.6070\n",
            "Epoch 62/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1189.4573 - val_loss: 760.8920\n",
            "Epoch 63/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1189.0984 - val_loss: 751.6533\n",
            "Epoch 64/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1188.7094 - val_loss: 743.2639\n",
            "Epoch 65/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1188.3344 - val_loss: 735.9089\n",
            "Epoch 66/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1187.9215 - val_loss: 727.7693\n",
            "Epoch 67/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1187.4937 - val_loss: 718.8163\n",
            "Epoch 68/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1187.0701 - val_loss: 711.2305\n",
            "Epoch 69/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1186.6251 - val_loss: 702.3200\n",
            "Epoch 70/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1186.2074 - val_loss: 696.3157\n",
            "Epoch 71/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1185.7540 - val_loss: 689.4822\n",
            "Epoch 72/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1185.2629 - val_loss: 681.3382\n",
            "Epoch 73/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1184.8074 - val_loss: 673.6680\n",
            "Epoch 74/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1184.3303 - val_loss: 665.9061\n",
            "Epoch 75/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1183.8239 - val_loss: 657.9985\n",
            "Epoch 76/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1183.3400 - val_loss: 651.5220\n",
            "Epoch 77/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1182.8120 - val_loss: 644.6994\n",
            "Epoch 78/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1182.2726 - val_loss: 637.7791\n",
            "Epoch 79/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1181.7549 - val_loss: 631.8602\n",
            "Epoch 80/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1181.2052 - val_loss: 625.5961\n",
            "Epoch 81/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1180.6447 - val_loss: 618.8204\n",
            "Epoch 82/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1180.0914 - val_loss: 613.6434\n",
            "Epoch 83/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1179.5229 - val_loss: 607.9581\n",
            "Epoch 84/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1178.9248 - val_loss: 602.1402\n",
            "Epoch 85/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1178.3337 - val_loss: 595.7137\n",
            "Epoch 86/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1177.7274 - val_loss: 590.1437\n",
            "Epoch 87/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1177.0946 - val_loss: 584.1974\n",
            "Epoch 88/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1176.4805 - val_loss: 579.7627\n",
            "Epoch 89/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1175.8755 - val_loss: 575.7393\n",
            "Epoch 90/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1175.1968 - val_loss: 571.6990\n",
            "Epoch 91/700\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1174.5406 - val_loss: 568.0920\n",
            "Epoch 92/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1173.8441 - val_loss: 564.6813\n",
            "Epoch 93/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1173.2094 - val_loss: 562.3159\n",
            "Epoch 94/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1172.4884 - val_loss: 560.9903\n",
            "Epoch 95/700\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1171.7865 - val_loss: 560.9614\n",
            "Epoch 96/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1171.1143 - val_loss: 562.1378\n",
            "Epoch 97/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1170.3826 - val_loss: 564.6616\n",
            "Epoch 98/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1169.6320 - val_loss: 569.6238\n",
            "Epoch 99/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1168.8920 - val_loss: 576.0755\n",
            "Epoch 100/700\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 1168.1615 - val_loss: 583.3222\n",
            "Epoch 101/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1167.3719 - val_loss: 592.3713\n",
            "Epoch 102/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1166.6034 - val_loss: 601.4778\n",
            "Epoch 103/700\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1165.7990 - val_loss: 611.4104\n",
            "Epoch 104/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1164.9688 - val_loss: 624.7509\n",
            "Epoch 105/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1164.1864 - val_loss: 637.6801\n",
            "Epoch 106/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1163.3466 - val_loss: 652.4888\n",
            "Epoch 107/700\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1162.5151 - val_loss: 670.4922\n",
            "Epoch 108/700\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 1161.6747 - val_loss: 688.4039\n",
            "Epoch 109/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1160.8193 - val_loss: 710.6580\n",
            "Epoch 110/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1159.9314 - val_loss: 735.1731\n",
            "Epoch 111/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1159.0718 - val_loss: 760.6108\n",
            "Epoch 112/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1158.1823 - val_loss: 788.4937\n",
            "Epoch 113/700\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 1157.2218 - val_loss: 822.4461\n",
            "Epoch 114/700\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1156.2896 - val_loss: 856.7020\n",
            "Epoch 115/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1155.3882 - val_loss: 887.5632\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1178.4718\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 82ms/step - loss: 915.0611 - val_loss: 652.6495\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 913.9298 - val_loss: 731.6448\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 911.9885 - val_loss: 918.9416\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 908.4771 - val_loss: 1664.6160\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 902.4578 - val_loss: 3226.0232\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 893.5374 - val_loss: 5433.7148\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 880.7795 - val_loss: 8410.1680\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 864.0227 - val_loss: 12328.5322\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 840.4232 - val_loss: 17217.8711\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 811.4360 - val_loss: 23117.1055\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 775.4671 - val_loss: 30291.6582\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 734.7298 - val_loss: 38673.6680\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 689.1245 - val_loss: 47714.5273\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 643.1374 - val_loss: 56073.1055\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 595.2187 - val_loss: 62137.7031\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 552.6009 - val_loss: 66921.1797\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 507.8537 - val_loss: 70366.7344\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 472.0583 - val_loss: 71936.7578\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 436.1903 - val_loss: 71760.5938\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 407.5550 - val_loss: 72416.4609\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 380.9124 - val_loss: 74501.7656\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 467.7894\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 115ms/step - loss: 913.4852 - val_loss: 506.0181\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 912.4490 - val_loss: 460.1582\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 910.6835 - val_loss: 634.6367\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 907.6039 - val_loss: 1304.9015\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 902.5293 - val_loss: 2646.6082\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 894.6004 - val_loss: 4569.0391\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 884.0858 - val_loss: 7120.9121\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 869.7111 - val_loss: 10318.2891\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 851.2617 - val_loss: 14287.7607\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 828.3986 - val_loss: 18892.8047\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 800.3352 - val_loss: 24738.9531\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 768.8323 - val_loss: 31587.3457\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 731.7500 - val_loss: 38797.2578\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 693.5054 - val_loss: 46125.9648\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 656.4028 - val_loss: 52240.2461\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 618.8387 - val_loss: 56117.2422\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 582.2562 - val_loss: 59111.8789\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 546.4392 - val_loss: 61471.6953\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 511.1952 - val_loss: 62565.4492\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 477.9034 - val_loss: 63432.1445\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 442.3730 - val_loss: 65194.4609\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 409.1913 - val_loss: 65922.2422\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 475.2357\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 78ms/step - loss: 913.9631 - val_loss: 688.9133\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 912.9414 - val_loss: 763.2935\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 911.1827 - val_loss: 829.7541\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 908.0939 - val_loss: 962.9327\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 903.1912 - val_loss: 1166.4523\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 895.6194 - val_loss: 1321.7687\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 884.9915 - val_loss: 1512.0090\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 870.9492 - val_loss: 1490.2067\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 852.3599 - val_loss: 1409.0323\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 828.1666 - val_loss: 1553.4498\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 799.5222 - val_loss: 1589.2778\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 766.3241 - val_loss: 1508.8014\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 727.4175 - val_loss: 916.6294\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 688.8525 - val_loss: 2204.6018\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 652.2794 - val_loss: 5364.3296\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 616.3193 - val_loss: 7917.4258\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 580.5333 - val_loss: 10116.8750\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 546.9536 - val_loss: 12721.4873\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 512.2812 - val_loss: 15660.2012\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 479.6494 - val_loss: 19033.0020\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 446.4407 - val_loss: 22904.7715\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 569.0899\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 73ms/step - loss: 314.1975 - val_loss: 282.5413\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 314.1923 - val_loss: 282.1243\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 314.1854 - val_loss: 281.5820\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 314.1786 - val_loss: 280.9687\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 314.1715 - val_loss: 280.3008\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 314.1638 - val_loss: 279.5179\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 314.1553 - val_loss: 278.6080\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 314.1469 - val_loss: 277.6597\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 314.1383 - val_loss: 276.7372\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 314.1290 - val_loss: 275.6404\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 314.1201 - val_loss: 274.5771\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 314.1110 - val_loss: 273.6719\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 314.1019 - val_loss: 272.5923\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 314.0918 - val_loss: 271.5128\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 314.0821 - val_loss: 270.4822\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 314.0720 - val_loss: 269.1313\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 314.0616 - val_loss: 267.6243\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 314.0521 - val_loss: 266.0443\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 314.0411 - val_loss: 264.7133\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 314.0298 - val_loss: 263.3879\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 314.0186 - val_loss: 261.9315\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 314.0070 - val_loss: 260.4013\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 313.9967 - val_loss: 258.5345\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 313.9841 - val_loss: 256.7007\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 313.9720 - val_loss: 254.9514\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 313.9588 - val_loss: 253.2826\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 313.9466 - val_loss: 251.5495\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 313.9336 - val_loss: 249.4309\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 313.9200 - val_loss: 247.2636\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 313.9072 - val_loss: 244.9318\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 313.8936 - val_loss: 242.7728\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 313.8784 - val_loss: 240.8055\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 313.8633 - val_loss: 238.6050\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 313.8483 - val_loss: 236.4255\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 313.8339 - val_loss: 233.6242\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 313.8175 - val_loss: 231.0727\n",
            "Epoch 37/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 313.8027 - val_loss: 228.2249\n",
            "Epoch 38/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 313.7845 - val_loss: 225.6303\n",
            "Epoch 39/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 313.7683 - val_loss: 222.9917\n",
            "Epoch 40/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 313.7513 - val_loss: 220.2131\n",
            "Epoch 41/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 313.7332 - val_loss: 217.3424\n",
            "Epoch 42/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 313.7177 - val_loss: 214.0419\n",
            "Epoch 43/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 313.6973 - val_loss: 211.2686\n",
            "Epoch 44/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 313.6789 - val_loss: 208.2878\n",
            "Epoch 45/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 313.6610 - val_loss: 204.9634\n",
            "Epoch 46/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 313.6411 - val_loss: 201.6110\n",
            "Epoch 47/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 313.6201 - val_loss: 198.2096\n",
            "Epoch 48/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 313.6000 - val_loss: 194.6486\n",
            "Epoch 49/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 313.5787 - val_loss: 191.2489\n",
            "Epoch 50/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 313.5566 - val_loss: 187.9308\n",
            "Epoch 51/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 313.5374 - val_loss: 184.3786\n",
            "Epoch 52/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 313.5126 - val_loss: 181.2449\n",
            "Epoch 53/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 313.4908 - val_loss: 177.9085\n",
            "Epoch 54/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 313.4678 - val_loss: 174.6078\n",
            "Epoch 55/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 313.4439 - val_loss: 171.6611\n",
            "Epoch 56/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 313.4194 - val_loss: 168.8800\n",
            "Epoch 57/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 313.3970 - val_loss: 165.6281\n",
            "Epoch 58/700\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 313.3703 - val_loss: 162.5410\n",
            "Epoch 59/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 313.3471 - val_loss: 159.0854\n",
            "Epoch 60/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 313.3196 - val_loss: 155.8311\n",
            "Epoch 61/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 313.2940 - val_loss: 152.4349\n",
            "Epoch 62/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 313.2673 - val_loss: 148.8591\n",
            "Epoch 63/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 313.2377 - val_loss: 145.3800\n",
            "Epoch 64/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 313.2104 - val_loss: 141.4730\n",
            "Epoch 65/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 313.1806 - val_loss: 137.5947\n",
            "Epoch 66/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 313.1527 - val_loss: 133.3663\n",
            "Epoch 67/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 313.1221 - val_loss: 129.4199\n",
            "Epoch 68/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 313.0885 - val_loss: 125.7970\n",
            "Epoch 69/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 313.0571 - val_loss: 122.2018\n",
            "Epoch 70/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 313.0265 - val_loss: 118.6964\n",
            "Epoch 71/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 312.9911 - val_loss: 115.6445\n",
            "Epoch 72/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 312.9564 - val_loss: 112.7037\n",
            "Epoch 73/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 312.9225 - val_loss: 109.8600\n",
            "Epoch 74/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 312.8865 - val_loss: 107.4056\n",
            "Epoch 75/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 312.8535 - val_loss: 105.0036\n",
            "Epoch 76/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 312.8181 - val_loss: 102.9276\n",
            "Epoch 77/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 312.7773 - val_loss: 101.2547\n",
            "Epoch 78/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 312.7408 - val_loss: 99.8652\n",
            "Epoch 79/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 312.7032 - val_loss: 98.8660\n",
            "Epoch 80/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 312.6640 - val_loss: 98.3808\n",
            "Epoch 81/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 312.6239 - val_loss: 98.4117\n",
            "Epoch 82/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 312.5856 - val_loss: 98.9594\n",
            "Epoch 83/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 312.5464 - val_loss: 99.9917\n",
            "Epoch 84/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 312.5030 - val_loss: 101.3984\n",
            "Epoch 85/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 312.4622 - val_loss: 103.0721\n",
            "Epoch 86/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 312.4209 - val_loss: 104.9393\n",
            "Epoch 87/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 312.3791 - val_loss: 107.1913\n",
            "Epoch 88/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 312.3346 - val_loss: 109.7669\n",
            "Epoch 89/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 312.2935 - val_loss: 112.8388\n",
            "Epoch 90/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 312.2495 - val_loss: 116.2911\n",
            "Epoch 91/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 312.2030 - val_loss: 120.0227\n",
            "Epoch 92/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 312.1559 - val_loss: 124.0243\n",
            "Epoch 93/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 312.1087 - val_loss: 128.2600\n",
            "Epoch 94/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 312.0625 - val_loss: 133.1926\n",
            "Epoch 95/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 312.0161 - val_loss: 138.7088\n",
            "Epoch 96/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 311.9726 - val_loss: 144.8493\n",
            "Epoch 97/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 311.9164 - val_loss: 150.5580\n",
            "Epoch 98/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 311.8666 - val_loss: 157.2203\n",
            "Epoch 99/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 311.8167 - val_loss: 164.8208\n",
            "Epoch 100/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 311.7672 - val_loss: 172.8843\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 312.3685\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 98ms/step - loss: 313.6499 - val_loss: 290.3967\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 313.6441 - val_loss: 290.4311\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 313.6385 - val_loss: 290.4419\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 313.6323 - val_loss: 290.3662\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 313.6254 - val_loss: 290.2089\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 313.6181 - val_loss: 289.9409\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 313.6105 - val_loss: 289.6449\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 313.6028 - val_loss: 289.2263\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 313.5948 - val_loss: 288.7849\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 313.5860 - val_loss: 288.4227\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 313.5776 - val_loss: 287.9530\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 313.5688 - val_loss: 287.5783\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 313.5598 - val_loss: 287.0078\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 313.5507 - val_loss: 286.4599\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 313.5410 - val_loss: 285.7812\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 313.5310 - val_loss: 285.1352\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 313.5215 - val_loss: 284.3752\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 313.5114 - val_loss: 283.5538\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 313.5001 - val_loss: 282.7330\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 313.4898 - val_loss: 281.8565\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 313.4792 - val_loss: 280.9823\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 313.4681 - val_loss: 280.1526\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 313.4561 - val_loss: 279.4619\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 313.4445 - val_loss: 278.6309\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 313.4335 - val_loss: 277.6011\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 313.4210 - val_loss: 276.5902\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 313.4080 - val_loss: 275.7007\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 313.3958 - val_loss: 274.7858\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 313.3828 - val_loss: 273.9461\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 313.3693 - val_loss: 272.9801\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 313.3561 - val_loss: 271.6801\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 313.3428 - val_loss: 270.2269\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 313.3269 - val_loss: 268.8953\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 313.3115 - val_loss: 267.4484\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 313.2991 - val_loss: 265.7059\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 313.2808 - val_loss: 264.2578\n",
            "Epoch 37/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 313.2657 - val_loss: 262.9331\n",
            "Epoch 38/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 313.2486 - val_loss: 261.2897\n",
            "Epoch 39/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 313.2333 - val_loss: 259.4344\n",
            "Epoch 40/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 313.2148 - val_loss: 257.7749\n",
            "Epoch 41/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 313.1975 - val_loss: 255.7389\n",
            "Epoch 42/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 313.1791 - val_loss: 253.8205\n",
            "Epoch 43/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 313.1601 - val_loss: 251.8014\n",
            "Epoch 44/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 313.1428 - val_loss: 249.4359\n",
            "Epoch 45/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 313.1220 - val_loss: 247.3493\n",
            "Epoch 46/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 313.1034 - val_loss: 244.9234\n",
            "Epoch 47/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 313.0840 - val_loss: 242.4388\n",
            "Epoch 48/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 313.0643 - val_loss: 239.9627\n",
            "Epoch 49/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 313.0406 - val_loss: 237.8090\n",
            "Epoch 50/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 313.0200 - val_loss: 235.5303\n",
            "Epoch 51/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 312.9977 - val_loss: 233.1039\n",
            "Epoch 52/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 312.9767 - val_loss: 230.5369\n",
            "Epoch 53/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 312.9522 - val_loss: 227.9132\n",
            "Epoch 54/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 312.9298 - val_loss: 224.9953\n",
            "Epoch 55/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 312.9066 - val_loss: 221.9926\n",
            "Epoch 56/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 312.8801 - val_loss: 219.0179\n",
            "Epoch 57/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 312.8554 - val_loss: 215.6536\n",
            "Epoch 58/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 312.8319 - val_loss: 212.3773\n",
            "Epoch 59/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 312.8028 - val_loss: 209.6496\n",
            "Epoch 60/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 312.7777 - val_loss: 206.7268\n",
            "Epoch 61/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 312.7504 - val_loss: 203.9019\n",
            "Epoch 62/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 312.7236 - val_loss: 200.9902\n",
            "Epoch 63/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 312.6972 - val_loss: 197.8555\n",
            "Epoch 64/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 312.6677 - val_loss: 194.6221\n",
            "Epoch 65/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 312.6389 - val_loss: 191.3775\n",
            "Epoch 66/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 312.6085 - val_loss: 188.1701\n",
            "Epoch 67/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 312.5806 - val_loss: 184.6538\n",
            "Epoch 68/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 312.5478 - val_loss: 181.3697\n",
            "Epoch 69/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 312.5167 - val_loss: 178.2165\n",
            "Epoch 70/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 312.4844 - val_loss: 175.0979\n",
            "Epoch 71/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 312.4531 - val_loss: 171.7532\n",
            "Epoch 72/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 312.4194 - val_loss: 168.5691\n",
            "Epoch 73/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 312.3858 - val_loss: 165.5460\n",
            "Epoch 74/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 312.3510 - val_loss: 162.6777\n",
            "Epoch 75/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 312.3145 - val_loss: 159.8747\n",
            "Epoch 76/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 312.2804 - val_loss: 156.8663\n",
            "Epoch 77/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 312.2434 - val_loss: 154.0058\n",
            "Epoch 78/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 312.2060 - val_loss: 151.2190\n",
            "Epoch 79/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 312.1668 - val_loss: 148.7011\n",
            "Epoch 80/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 312.1295 - val_loss: 146.3748\n",
            "Epoch 81/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 312.0910 - val_loss: 144.2871\n",
            "Epoch 82/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 312.0486 - val_loss: 142.5040\n",
            "Epoch 83/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 312.0056 - val_loss: 140.9662\n",
            "Epoch 84/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 311.9698 - val_loss: 139.5253\n",
            "Epoch 85/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 311.9249 - val_loss: 138.6104\n",
            "Epoch 86/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 311.8805 - val_loss: 138.1242\n",
            "Epoch 87/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 311.8362 - val_loss: 138.0306\n",
            "Epoch 88/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 311.7960 - val_loss: 138.3566\n",
            "Epoch 89/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 311.7478 - val_loss: 139.0662\n",
            "Epoch 90/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 311.7042 - val_loss: 140.3108\n",
            "Epoch 91/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 311.6554 - val_loss: 141.9917\n",
            "Epoch 92/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 311.6106 - val_loss: 144.3109\n",
            "Epoch 93/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 311.5615 - val_loss: 147.2702\n",
            "Epoch 94/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 311.5148 - val_loss: 150.7734\n",
            "Epoch 95/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 311.4682 - val_loss: 154.6559\n",
            "Epoch 96/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 311.4146 - val_loss: 158.7134\n",
            "Epoch 97/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 311.3695 - val_loss: 163.6529\n",
            "Epoch 98/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 311.3135 - val_loss: 168.7581\n",
            "Epoch 99/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 311.2646 - val_loss: 174.9088\n",
            "Epoch 100/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 311.2101 - val_loss: 181.3940\n",
            "Epoch 101/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 311.1580 - val_loss: 188.6486\n",
            "Epoch 102/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 311.1043 - val_loss: 196.4286\n",
            "Epoch 103/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 311.0489 - val_loss: 204.3287\n",
            "Epoch 104/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 310.9948 - val_loss: 212.6072\n",
            "Epoch 105/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 310.9366 - val_loss: 221.2402\n",
            "Epoch 106/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 310.8819 - val_loss: 230.0600\n",
            "Epoch 107/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 310.8257 - val_loss: 239.4473\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 312.7073\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 124ms/step - loss: 313.6914 - val_loss: 268.5715\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 313.6853 - val_loss: 269.1629\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 313.6788 - val_loss: 269.8342\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 313.6722 - val_loss: 270.4977\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 313.6644 - val_loss: 271.2190\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 313.6563 - val_loss: 271.8534\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 313.6477 - val_loss: 272.7372\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 313.6389 - val_loss: 273.5979\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 313.6322 - val_loss: 274.5722\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 313.6210 - val_loss: 275.2706\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 313.6117 - val_loss: 275.9698\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 313.6027 - val_loss: 276.8125\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 313.5930 - val_loss: 277.6041\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 313.5829 - val_loss: 278.3797\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 313.5732 - val_loss: 279.3470\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 313.5622 - val_loss: 280.1720\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 313.5516 - val_loss: 281.1262\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 313.5409 - val_loss: 282.1929\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 313.5292 - val_loss: 283.0460\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 313.5182 - val_loss: 284.0580\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 313.5062 - val_loss: 284.8707\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 314.0990\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 77ms/step - loss: 1389.0890 - val_loss: 1109.4802\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1388.7814 - val_loss: 1097.9539\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1388.3892 - val_loss: 1087.3788\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1387.9448 - val_loss: 1073.2659\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1387.4580 - val_loss: 1055.4572\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1386.9233 - val_loss: 1036.5060\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1386.2562 - val_loss: 1018.7787\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1385.5861 - val_loss: 993.1923\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1384.8076 - val_loss: 966.7136\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1383.8903 - val_loss: 941.7595\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1382.8457 - val_loss: 924.5009\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1381.6029 - val_loss: 913.8705\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1380.1337 - val_loss: 908.8470\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1378.4479 - val_loss: 913.8523\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1376.4691 - val_loss: 939.3286\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1374.2686 - val_loss: 1005.2300\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1371.6415 - val_loss: 1106.7010\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1368.5007 - val_loss: 1244.3123\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1364.9541 - val_loss: 1447.5472\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1360.7393 - val_loss: 1749.4388\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1355.6134 - val_loss: 2121.4788\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1349.9619 - val_loss: 2581.0576\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1343.6255 - val_loss: 3216.6562\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1336.0184 - val_loss: 4034.0276\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1327.3140 - val_loss: 4979.8179\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1317.0601 - val_loss: 6044.4360\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1306.0901 - val_loss: 7281.1992\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1292.6444 - val_loss: 8657.6562\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1278.1759 - val_loss: 10260.5127\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1261.5911 - val_loss: 12115.1650\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1242.5281 - val_loss: 14235.1465\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1221.9719 - val_loss: 16638.9375\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1197.2024 - val_loss: 19271.7246\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1239.8300\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 3s 106ms/step - loss: 1386.7900 - val_loss: 1188.9628\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1386.4556 - val_loss: 1196.0721\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1386.0323 - val_loss: 1201.8330\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1385.5630 - val_loss: 1206.6185\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1385.0538 - val_loss: 1212.4775\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1384.4847 - val_loss: 1219.2489\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1383.8715 - val_loss: 1224.6522\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1383.1627 - val_loss: 1226.1925\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1382.3730 - val_loss: 1224.0527\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1381.5503 - val_loss: 1216.3453\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1380.5057 - val_loss: 1206.6831\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1379.4709 - val_loss: 1187.8651\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1378.2261 - val_loss: 1164.8544\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1376.7902 - val_loss: 1136.2219\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1375.1926 - val_loss: 1100.8395\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1373.3455 - val_loss: 1075.5734\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1371.3665 - val_loss: 1081.2864\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1369.0037 - val_loss: 1113.0573\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1366.1404 - val_loss: 1154.3107\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1363.0502 - val_loss: 1197.1512\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1359.3324 - val_loss: 1256.5477\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1355.0143 - val_loss: 1341.7990\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1350.2428 - val_loss: 1455.8888\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1344.4745 - val_loss: 1618.4684\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1337.8545 - val_loss: 1866.3517\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1330.8048 - val_loss: 2284.6304\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1322.0742 - val_loss: 2854.0452\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1311.9730 - val_loss: 3571.1042\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1300.8375 - val_loss: 4520.3535\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1288.4830 - val_loss: 5655.8198\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1274.0669 - val_loss: 6967.7100\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1258.3286 - val_loss: 8509.2773\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1238.8959 - val_loss: 10271.1289\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1219.4125 - val_loss: 12373.5703\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1194.5613 - val_loss: 14738.1035\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1168.9418 - val_loss: 17507.8711\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1197.0526\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 80ms/step - loss: 1387.2487 - val_loss: 1158.6320\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1386.8864 - val_loss: 1179.7395\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1386.4862 - val_loss: 1199.5267\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1385.9973 - val_loss: 1219.0175\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1385.4993 - val_loss: 1239.6864\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1384.9247 - val_loss: 1260.0371\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1384.2786 - val_loss: 1280.6342\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1383.5380 - val_loss: 1302.3365\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1382.7660 - val_loss: 1329.3083\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1381.8572 - val_loss: 1357.4568\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1380.8214 - val_loss: 1386.3683\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1379.6801 - val_loss: 1416.5437\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1378.3832 - val_loss: 1450.4285\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1376.9005 - val_loss: 1485.3120\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1375.2405 - val_loss: 1527.8284\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1373.4165 - val_loss: 1573.8405\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1371.2561 - val_loss: 1621.6932\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1368.7362 - val_loss: 1671.6849\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1366.0414 - val_loss: 1730.4470\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1362.9021 - val_loss: 1790.3824\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1359.2544 - val_loss: 1855.8702\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1375.2850\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 60ms/step - loss: 1295.8969 - val_loss: 261.0858\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1295.8879 - val_loss: 260.4932\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1295.8805 - val_loss: 259.8621\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1295.8716 - val_loss: 259.2799\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1295.8622 - val_loss: 258.5806\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1295.8541 - val_loss: 257.9541\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1295.8425 - val_loss: 257.1435\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1295.8322 - val_loss: 256.4007\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1295.8224 - val_loss: 255.3891\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1295.8116 - val_loss: 254.6007\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1295.8007 - val_loss: 253.7368\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1295.7906 - val_loss: 252.8349\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1295.7812 - val_loss: 251.8989\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1295.7704 - val_loss: 251.4007\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1295.7598 - val_loss: 250.7846\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1295.7495 - val_loss: 250.1050\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1295.7400 - val_loss: 249.3604\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1295.7289 - val_loss: 248.5805\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1295.7188 - val_loss: 247.7639\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1295.7086 - val_loss: 247.1887\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1295.6980 - val_loss: 246.5356\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1295.6875 - val_loss: 245.8812\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1295.6779 - val_loss: 245.0473\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1295.6674 - val_loss: 244.5318\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1295.6575 - val_loss: 243.9562\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1295.6467 - val_loss: 243.5861\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1295.6361 - val_loss: 243.3940\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1295.6262 - val_loss: 243.0522\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1295.6167 - val_loss: 242.6119\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1295.6068 - val_loss: 242.3285\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1295.5962 - val_loss: 242.0283\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1295.5862 - val_loss: 241.8898\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1295.5760 - val_loss: 241.3178\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1295.5663 - val_loss: 240.8499\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1295.5558 - val_loss: 240.2939\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1295.5460 - val_loss: 239.3497\n",
            "Epoch 37/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1295.5353 - val_loss: 238.9626\n",
            "Epoch 38/700\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1295.5244 - val_loss: 238.2027\n",
            "Epoch 39/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1295.5145 - val_loss: 237.3894\n",
            "Epoch 40/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1295.5044 - val_loss: 236.5210\n",
            "Epoch 41/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1295.4933 - val_loss: 235.8252\n",
            "Epoch 42/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1295.4830 - val_loss: 235.2461\n",
            "Epoch 43/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1295.4727 - val_loss: 234.6522\n",
            "Epoch 44/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1295.4623 - val_loss: 233.9449\n",
            "Epoch 45/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1295.4523 - val_loss: 233.0426\n",
            "Epoch 46/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1295.4430 - val_loss: 232.0996\n",
            "Epoch 47/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1295.4337 - val_loss: 231.1993\n",
            "Epoch 48/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1295.4207 - val_loss: 230.8142\n",
            "Epoch 49/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1295.4111 - val_loss: 230.1953\n",
            "Epoch 50/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1295.4003 - val_loss: 229.8065\n",
            "Epoch 51/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1295.3904 - val_loss: 229.3769\n",
            "Epoch 52/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1295.3805 - val_loss: 229.1714\n",
            "Epoch 53/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1295.3702 - val_loss: 228.7996\n",
            "Epoch 54/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1295.3605 - val_loss: 228.0899\n",
            "Epoch 55/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1295.3496 - val_loss: 227.5392\n",
            "Epoch 56/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1295.3394 - val_loss: 226.9736\n",
            "Epoch 57/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1295.3290 - val_loss: 226.4978\n",
            "Epoch 58/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1295.3181 - val_loss: 226.1079\n",
            "Epoch 59/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1295.3102 - val_loss: 225.5881\n",
            "Epoch 60/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1295.2983 - val_loss: 225.3351\n",
            "Epoch 61/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1295.2896 - val_loss: 224.8725\n",
            "Epoch 62/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1295.2780 - val_loss: 224.5641\n",
            "Epoch 63/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1295.2682 - val_loss: 224.2094\n",
            "Epoch 64/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1295.2576 - val_loss: 224.0516\n",
            "Epoch 65/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1295.2477 - val_loss: 223.7449\n",
            "Epoch 66/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1295.2375 - val_loss: 223.5039\n",
            "Epoch 67/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1295.2272 - val_loss: 223.2340\n",
            "Epoch 68/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1295.2174 - val_loss: 222.9991\n",
            "Epoch 69/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1295.2070 - val_loss: 222.9150\n",
            "Epoch 70/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1295.1971 - val_loss: 222.6026\n",
            "Epoch 71/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1295.1866 - val_loss: 222.3488\n",
            "Epoch 72/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 1295.1769 - val_loss: 222.0949\n",
            "Epoch 73/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1295.1666 - val_loss: 221.8164\n",
            "Epoch 74/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1295.1564 - val_loss: 221.5691\n",
            "Epoch 75/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1295.1476 - val_loss: 221.2762\n",
            "Epoch 76/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1295.1364 - val_loss: 221.1796\n",
            "Epoch 77/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1295.1263 - val_loss: 221.0949\n",
            "Epoch 78/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1295.1157 - val_loss: 220.9066\n",
            "Epoch 79/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1295.1082 - val_loss: 220.5292\n",
            "Epoch 80/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1295.0955 - val_loss: 220.3720\n",
            "Epoch 81/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1295.0861 - val_loss: 220.1988\n",
            "Epoch 82/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1295.0768 - val_loss: 219.9559\n",
            "Epoch 83/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1295.0659 - val_loss: 219.9171\n",
            "Epoch 84/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1295.0560 - val_loss: 219.8038\n",
            "Epoch 85/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1295.0455 - val_loss: 219.6421\n",
            "Epoch 86/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1295.0363 - val_loss: 219.4473\n",
            "Epoch 87/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1295.0260 - val_loss: 219.3654\n",
            "Epoch 88/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1295.0157 - val_loss: 219.3521\n",
            "Epoch 89/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1295.0052 - val_loss: 219.1655\n",
            "Epoch 90/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1294.9951 - val_loss: 218.9551\n",
            "Epoch 91/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1294.9858 - val_loss: 218.7065\n",
            "Epoch 92/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1294.9752 - val_loss: 218.6064\n",
            "Epoch 93/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1294.9645 - val_loss: 218.4509\n",
            "Epoch 94/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1294.9557 - val_loss: 218.1888\n",
            "Epoch 95/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1294.9442 - val_loss: 218.0588\n",
            "Epoch 96/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1294.9346 - val_loss: 217.8672\n",
            "Epoch 97/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1294.9243 - val_loss: 217.7069\n",
            "Epoch 98/700\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1294.9138 - val_loss: 217.5875\n",
            "Epoch 99/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1294.9043 - val_loss: 217.5109\n",
            "Epoch 100/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1294.8945 - val_loss: 217.3813\n",
            "Epoch 101/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1294.8839 - val_loss: 217.2600\n",
            "Epoch 102/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1294.8741 - val_loss: 217.2294\n",
            "Epoch 103/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1294.8638 - val_loss: 217.0970\n",
            "Epoch 104/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1294.8536 - val_loss: 216.9391\n",
            "Epoch 105/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1294.8435 - val_loss: 216.7478\n",
            "Epoch 106/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1294.8334 - val_loss: 216.5844\n",
            "Epoch 107/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1294.8225 - val_loss: 216.4364\n",
            "Epoch 108/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1294.8126 - val_loss: 216.3064\n",
            "Epoch 109/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1294.8033 - val_loss: 216.1629\n",
            "Epoch 110/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1294.7924 - val_loss: 216.0914\n",
            "Epoch 111/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1294.7826 - val_loss: 216.0484\n",
            "Epoch 112/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1294.7725 - val_loss: 216.0575\n",
            "Epoch 113/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1294.7634 - val_loss: 215.9290\n",
            "Epoch 114/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1294.7523 - val_loss: 215.8762\n",
            "Epoch 115/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1294.7427 - val_loss: 215.8032\n",
            "Epoch 116/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1294.7322 - val_loss: 215.7563\n",
            "Epoch 117/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1294.7220 - val_loss: 215.6769\n",
            "Epoch 118/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1294.7118 - val_loss: 215.5891\n",
            "Epoch 119/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1294.7017 - val_loss: 215.4941\n",
            "Epoch 120/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1294.6913 - val_loss: 215.4095\n",
            "Epoch 121/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1294.6808 - val_loss: 215.3246\n",
            "Epoch 122/700\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1294.6715 - val_loss: 215.2420\n",
            "Epoch 123/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1294.6606 - val_loss: 215.1499\n",
            "Epoch 124/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1294.6500 - val_loss: 215.1054\n",
            "Epoch 125/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1294.6399 - val_loss: 215.0787\n",
            "Epoch 126/700\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1294.6299 - val_loss: 215.0744\n",
            "Epoch 127/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1294.6194 - val_loss: 215.0814\n",
            "Epoch 128/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1294.6093 - val_loss: 215.0945\n",
            "Epoch 129/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1294.5992 - val_loss: 215.1096\n",
            "Epoch 130/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1294.5891 - val_loss: 215.1290\n",
            "Epoch 131/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1294.5795 - val_loss: 215.1498\n",
            "Epoch 132/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1294.5693 - val_loss: 215.1738\n",
            "Epoch 133/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1294.5592 - val_loss: 215.1949\n",
            "Epoch 134/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1294.5488 - val_loss: 215.2201\n",
            "Epoch 135/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1294.5392 - val_loss: 215.2482\n",
            "Epoch 136/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1294.5292 - val_loss: 215.2858\n",
            "Epoch 137/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1294.5183 - val_loss: 215.3258\n",
            "Epoch 138/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1294.5085 - val_loss: 215.3615\n",
            "Epoch 139/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1294.4980 - val_loss: 215.4089\n",
            "Epoch 140/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1294.4883 - val_loss: 215.4594\n",
            "Epoch 141/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1294.4786 - val_loss: 215.5583\n",
            "Epoch 142/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1294.4684 - val_loss: 215.6476\n",
            "Epoch 143/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1294.4570 - val_loss: 215.7119\n",
            "Epoch 144/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1294.4473 - val_loss: 215.7634\n",
            "Epoch 145/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1294.4382 - val_loss: 215.8760\n",
            "Epoch 146/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1294.4270 - val_loss: 215.9577\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1291.3812\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 87ms/step - loss: 1293.6887 - val_loss: 260.4662\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1293.6786 - val_loss: 259.7929\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1293.6708 - val_loss: 259.0169\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1293.6613 - val_loss: 257.9413\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1293.6514 - val_loss: 257.0226\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1293.6409 - val_loss: 255.9360\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1293.6309 - val_loss: 254.6477\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1293.6199 - val_loss: 253.4794\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1293.6095 - val_loss: 252.4458\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1293.5981 - val_loss: 251.5058\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1293.5874 - val_loss: 250.6577\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1293.5769 - val_loss: 249.8051\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1293.5658 - val_loss: 249.1483\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1293.5552 - val_loss: 248.5763\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1293.5436 - val_loss: 247.7077\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1293.5342 - val_loss: 246.7325\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1293.5221 - val_loss: 246.0490\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1293.5110 - val_loss: 245.3577\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1293.5000 - val_loss: 244.8009\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1293.4895 - val_loss: 244.0441\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1293.4791 - val_loss: 243.5520\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1293.4672 - val_loss: 243.0169\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1293.4564 - val_loss: 242.1448\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1293.4464 - val_loss: 240.9892\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1293.4352 - val_loss: 239.9956\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1293.4238 - val_loss: 239.2422\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1293.4122 - val_loss: 238.6013\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1293.4020 - val_loss: 237.7680\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1293.3906 - val_loss: 237.1449\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1293.3811 - val_loss: 236.4423\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1293.3698 - val_loss: 235.8921\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1293.3586 - val_loss: 235.2662\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1293.3478 - val_loss: 234.4793\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1293.3367 - val_loss: 233.7769\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1293.3256 - val_loss: 233.0114\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1293.3141 - val_loss: 232.1736\n",
            "Epoch 37/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1293.3031 - val_loss: 231.3203\n",
            "Epoch 38/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1293.2933 - val_loss: 230.3621\n",
            "Epoch 39/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1293.2814 - val_loss: 229.6857\n",
            "Epoch 40/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1293.2699 - val_loss: 229.1926\n",
            "Epoch 41/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1293.2594 - val_loss: 228.6872\n",
            "Epoch 42/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1293.2489 - val_loss: 228.2457\n",
            "Epoch 43/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1293.2380 - val_loss: 227.9133\n",
            "Epoch 44/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1293.2269 - val_loss: 227.5659\n",
            "Epoch 45/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1293.2172 - val_loss: 227.2384\n",
            "Epoch 46/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1293.2063 - val_loss: 227.0549\n",
            "Epoch 47/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1293.1976 - val_loss: 226.3951\n",
            "Epoch 48/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1293.1847 - val_loss: 225.9868\n",
            "Epoch 49/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1293.1740 - val_loss: 225.5625\n",
            "Epoch 50/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1293.1630 - val_loss: 225.0547\n",
            "Epoch 51/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1293.1523 - val_loss: 224.5285\n",
            "Epoch 52/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1293.1418 - val_loss: 223.8577\n",
            "Epoch 53/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1293.1301 - val_loss: 223.3161\n",
            "Epoch 54/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1293.1195 - val_loss: 222.7707\n",
            "Epoch 55/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1293.1080 - val_loss: 222.3853\n",
            "Epoch 56/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1293.0980 - val_loss: 221.8369\n",
            "Epoch 57/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1293.0863 - val_loss: 221.5291\n",
            "Epoch 58/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1293.0760 - val_loss: 221.1309\n",
            "Epoch 59/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1293.0645 - val_loss: 220.8131\n",
            "Epoch 60/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1293.0536 - val_loss: 220.4952\n",
            "Epoch 61/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1293.0433 - val_loss: 220.0209\n",
            "Epoch 62/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1293.0330 - val_loss: 219.6103\n",
            "Epoch 63/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1293.0209 - val_loss: 219.3062\n",
            "Epoch 64/700\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1293.0100 - val_loss: 218.9199\n",
            "Epoch 65/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1292.9995 - val_loss: 218.5426\n",
            "Epoch 66/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1292.9893 - val_loss: 218.2282\n",
            "Epoch 67/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1292.9780 - val_loss: 218.0292\n",
            "Epoch 68/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1292.9664 - val_loss: 217.8896\n",
            "Epoch 69/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1292.9557 - val_loss: 217.6604\n",
            "Epoch 70/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1292.9447 - val_loss: 217.4479\n",
            "Epoch 71/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1292.9337 - val_loss: 217.2504\n",
            "Epoch 72/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1292.9230 - val_loss: 217.0469\n",
            "Epoch 73/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1292.9127 - val_loss: 216.7919\n",
            "Epoch 74/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1292.9014 - val_loss: 216.5873\n",
            "Epoch 75/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1292.8905 - val_loss: 216.3911\n",
            "Epoch 76/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1292.8802 - val_loss: 216.1335\n",
            "Epoch 77/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1292.8689 - val_loss: 215.9671\n",
            "Epoch 78/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1292.8585 - val_loss: 215.8191\n",
            "Epoch 79/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1292.8477 - val_loss: 215.6564\n",
            "Epoch 80/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1292.8364 - val_loss: 215.5465\n",
            "Epoch 81/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1292.8267 - val_loss: 215.4155\n",
            "Epoch 82/700\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1292.8158 - val_loss: 215.2869\n",
            "Epoch 83/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1292.8048 - val_loss: 215.2002\n",
            "Epoch 84/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1292.7941 - val_loss: 215.1502\n",
            "Epoch 85/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1292.7838 - val_loss: 215.0573\n",
            "Epoch 86/700\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1292.7731 - val_loss: 214.9648\n",
            "Epoch 87/700\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1292.7629 - val_loss: 214.8785\n",
            "Epoch 88/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1292.7512 - val_loss: 214.8389\n",
            "Epoch 89/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1292.7411 - val_loss: 214.7770\n",
            "Epoch 90/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1292.7306 - val_loss: 214.7280\n",
            "Epoch 91/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1292.7191 - val_loss: 214.7057\n",
            "Epoch 92/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1292.7092 - val_loss: 214.6820\n",
            "Epoch 93/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1292.6984 - val_loss: 214.6692\n",
            "Epoch 94/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1292.6875 - val_loss: 214.6688\n",
            "Epoch 95/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1292.6771 - val_loss: 214.6806\n",
            "Epoch 96/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1292.6667 - val_loss: 214.6994\n",
            "Epoch 97/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1292.6564 - val_loss: 214.7264\n",
            "Epoch 98/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1292.6449 - val_loss: 214.7534\n",
            "Epoch 99/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1292.6351 - val_loss: 214.7887\n",
            "Epoch 100/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1292.6245 - val_loss: 214.8287\n",
            "Epoch 101/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1292.6136 - val_loss: 214.8619\n",
            "Epoch 102/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1292.6031 - val_loss: 214.9020\n",
            "Epoch 103/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1292.5929 - val_loss: 214.9541\n",
            "Epoch 104/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1292.5826 - val_loss: 215.0090\n",
            "Epoch 105/700\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1292.5724 - val_loss: 215.0599\n",
            "Epoch 106/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1292.5614 - val_loss: 215.1097\n",
            "Epoch 107/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1292.5513 - val_loss: 215.1388\n",
            "Epoch 108/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1292.5414 - val_loss: 215.2233\n",
            "Epoch 109/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1292.5299 - val_loss: 215.2955\n",
            "Epoch 110/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1292.5199 - val_loss: 215.3818\n",
            "Epoch 111/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1292.5096 - val_loss: 215.5188\n",
            "Epoch 112/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1292.4977 - val_loss: 215.6533\n",
            "Epoch 113/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1292.4875 - val_loss: 215.8181\n",
            "Epoch 114/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1292.4769 - val_loss: 215.9817\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 1296.0067\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 102ms/step - loss: 1294.0769 - val_loss: 262.7763\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1294.0654 - val_loss: 264.1917\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1294.0554 - val_loss: 265.8335\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1294.0426 - val_loss: 267.5501\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1294.0304 - val_loss: 269.4340\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1294.0181 - val_loss: 271.5298\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1294.0049 - val_loss: 273.5623\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1293.9915 - val_loss: 275.6702\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1293.9792 - val_loss: 277.9626\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1293.9653 - val_loss: 280.2111\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1293.9515 - val_loss: 282.3747\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1293.9377 - val_loss: 284.5983\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1293.9254 - val_loss: 286.8900\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1293.9116 - val_loss: 289.2038\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1293.8977 - val_loss: 291.4929\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1293.8844 - val_loss: 293.6069\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1293.8718 - val_loss: 295.7950\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1293.8578 - val_loss: 298.2719\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1293.8442 - val_loss: 300.5173\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1293.8329 - val_loss: 303.3566\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1293.8177 - val_loss: 305.4441\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 1295.5868\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 128ms/step - loss: 1107.5278 - val_loss: 229.5851\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1107.5181 - val_loss: 229.0848\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 1107.5079 - val_loss: 228.3196\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1107.4954 - val_loss: 227.5442\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1107.4840 - val_loss: 226.7817\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1107.4717 - val_loss: 226.0907\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1107.4583 - val_loss: 225.0035\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1107.4449 - val_loss: 223.7328\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1107.4314 - val_loss: 222.5549\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1107.4202 - val_loss: 221.2177\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1107.4045 - val_loss: 220.3618\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1107.3914 - val_loss: 219.5431\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1107.3790 - val_loss: 218.6702\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1107.3655 - val_loss: 218.0556\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1107.3523 - val_loss: 217.3739\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1107.3398 - val_loss: 216.8375\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1107.3264 - val_loss: 216.7676\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1107.3129 - val_loss: 216.1778\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1107.2997 - val_loss: 215.5469\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1107.2861 - val_loss: 214.4969\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1107.2723 - val_loss: 213.2289\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1107.2582 - val_loss: 211.9885\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1107.2451 - val_loss: 210.7233\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1107.2312 - val_loss: 209.6270\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1107.2202 - val_loss: 208.5488\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1107.2046 - val_loss: 207.9996\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1107.1919 - val_loss: 207.5258\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1107.1788 - val_loss: 206.7476\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1107.1664 - val_loss: 205.9163\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1107.1525 - val_loss: 205.3089\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1107.1399 - val_loss: 204.7159\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1107.1260 - val_loss: 204.2663\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1107.1125 - val_loss: 203.7210\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1107.0992 - val_loss: 203.2447\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1107.0870 - val_loss: 202.8199\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1107.0730 - val_loss: 202.4906\n",
            "Epoch 37/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1107.0603 - val_loss: 201.9194\n",
            "Epoch 38/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1107.0482 - val_loss: 201.4989\n",
            "Epoch 39/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1107.0350 - val_loss: 200.9804\n",
            "Epoch 40/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1107.0214 - val_loss: 200.5323\n",
            "Epoch 41/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1107.0084 - val_loss: 200.3703\n",
            "Epoch 42/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1106.9948 - val_loss: 199.9168\n",
            "Epoch 43/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1106.9816 - val_loss: 199.4013\n",
            "Epoch 44/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1106.9689 - val_loss: 198.9675\n",
            "Epoch 45/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1106.9583 - val_loss: 198.3230\n",
            "Epoch 46/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1106.9429 - val_loss: 197.9629\n",
            "Epoch 47/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1106.9293 - val_loss: 197.5071\n",
            "Epoch 48/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1106.9172 - val_loss: 196.9317\n",
            "Epoch 49/700\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1106.9038 - val_loss: 196.5467\n",
            "Epoch 50/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1106.8910 - val_loss: 196.1626\n",
            "Epoch 51/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1106.8771 - val_loss: 195.9014\n",
            "Epoch 52/700\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1106.8640 - val_loss: 195.6450\n",
            "Epoch 53/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1106.8507 - val_loss: 195.3528\n",
            "Epoch 54/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1106.8384 - val_loss: 195.0880\n",
            "Epoch 55/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1106.8250 - val_loss: 194.9126\n",
            "Epoch 56/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1106.8115 - val_loss: 194.6515\n",
            "Epoch 57/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1106.7992 - val_loss: 194.3909\n",
            "Epoch 58/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1106.7859 - val_loss: 194.1602\n",
            "Epoch 59/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1106.7727 - val_loss: 193.8400\n",
            "Epoch 60/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1106.7588 - val_loss: 193.5751\n",
            "Epoch 61/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1106.7461 - val_loss: 193.2018\n",
            "Epoch 62/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1106.7328 - val_loss: 192.9393\n",
            "Epoch 63/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1106.7196 - val_loss: 192.6850\n",
            "Epoch 64/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1106.7073 - val_loss: 192.3505\n",
            "Epoch 65/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1106.6938 - val_loss: 192.1988\n",
            "Epoch 66/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1106.6796 - val_loss: 191.9911\n",
            "Epoch 67/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1106.6663 - val_loss: 191.7948\n",
            "Epoch 68/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1106.6530 - val_loss: 191.5328\n",
            "Epoch 69/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1106.6406 - val_loss: 191.2858\n",
            "Epoch 70/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1106.6259 - val_loss: 191.1476\n",
            "Epoch 71/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1106.6128 - val_loss: 191.0282\n",
            "Epoch 72/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1106.5995 - val_loss: 190.9295\n",
            "Epoch 73/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1106.5862 - val_loss: 190.8111\n",
            "Epoch 74/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1106.5725 - val_loss: 190.7130\n",
            "Epoch 75/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1106.5597 - val_loss: 190.6470\n",
            "Epoch 76/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1106.5476 - val_loss: 190.5888\n",
            "Epoch 77/700\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1106.5332 - val_loss: 190.5759\n",
            "Epoch 78/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1106.5193 - val_loss: 190.5742\n",
            "Epoch 79/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1106.5066 - val_loss: 190.5900\n",
            "Epoch 80/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1106.4929 - val_loss: 190.6173\n",
            "Epoch 81/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1106.4796 - val_loss: 190.6514\n",
            "Epoch 82/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1106.4672 - val_loss: 190.6909\n",
            "Epoch 83/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1106.4542 - val_loss: 190.7391\n",
            "Epoch 84/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1106.4406 - val_loss: 190.7907\n",
            "Epoch 85/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1106.4277 - val_loss: 190.8571\n",
            "Epoch 86/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1106.4147 - val_loss: 190.9561\n",
            "Epoch 87/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1106.4015 - val_loss: 191.0802\n",
            "Epoch 88/700\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 1106.3884 - val_loss: 191.2061\n",
            "Epoch 89/700\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1106.3746 - val_loss: 191.2775\n",
            "Epoch 90/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1106.3621 - val_loss: 191.4043\n",
            "Epoch 91/700\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 1106.3486 - val_loss: 191.5894\n",
            "Epoch 92/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1106.3350 - val_loss: 191.7848\n",
            "Epoch 93/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1106.3219 - val_loss: 191.9945\n",
            "Epoch 94/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1106.3088 - val_loss: 192.1574\n",
            "Epoch 95/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1106.2957 - val_loss: 192.3150\n",
            "Epoch 96/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1106.2820 - val_loss: 192.4991\n",
            "Epoch 97/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1106.2690 - val_loss: 192.7437\n",
            "Epoch 98/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1106.2576 - val_loss: 193.0551\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1103.7167\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 3s 104ms/step - loss: 1105.6578 - val_loss: 229.4294\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1105.6476 - val_loss: 229.0538\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1105.6366 - val_loss: 228.5234\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1105.6254 - val_loss: 227.7109\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1105.6133 - val_loss: 226.6888\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1105.5994 - val_loss: 225.6292\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 1105.5856 - val_loss: 224.3096\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1105.5729 - val_loss: 223.0417\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1105.5590 - val_loss: 222.0772\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 1105.5454 - val_loss: 221.3486\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1105.5322 - val_loss: 220.4237\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1105.5175 - val_loss: 219.8295\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1105.5048 - val_loss: 218.9649\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1105.4913 - val_loss: 217.9412\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1105.4767 - val_loss: 216.9663\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1105.4623 - val_loss: 215.8611\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 1105.4489 - val_loss: 214.7054\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 1105.4342 - val_loss: 213.8571\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 1105.4209 - val_loss: 213.0133\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1105.4060 - val_loss: 212.3868\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1105.3921 - val_loss: 211.6266\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1105.3783 - val_loss: 210.7060\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1105.3641 - val_loss: 210.0521\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1105.3503 - val_loss: 209.0297\n",
            "Epoch 25/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1105.3378 - val_loss: 207.9183\n",
            "Epoch 26/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1105.3231 - val_loss: 207.3287\n",
            "Epoch 27/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1105.3092 - val_loss: 206.8672\n",
            "Epoch 28/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1105.2960 - val_loss: 206.4526\n",
            "Epoch 29/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1105.2827 - val_loss: 206.2718\n",
            "Epoch 30/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1105.2686 - val_loss: 205.8232\n",
            "Epoch 31/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1105.2556 - val_loss: 205.2750\n",
            "Epoch 32/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1105.2423 - val_loss: 204.4525\n",
            "Epoch 33/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1105.2273 - val_loss: 203.8081\n",
            "Epoch 34/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1105.2137 - val_loss: 203.0045\n",
            "Epoch 35/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1105.1996 - val_loss: 202.1875\n",
            "Epoch 36/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1105.1854 - val_loss: 201.3544\n",
            "Epoch 37/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1105.1727 - val_loss: 200.4248\n",
            "Epoch 38/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1105.1561 - val_loss: 199.7764\n",
            "Epoch 39/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1105.1434 - val_loss: 198.9571\n",
            "Epoch 40/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1105.1285 - val_loss: 198.4331\n",
            "Epoch 41/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1105.1146 - val_loss: 197.8072\n",
            "Epoch 42/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1105.1001 - val_loss: 197.2488\n",
            "Epoch 43/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1105.0869 - val_loss: 196.5305\n",
            "Epoch 44/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1105.0724 - val_loss: 195.7332\n",
            "Epoch 45/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1105.0586 - val_loss: 195.0827\n",
            "Epoch 46/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1105.0437 - val_loss: 194.5699\n",
            "Epoch 47/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1105.0298 - val_loss: 194.0389\n",
            "Epoch 48/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1105.0165 - val_loss: 193.4931\n",
            "Epoch 49/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1105.0021 - val_loss: 193.0988\n",
            "Epoch 50/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1104.9873 - val_loss: 192.7041\n",
            "Epoch 51/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1104.9740 - val_loss: 192.2640\n",
            "Epoch 52/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1104.9587 - val_loss: 191.9566\n",
            "Epoch 53/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1104.9459 - val_loss: 191.6240\n",
            "Epoch 54/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1104.9316 - val_loss: 191.3891\n",
            "Epoch 55/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1104.9193 - val_loss: 191.1395\n",
            "Epoch 56/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1104.9065 - val_loss: 190.9412\n",
            "Epoch 57/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1104.8894 - val_loss: 190.8679\n",
            "Epoch 58/700\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 1104.8760 - val_loss: 190.7620\n",
            "Epoch 59/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1104.8617 - val_loss: 190.6532\n",
            "Epoch 60/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1104.8481 - val_loss: 190.5559\n",
            "Epoch 61/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1104.8351 - val_loss: 190.4356\n",
            "Epoch 62/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1104.8209 - val_loss: 190.3732\n",
            "Epoch 63/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1104.8066 - val_loss: 190.3567\n",
            "Epoch 64/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1104.7930 - val_loss: 190.3588\n",
            "Epoch 65/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1104.7786 - val_loss: 190.3692\n",
            "Epoch 66/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1104.7646 - val_loss: 190.3911\n",
            "Epoch 67/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1104.7512 - val_loss: 190.4396\n",
            "Epoch 68/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1104.7372 - val_loss: 190.4997\n",
            "Epoch 69/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1104.7246 - val_loss: 190.6004\n",
            "Epoch 70/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1104.7090 - val_loss: 190.7011\n",
            "Epoch 71/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1104.6960 - val_loss: 190.8386\n",
            "Epoch 72/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1104.6832 - val_loss: 191.0012\n",
            "Epoch 73/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1104.6671 - val_loss: 191.1111\n",
            "Epoch 74/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1104.6539 - val_loss: 191.3107\n",
            "Epoch 75/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1104.6411 - val_loss: 191.5207\n",
            "Epoch 76/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1104.6272 - val_loss: 191.7838\n",
            "Epoch 77/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1104.6121 - val_loss: 191.9850\n",
            "Epoch 78/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1104.5981 - val_loss: 192.2177\n",
            "Epoch 79/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1104.5852 - val_loss: 192.4923\n",
            "Epoch 80/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1104.5704 - val_loss: 192.7537\n",
            "Epoch 81/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1104.5563 - val_loss: 193.1110\n",
            "Epoch 82/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1104.5430 - val_loss: 193.5406\n",
            "Epoch 83/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1104.5282 - val_loss: 193.9045\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1107.6012\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 1s 81ms/step - loss: 1105.9890 - val_loss: 230.9987\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1105.9741 - val_loss: 232.6619\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1105.9611 - val_loss: 234.5450\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1105.9456 - val_loss: 236.6020\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1105.9298 - val_loss: 239.1035\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1105.9139 - val_loss: 241.3647\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1105.8977 - val_loss: 243.6489\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1105.8802 - val_loss: 245.5550\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1105.8645 - val_loss: 247.9977\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1105.8470 - val_loss: 250.2337\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1105.8303 - val_loss: 252.7255\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 1105.8126 - val_loss: 255.0086\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1105.7957 - val_loss: 257.3263\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1105.7791 - val_loss: 260.1757\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1105.7599 - val_loss: 263.3442\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1105.7432 - val_loss: 266.8044\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1105.7261 - val_loss: 270.5554\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1105.7079 - val_loss: 274.6437\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 1105.6890 - val_loss: 278.6275\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1105.6703 - val_loss: 282.3139\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 1105.6533 - val_loss: 286.5943\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1107.2988\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 4s 99ms/step - loss: 518.3062 - val_loss: 456.7248\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 517.3696 - val_loss: 420.6250\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 515.7394 - val_loss: 351.0426\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 512.6252 - val_loss: 269.5243\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 506.4963 - val_loss: 337.0411\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 494.9711 - val_loss: 1195.0499\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 474.1129 - val_loss: 2911.3882\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 438.7191 - val_loss: 5951.1323\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 390.0743 - val_loss: 10539.5957\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 346.1817 - val_loss: 14565.9404\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 332.1693 - val_loss: 15270.0146\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 316.9868 - val_loss: 13413.2881\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 298.9451 - val_loss: 11032.9209\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 282.6143 - val_loss: 8834.4209\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 266.4844 - val_loss: 7341.5044\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 250.6231 - val_loss: 5864.0298\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 234.3091 - val_loss: 4207.9990\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 219.6381 - val_loss: 2483.3850\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 204.6750 - val_loss: 741.9451\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 191.0649 - val_loss: 1221.2781\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 176.4554 - val_loss: 3635.5581\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 161.4315 - val_loss: 5944.8208\n",
            "Epoch 23/700\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 148.1370 - val_loss: 8124.7817\n",
            "Epoch 24/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 136.0121 - val_loss: 9953.0674\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 167.9760\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 2s 93ms/step - loss: 517.6348 - val_loss: 449.5874\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 516.7793 - val_loss: 438.8864\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 515.5179 - val_loss: 444.5038\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 513.2606 - val_loss: 527.1519\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 509.0009 - val_loss: 775.7745\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 501.5229 - val_loss: 1582.6469\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 487.4478 - val_loss: 3622.5181\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 464.6715 - val_loss: 7115.7363\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 429.1702 - val_loss: 13201.2832\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 382.7271 - val_loss: 21602.8262\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 346.9985 - val_loss: 27501.9766\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 322.6880 - val_loss: 27385.0840\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 294.7926 - val_loss: 21976.2285\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 255.1181 - val_loss: 14960.3076\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 219.6305 - val_loss: 11107.1611\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 183.3259 - val_loss: 9141.3750\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 155.9579 - val_loss: 3563.8628\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 137.6337 - val_loss: 2432.1677\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 123.9545 - val_loss: 6774.6172\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 110.8810 - val_loss: 13379.7295\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 98.7977 - val_loss: 14363.5234\n",
            "Epoch 22/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 91.6691 - val_loss: 19447.0684\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 132.2566\n",
            "Epoch 1/700\n",
            "4/4 [==============================] - 3s 124ms/step - loss: 517.8726 - val_loss: 465.5806\n",
            "Epoch 2/700\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 517.2399 - val_loss: 468.3279\n",
            "Epoch 3/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 516.3655 - val_loss: 466.2011\n",
            "Epoch 4/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 514.7551 - val_loss: 475.6920\n",
            "Epoch 5/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 511.7919 - val_loss: 509.4337\n",
            "Epoch 6/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 506.2619 - val_loss: 558.5818\n",
            "Epoch 7/700\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 496.1714 - val_loss: 622.3679\n",
            "Epoch 8/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 478.1019 - val_loss: 684.7554\n",
            "Epoch 9/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 445.5696 - val_loss: 689.5370\n",
            "Epoch 10/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 397.9587 - val_loss: 589.7080\n",
            "Epoch 11/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 356.1371 - val_loss: 908.3460\n",
            "Epoch 12/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 330.1249 - val_loss: 1917.5481\n",
            "Epoch 13/700\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 307.5656 - val_loss: 3255.6731\n",
            "Epoch 14/700\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 282.4156 - val_loss: 5129.1104\n",
            "Epoch 15/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 253.8066 - val_loss: 7665.9800\n",
            "Epoch 16/700\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 223.8421 - val_loss: 11164.4658\n",
            "Epoch 17/700\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 191.5306 - val_loss: 15577.1484\n",
            "Epoch 18/700\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 161.3162 - val_loss: 20990.0977\n",
            "Epoch 19/700\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 135.0464 - val_loss: 26838.0352\n",
            "Epoch 20/700\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 116.9636 - val_loss: 31581.7539\n",
            "Epoch 21/700\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 102.6647 - val_loss: 34100.6602\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 188.9858\n",
            "Epoch 1/700\n",
            "6/6 [==============================] - 2s 48ms/step - loss: 104.2258 - val_loss: 1586.7256\n",
            "Epoch 2/700\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 65.8448 - val_loss: 4505.0171\n",
            "Epoch 3/700\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 42.2539 - val_loss: 2636.6033\n",
            "Epoch 4/700\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 29.9830 - val_loss: 1653.8439\n",
            "Epoch 5/700\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 20.1846 - val_loss: 1290.4410\n",
            "Epoch 6/700\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 13.3720 - val_loss: 893.5760\n",
            "Epoch 7/700\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 10.7659 - val_loss: 786.4694\n",
            "Epoch 8/700\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 7.1647 - val_loss: 1196.6152\n",
            "Epoch 9/700\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 6.0690 - val_loss: 989.9088\n",
            "Epoch 10/700\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 5.5512 - val_loss: 1264.6901\n",
            "Epoch 11/700\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 4.8734 - val_loss: 1329.9944\n",
            "Epoch 12/700\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 4.2075 - val_loss: 1207.4794\n",
            "Epoch 13/700\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 3.3500 - val_loss: 1528.7020\n",
            "Epoch 14/700\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 4.0336 - val_loss: 1235.3265\n",
            "Epoch 15/700\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 3.6113 - val_loss: 1395.3541\n",
            "Epoch 16/700\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 3.5005 - val_loss: 1311.0947\n",
            "Epoch 17/700\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 2.7800 - val_loss: 1380.6949\n",
            "Epoch 18/700\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 2.7678 - val_loss: 1199.9158\n",
            "Epoch 19/700\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 3.1548 - val_loss: 1156.4296\n",
            "Epoch 20/700\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 2.6975 - val_loss: 1392.2985\n",
            "Epoch 21/700\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 2.8087 - val_loss: 1163.1091\n",
            "Epoch 22/700\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 3.0265 - val_loss: 1362.4067\n",
            "Epoch 23/700\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 3.0051 - val_loss: 1367.0223\n",
            "Epoch 24/700\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 2.8432 - val_loss: 1299.4142\n",
            "Epoch 25/700\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 2.9631 - val_loss: 1183.1954\n",
            "Epoch 26/700\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.6049 - val_loss: 1150.1295\n",
            "Epoch 27/700\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 2.9558 - val_loss: 1271.7115\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3,\n",
              "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x7f5be8d5af10>,\n",
              "                   n_iter=500,\n",
              "                   param_distributions={'Huberloss': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
              "                                        'learning_rate': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f5bc8b64b50>,\n",
              "                                        'n_hidden': array([0, 1, 2, 3, 4]),\n",
              "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
              "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
              "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
              "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
              "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
              "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7f5be8d5af10&gt;,\n",
              "                   n_iter=500,\n",
              "                   param_distributions={&#x27;Huberloss&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
              "                                        &#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f5bc8b64b50&gt;,\n",
              "                                        &#x27;n_hidden&#x27;: array([0, 1, 2, 3, 4]),\n",
              "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
              "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
              "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
              "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
              "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
              "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7f5be8d5af10&gt;,\n",
              "                   n_iter=500,\n",
              "                   param_distributions={&#x27;Huberloss&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
              "                                        &#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f5bc8b64b50&gt;,\n",
              "                                        &#x27;n_hidden&#x27;: array([0, 1, 2, 3, 4]),\n",
              "                                        &#x27;n_neurons&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
              "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
              "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
              "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
              "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7f5be8d5af10&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x7f5be8d5af10&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_search_cv.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXRnL_ZbwuQh",
        "outputId": "4999ecb2-f773-48b8-d833-c7348ad12012"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Huberloss': 1,\n",
              " 'learning_rate': 0.022581069891024586,\n",
              " 'n_hidden': 3,\n",
              " 'n_neurons': 33}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([keras.layers.InputLayer(input_shape = [30,]),\n",
        "keras.layers.Dropout(rate=0.3),                               \n",
        "keras.layers.Dense(33, activation = \"selu\"),\n",
        "keras.layers.Dense(33, activation = \"selu\"),\n",
        "keras.layers.Dense(33, activation = \"selu\"),\n",
        "keras.layers.Dense(9, kernel_initializer=initializer)\n",
        "])\n",
        "model.compile(loss=HuberLoss(1), optimizer = keras.optimizers.Nadam(learning_rate=0.022581069891024586,), metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, Y_train, epochs = 700, validation_data = (X_valid, Y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=20)])\n",
        "mse_test = model.evaluate(x_test, y_test)\n"
      ],
      "metadata": {
        "id": "LE7LYLujzdZe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5be55816-ce11-4707-f91d-472e4512d21c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "6/6 [==============================] - 3s 67ms/step - loss: 104.4857 - accuracy: 0.0405 - val_loss: 712.9058 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/700\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 67.7519 - accuracy: 0.0694 - val_loss: 8317.9053 - val_accuracy: 1.0000\n",
            "Epoch 3/700\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 49.2946 - accuracy: 0.4913 - val_loss: 3262.5334 - val_accuracy: 1.0000\n",
            "Epoch 4/700\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 34.7868 - accuracy: 0.9711 - val_loss: 1183.0684 - val_accuracy: 1.0000\n",
            "Epoch 5/700\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 24.8313 - accuracy: 0.9769 - val_loss: 764.7717 - val_accuracy: 1.0000\n",
            "Epoch 6/700\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 17.8025 - accuracy: 0.9884 - val_loss: 161.5143 - val_accuracy: 0.9831\n",
            "Epoch 7/700\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.0235 - accuracy: 0.9942 - val_loss: 110.9460 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/700\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 8.0186 - accuracy: 1.0000 - val_loss: 115.3063 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/700\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 6.5534 - accuracy: 1.0000 - val_loss: 115.2006 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.5620 - accuracy: 1.0000 - val_loss: 117.8291 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/700\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.5015 - accuracy: 1.0000 - val_loss: 114.7362 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/700\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.9713 - accuracy: 1.0000 - val_loss: 116.6534 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.3344 - accuracy: 1.0000 - val_loss: 117.9538 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.4187 - accuracy: 1.0000 - val_loss: 118.4104 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/700\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.2419 - accuracy: 1.0000 - val_loss: 116.4614 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.8233 - accuracy: 1.0000 - val_loss: 115.3351 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.4120 - accuracy: 1.0000 - val_loss: 117.8166 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/700\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.7286 - accuracy: 1.0000 - val_loss: 111.7718 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/700\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 3.4597 - accuracy: 1.0000 - val_loss: 112.2817 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.1998 - accuracy: 1.0000 - val_loss: 112.2087 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/700\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.5942 - accuracy: 1.0000 - val_loss: 112.7462 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.1144 - accuracy: 1.0000 - val_loss: 111.1773 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/700\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 3.4029 - accuracy: 1.0000 - val_loss: 109.4428 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.3580 - accuracy: 1.0000 - val_loss: 108.3651 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.3820 - accuracy: 1.0000 - val_loss: 107.4724 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.1124 - accuracy: 1.0000 - val_loss: 108.4120 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.2548 - accuracy: 1.0000 - val_loss: 108.4603 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/700\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.1476 - accuracy: 1.0000 - val_loss: 108.1696 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.2836 - accuracy: 1.0000 - val_loss: 108.6360 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.0814 - accuracy: 1.0000 - val_loss: 110.2042 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/700\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.6738 - accuracy: 1.0000 - val_loss: 109.5028 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/700\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.8956 - accuracy: 1.0000 - val_loss: 109.8637 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.8405 - accuracy: 1.0000 - val_loss: 109.2262 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/700\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.7781 - accuracy: 1.0000 - val_loss: 108.4757 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.5402 - accuracy: 1.0000 - val_loss: 108.4015 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.9071 - accuracy: 1.0000 - val_loss: 108.5003 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/700\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.5808 - accuracy: 1.0000 - val_loss: 108.6485 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/700\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 2.4512 - accuracy: 1.0000 - val_loss: 108.5077 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.8079 - accuracy: 1.0000 - val_loss: 108.2717 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/700\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.7710 - accuracy: 1.0000 - val_loss: 108.1148 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/700\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.6405 - accuracy: 1.0000 - val_loss: 107.9667 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/700\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.8294 - accuracy: 1.0000 - val_loss: 107.3129 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.8511 - accuracy: 1.0000 - val_loss: 106.7155 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/700\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 2.8001 - accuracy: 1.0000 - val_loss: 106.9009 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/700\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 2.4165 - accuracy: 1.0000 - val_loss: 106.5104 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/700\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.6136 - accuracy: 1.0000 - val_loss: 106.4785 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.5965 - accuracy: 1.0000 - val_loss: 107.1428 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.3604 - accuracy: 1.0000 - val_loss: 108.2893 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.7251 - accuracy: 1.0000 - val_loss: 109.0228 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/700\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.7223 - accuracy: 1.0000 - val_loss: 109.4770 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/700\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.2854 - accuracy: 1.0000 - val_loss: 109.1841 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/700\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.7852 - accuracy: 1.0000 - val_loss: 108.7643 - val_accuracy: 0.0169\n",
            "Epoch 53/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.7012 - accuracy: 1.0000 - val_loss: 109.7409 - val_accuracy: 0.2203\n",
            "Epoch 54/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.2004 - accuracy: 1.0000 - val_loss: 110.3892 - val_accuracy: 1.0000\n",
            "Epoch 55/700\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.1884 - accuracy: 1.0000 - val_loss: 112.5036 - val_accuracy: 1.0000\n",
            "Epoch 56/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.8019 - accuracy: 1.0000 - val_loss: 110.6974 - val_accuracy: 1.0000\n",
            "Epoch 57/700\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 2.3797 - accuracy: 1.0000 - val_loss: 110.6864 - val_accuracy: 1.0000\n",
            "Epoch 58/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.3655 - accuracy: 1.0000 - val_loss: 110.5012 - val_accuracy: 1.0000\n",
            "Epoch 59/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.2649 - accuracy: 1.0000 - val_loss: 108.3058 - val_accuracy: 1.0000\n",
            "Epoch 60/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.1461 - accuracy: 1.0000 - val_loss: 106.6426 - val_accuracy: 1.0000\n",
            "Epoch 61/700\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.4328 - accuracy: 1.0000 - val_loss: 105.8718 - val_accuracy: 1.0000\n",
            "Epoch 62/700\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.6135 - accuracy: 1.0000 - val_loss: 105.7192 - val_accuracy: 1.0000\n",
            "Epoch 63/700\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.2117 - accuracy: 1.0000 - val_loss: 106.5811 - val_accuracy: 1.0000\n",
            "Epoch 64/700\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.2601 - accuracy: 1.0000 - val_loss: 108.2047 - val_accuracy: 1.0000\n",
            "Epoch 65/700\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.1411 - accuracy: 1.0000 - val_loss: 109.5478 - val_accuracy: 1.0000\n",
            "Epoch 66/700\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.4339 - accuracy: 0.9942 - val_loss: 110.1036 - val_accuracy: 1.0000\n",
            "Epoch 67/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.3101 - accuracy: 1.0000 - val_loss: 107.8190 - val_accuracy: 1.0000\n",
            "Epoch 68/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.4966 - accuracy: 1.0000 - val_loss: 107.3492 - val_accuracy: 1.0000\n",
            "Epoch 69/700\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.3398 - accuracy: 1.0000 - val_loss: 106.6602 - val_accuracy: 1.0000\n",
            "Epoch 70/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.4602 - accuracy: 1.0000 - val_loss: 105.9135 - val_accuracy: 1.0000\n",
            "Epoch 71/700\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 2.4467 - accuracy: 1.0000 - val_loss: 105.8363 - val_accuracy: 1.0000\n",
            "Epoch 72/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.2716 - accuracy: 0.9942 - val_loss: 105.8404 - val_accuracy: 1.0000\n",
            "Epoch 73/700\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.0067 - accuracy: 1.0000 - val_loss: 105.2042 - val_accuracy: 1.0000\n",
            "Epoch 74/700\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.5610 - accuracy: 0.9884 - val_loss: 103.6761 - val_accuracy: 1.0000\n",
            "Epoch 75/700\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.2613 - accuracy: 1.0000 - val_loss: 105.0630 - val_accuracy: 1.0000\n",
            "Epoch 76/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.4906 - accuracy: 1.0000 - val_loss: 106.0742 - val_accuracy: 1.0000\n",
            "Epoch 77/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.9990 - accuracy: 1.0000 - val_loss: 106.6336 - val_accuracy: 1.0000\n",
            "Epoch 78/700\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.0408 - accuracy: 1.0000 - val_loss: 107.0613 - val_accuracy: 1.0000\n",
            "Epoch 79/700\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.1127 - accuracy: 0.9884 - val_loss: 106.8226 - val_accuracy: 1.0000\n",
            "Epoch 80/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.1261 - accuracy: 1.0000 - val_loss: 106.2832 - val_accuracy: 1.0000\n",
            "Epoch 81/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.2333 - accuracy: 0.9942 - val_loss: 105.9262 - val_accuracy: 1.0000\n",
            "Epoch 82/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.8253 - accuracy: 0.9942 - val_loss: 106.6817 - val_accuracy: 1.0000\n",
            "Epoch 83/700\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.0146 - accuracy: 1.0000 - val_loss: 106.3981 - val_accuracy: 1.0000\n",
            "Epoch 84/700\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.8454 - accuracy: 1.0000 - val_loss: 107.3172 - val_accuracy: 1.0000\n",
            "Epoch 85/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.0676 - accuracy: 0.9942 - val_loss: 107.5741 - val_accuracy: 1.0000\n",
            "Epoch 86/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.1020 - accuracy: 1.0000 - val_loss: 106.3406 - val_accuracy: 1.0000\n",
            "Epoch 87/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.0385 - accuracy: 1.0000 - val_loss: 105.2312 - val_accuracy: 1.0000\n",
            "Epoch 88/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.1131 - accuracy: 0.9942 - val_loss: 105.2305 - val_accuracy: 1.0000\n",
            "Epoch 89/700\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.8646 - accuracy: 1.0000 - val_loss: 105.2343 - val_accuracy: 1.0000\n",
            "Epoch 90/700\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.0073 - accuracy: 0.9942 - val_loss: 105.2950 - val_accuracy: 1.0000\n",
            "Epoch 91/700\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.9724 - accuracy: 0.9884 - val_loss: 127.8091 - val_accuracy: 1.0000\n",
            "Epoch 92/700\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 2.0181 - accuracy: 1.0000 - val_loss: 131.4122 - val_accuracy: 1.0000\n",
            "Epoch 93/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.4078 - accuracy: 1.0000 - val_loss: 110.0641 - val_accuracy: 1.0000\n",
            "Epoch 94/700\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.9165 - accuracy: 1.0000 - val_loss: 146.3876 - val_accuracy: 0.9831\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 4.7475 - accuracy: 0.9831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.DataFrame(history.history).plot(figsize=(20, 12))\n",
        "plt.grid(True)\n",
        "plt.show"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2URiPXvidlvw",
        "outputId": "a0f30d05-b7d9-4daa-85dc-71f77fed8a7c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "Yj7wnz1pvl_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94a9e6fe-e8bf-4c30-80a1-5f2e68e740f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 24.4819\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24.481895446777344"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_new = x_test[:20]\n",
        "y_pred = model.predict(x_new)\n",
        "print(y_pred.round(0))\n",
        "print( )\n",
        "print(y_test[:20])\n",
        "print()\n",
        "print(y_pred.round(0)-y_test[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHbuQqR6e7JG",
        "outputId": "ba276f2b-c1f1-4e6f-d39e-17645a5f91e6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 150ms/step\n",
            "[[141. 132. 127. 119. 110.  95.  81.  75.  70.]\n",
            " [150. 138. 129. 118. 107.  93.  82.  77.  74.]\n",
            " [146. 135. 128. 118. 107.  93.  82.  77.  72.]\n",
            " [150. 138. 130. 120. 108.  92.  82.  78.  75.]\n",
            " [150. 141. 132. 119. 105.  91.  83.  80.  77.]\n",
            " [144. 137. 129. 119. 107.  93.  82.  77.  73.]\n",
            " [161. 146. 132. 118. 104.  92.  85.  82.  78.]\n",
            " [127. 125. 122. 119. 112. 101.  83.  69.  62.]\n",
            " [156. 140. 129. 118. 105.  92.  83.  79.  76.]\n",
            " [146. 136. 128. 118. 106.  92.  81.  76.  73.]\n",
            " [141. 135. 129. 119. 108.  95.  82.  76.  72.]\n",
            " [158. 144. 132. 118. 104.  92.  84.  81.  78.]\n",
            " [153. 139. 130. 119. 107.  92.  83.  78.  76.]\n",
            " [163. 144. 130. 116. 102.  91.  85.  80.  77.]\n",
            " [153. 141. 132. 121. 109.  95.  84.  79.  76.]\n",
            " [136. 129. 125. 118. 110.  97.  82.  73.  67.]\n",
            " [145. 136. 130. 119. 107.  93.  82.  77.  74.]\n",
            " [150. 138. 129. 119. 108.  94.  83.  78.  74.]\n",
            " [166. 147. 134. 118. 104.  93.  87.  83.  80.]\n",
            " [150. 139. 130. 119. 107.  92.  83.  78.  75.]]\n",
            "\n",
            "[[145 135 129 119 106  90  80  76  73]\n",
            " [145 135 128 117 106  94  82  73  69]\n",
            " [137 130 123 117 109  98  84  70  62]\n",
            " [152 139 128 117 103  90  82  78  75]\n",
            " [143 137 130 120 103  89  82  77  75]\n",
            " [148 141 131 116 101  90  82  79  75]\n",
            " [170 143 130 113  99  90  84  80  76]\n",
            " [132 126 123 117 110  98  81  69  65]\n",
            " [142 133 126 118 107  92  79  75  72]\n",
            " [156 138 128 117 105  93  81  76  73]\n",
            " [144 138 131 119 101  88  83  79  77]\n",
            " [149 138 127 115 104  94  84  75  67]\n",
            " [142 135 129 118 105  90  80  76  74]\n",
            " [157 139 129 115 102  91  83  78  74]\n",
            " [159 141 130 114 102  90  82  79  75]\n",
            " [129 127 123 117 110  99  83  69  63]\n",
            " [137 131 126 120 108  91  80  75  72]\n",
            " [145 133 126 119 107  91  80  76  72]\n",
            " [177 145 128 112  99  90  86  80  77]\n",
            " [146 134 127 116 107  94  83  73  65]]\n",
            "\n",
            "[[ -4.  -3.  -2.   0.   4.   5.   1.  -1.  -3.]\n",
            " [  5.   3.   1.   1.   1.  -1.   0.   4.   5.]\n",
            " [  9.   5.   5.   1.  -2.  -5.  -2.   7.  10.]\n",
            " [ -2.  -1.   2.   3.   5.   2.   0.   0.   0.]\n",
            " [  7.   4.   2.  -1.   2.   2.   1.   3.   2.]\n",
            " [ -4.  -4.  -2.   3.   6.   3.   0.  -2.  -2.]\n",
            " [ -9.   3.   2.   5.   5.   2.   1.   2.   2.]\n",
            " [ -5.  -1.  -1.   2.   2.   3.   2.   0.  -3.]\n",
            " [ 14.   7.   3.   0.  -2.   0.   4.   4.   4.]\n",
            " [-10.  -2.   0.   1.   1.  -1.   0.   0.   0.]\n",
            " [ -3.  -3.  -2.   0.   7.   7.  -1.  -3.  -5.]\n",
            " [  9.   6.   5.   3.   0.  -2.   0.   6.  11.]\n",
            " [ 11.   4.   1.   1.   2.   2.   3.   2.   2.]\n",
            " [  6.   5.   1.   1.   0.   0.   2.   2.   3.]\n",
            " [ -6.   0.   2.   7.   7.   5.   2.   0.   1.]\n",
            " [  7.   2.   2.   1.   0.  -2.  -1.   4.   4.]\n",
            " [  8.   5.   4.  -1.  -1.   2.   2.   2.   2.]\n",
            " [  5.   5.   3.   0.   1.   3.   3.   2.   2.]\n",
            " [-11.   2.   6.   6.   5.   3.   1.   3.   3.]\n",
            " [  4.   5.   3.   3.   0.  -2.   0.   5.  10.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BBw1Nt4mPVU2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}